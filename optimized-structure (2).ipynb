{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.16","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":93057,"databundleVersionId":11145869,"sourceType":"competition"}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport pickle\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nfrom torch.utils.data import DataLoader, random_split, TensorDataset\nfrom torch.optim.lr_scheduler import StepLR\nfrom PIL import Image\n\n# auto. choose CPU or GPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n# Function to load CIFAR-10 dataset\ndef load_cifar_batch(file):\n    with open(file, 'rb') as fo:\n        dict = pickle.load(fo, encoding='bytes')\n    return dict\n\n# Specify the directory containing CIFAR-10 batches\ncifar10_dir = '/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py'\n\n# Load metadata (labels)\nmeta_data_dict = load_cifar_batch(os.path.join(cifar10_dir, 'batches.meta'))\nlabel_names = [label.decode('utf-8') for label in meta_data_dict[b'label_names']]\n\n# Load training data\ntrain_data = []\ntrain_labels = []\nfor i in range(1, 6):\n    batch = load_cifar_batch(os.path.join(cifar10_dir, f'data_batch_{i}'))\n    train_data.append(batch[b'data'])\n    train_labels += batch[b'labels']\n\ntrain_data = np.vstack(train_data).reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)  # Convert to HWC format\ntrain_labels = np.array(train_labels)\n\n# Data augmentation and normalization\ntransform = transforms.Compose([\n    transforms.ToPILImage(),  # Convert numpy array to PIL Image\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(brightness = 0.1,contrast = 0.1,saturation = 0.1),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomAdjustSharpness(sharpness_factor = 2,p = 0.2),\n    transforms.RandomCrop(32, padding=4),\n    transforms.ToTensor(),\n    #transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n    transforms.RandomErasing(p=0.2,scale=(0.02, 0.1),value=1.0, inplace=False)\n])\n\n# Convert to TensorDataset and apply transformations\ntrain_dataset = [(transform(img), label) for img, label in zip(train_data, train_labels)]\n\n# Split into training and validation sets\ntrain_size = int(0.9 * len(train_dataset))\nval_size = len(train_dataset) - train_size\ntrain_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n\n# Load test dataset\ncifar_test_path = '/kaggle/input/deep-learning-spring-2025-project-1/cifar_test_nolabel.pkl'\ntest_batch = load_cifar_batch(cifar_test_path)\ntest_images = test_batch[b'data'].astype(np.float32) / 255.0\ntest_images = test_images.reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)  # Convert to HWC format\n\n# Convert test dataset to Tensor\ntest_dataset = [(transform(img)) for img in test_images]\ntest_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4)\n\n# DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=4)\n\n# Train function\ndef train_model(model, train_loader, val_loader, epochs=30):\n    criterion = nn.CrossEntropyLoss()\n    #optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n    #scheduler = StepLR(optimizer, step_size=20, gamma=0.1)\n    scheduler = StepLR(optimizer, step_size=10, gamma=0.5)\n\n    \n    for epoch in range(epochs):\n        model.train()\n        running_loss = 0.0\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        \n        model.eval()\n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                _, predicted = torch.max(outputs, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n        \n        scheduler.step()\n        print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}, Validation Accuracy: {100 * correct / total}%')\n\n# Define a custom ResNet model from scratch\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.skip = nn.Sequential()\n        if stride != 1 or in_channels != out_channels:\n            self.skip = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels)\n            )\n    \n    def forward(self, x):\n        identity = x \n        if self.skip:\n            identity = self.skip(x)\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out += identity\n        out = self.relu(out)\n        return out\n\nclass CustomResNet(nn.Module):\n    def __init__(self, num_classes=10):\n        super(CustomResNet, self).__init__()\n        self.init_conv = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.init_bn = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.layer1 = self._make_layer(64, 64, 2, stride=1)\n        self.layer2 = self._make_layer(64, 128, 2, stride=2)\n        self.layer3 = self._make_layer(128, 256, 2, stride=2)\n        #self.layer4 = self._make_layer(256, 512, 2, stride=2)\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Linear(256, num_classes)\n\n    def _make_layer(self, in_channels, out_channels, blocks, stride):\n        layers = [ResidualBlock(in_channels, out_channels, stride)]\n        for _ in range(1, blocks):\n            layers.append(ResidualBlock(out_channels, out_channels))\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = self.init_conv(x)\n        out = self.init_bn(out)\n        out = self.relu(out)\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        #out = self.layer4(out)\n        out = self.avg_pool(out)\n        out = torch.flatten(out, 1)\n        out = self.fc(out)\n        return out\n\n# put models to devices (CPU/GPU)\nmodel = CustomResNet().to(device)\n\n# Print the number of parameters\nfrom torchsummary import summary\nsummary(model, (3, 32, 32))\n\n# Train the model\ntrain_model(model, train_loader, val_loader, epochs=30) #originally 50\n\n# Generate submission file\nmodel.eval()\npredictions = []\nwith torch.no_grad():\n    for images in test_loader:\n        images = images.to(device) \n        outputs = model(images) \n        _, predicted = torch.max(outputs, 1)\n        predictions.extend(predicted.cpu().numpy())\n\nsubmission = pd.DataFrame({'ID': np.arange(len(predictions)), 'Labels': predictions})\nsubmission.to_csv('/kaggle/working/submission.csv', index=False)\nprint(\"Submission file saved.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T18:24:34.611368Z","iopub.execute_input":"2025-03-07T18:24:34.611618Z","iopub.status.idle":"2025-03-07T18:39:41.882237Z","shell.execute_reply.started":"2025-03-07T18:24:34.611596Z","shell.execute_reply":"2025-03-07T18:39:41.881238Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1           [-1, 64, 32, 32]           1,728\n       BatchNorm2d-2           [-1, 64, 32, 32]             128\n              ReLU-3           [-1, 64, 32, 32]               0\n            Conv2d-4           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-5           [-1, 64, 32, 32]             128\n              ReLU-6           [-1, 64, 32, 32]               0\n            Conv2d-7           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-8           [-1, 64, 32, 32]             128\n              ReLU-9           [-1, 64, 32, 32]               0\n    ResidualBlock-10           [-1, 64, 32, 32]               0\n           Conv2d-11           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-12           [-1, 64, 32, 32]             128\n             ReLU-13           [-1, 64, 32, 32]               0\n           Conv2d-14           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-15           [-1, 64, 32, 32]             128\n             ReLU-16           [-1, 64, 32, 32]               0\n    ResidualBlock-17           [-1, 64, 32, 32]               0\n           Conv2d-18          [-1, 128, 16, 16]           8,192\n      BatchNorm2d-19          [-1, 128, 16, 16]             256\n           Conv2d-20          [-1, 128, 16, 16]          73,728\n      BatchNorm2d-21          [-1, 128, 16, 16]             256\n             ReLU-22          [-1, 128, 16, 16]               0\n           Conv2d-23          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-24          [-1, 128, 16, 16]             256\n             ReLU-25          [-1, 128, 16, 16]               0\n    ResidualBlock-26          [-1, 128, 16, 16]               0\n           Conv2d-27          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-28          [-1, 128, 16, 16]             256\n             ReLU-29          [-1, 128, 16, 16]               0\n           Conv2d-30          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-31          [-1, 128, 16, 16]             256\n             ReLU-32          [-1, 128, 16, 16]               0\n    ResidualBlock-33          [-1, 128, 16, 16]               0\n           Conv2d-34            [-1, 256, 8, 8]          32,768\n      BatchNorm2d-35            [-1, 256, 8, 8]             512\n           Conv2d-36            [-1, 256, 8, 8]         294,912\n      BatchNorm2d-37            [-1, 256, 8, 8]             512\n             ReLU-38            [-1, 256, 8, 8]               0\n           Conv2d-39            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-40            [-1, 256, 8, 8]             512\n             ReLU-41            [-1, 256, 8, 8]               0\n    ResidualBlock-42            [-1, 256, 8, 8]               0\n           Conv2d-43            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-44            [-1, 256, 8, 8]             512\n             ReLU-45            [-1, 256, 8, 8]               0\n           Conv2d-46            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-47            [-1, 256, 8, 8]             512\n             ReLU-48            [-1, 256, 8, 8]               0\n    ResidualBlock-49            [-1, 256, 8, 8]               0\nAdaptiveAvgPool2d-50            [-1, 256, 1, 1]               0\n           Linear-51                   [-1, 10]           2,570\n================================================================\nTotal params: 2,777,674\nTrainable params: 2,777,674\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.01\nForward/backward pass size (MB): 14.50\nParams size (MB): 10.60\nEstimated Total Size (MB): 25.11\n----------------------------------------------------------------\nEpoch 1, Loss: 1.5248508836058052, Validation Accuracy: 49.6%\nEpoch 2, Loss: 1.0962714097377928, Validation Accuracy: 45.14%\nEpoch 3, Loss: 0.8826654380695387, Validation Accuracy: 58.9%\nEpoch 4, Loss: 0.7308620891787789, Validation Accuracy: 69.82%\nEpoch 5, Loss: 0.6215875993736766, Validation Accuracy: 67.86%\nEpoch 6, Loss: 0.5306581915779547, Validation Accuracy: 73.36%\nEpoch 7, Loss: 0.4476620245470919, Validation Accuracy: 73.82%\nEpoch 8, Loss: 0.37161384150385857, Validation Accuracy: 72.36%\nEpoch 9, Loss: 0.2988157923418013, Validation Accuracy: 73.26%\nEpoch 10, Loss: 0.228967407527803, Validation Accuracy: 57.22%\nEpoch 11, Loss: 0.07812018434263089, Validation Accuracy: 79.28%\nEpoch 12, Loss: 0.026352445473259486, Validation Accuracy: 80.52%\nEpoch 13, Loss: 0.01237494635808451, Validation Accuracy: 80.72%\nEpoch 14, Loss: 0.007786162128137552, Validation Accuracy: 80.94%\nEpoch 15, Loss: 0.005824562183988746, Validation Accuracy: 81.24%\nEpoch 16, Loss: 0.004729437729772392, Validation Accuracy: 81.08%\nEpoch 17, Loss: 0.004181512257756284, Validation Accuracy: 81.14%\nEpoch 18, Loss: 0.0037267027331505565, Validation Accuracy: 81.44%\nEpoch 19, Loss: 0.0033351084679121745, Validation Accuracy: 81.1%\nEpoch 20, Loss: 0.0031902187246569983, Validation Accuracy: 81.3%\nEpoch 21, Loss: 0.0028791632536343636, Validation Accuracy: 81.28%\nEpoch 22, Loss: 0.0027648509706275286, Validation Accuracy: 81.18%\nEpoch 23, Loss: 0.0026645255265148908, Validation Accuracy: 81.26%\nEpoch 24, Loss: 0.002663832992601039, Validation Accuracy: 81.38%\nEpoch 25, Loss: 0.0025866146173608618, Validation Accuracy: 81.26%\nEpoch 26, Loss: 0.0025271068751118782, Validation Accuracy: 81.14%\nEpoch 27, Loss: 0.0024407660017790145, Validation Accuracy: 81.26%\nEpoch 28, Loss: 0.0024083235690671822, Validation Accuracy: 81.34%\nEpoch 29, Loss: 0.002466035565951395, Validation Accuracy: 81.2%\nEpoch 30, Loss: 0.002389023669490019, Validation Accuracy: 81.28%\nSubmission file saved.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport pickle\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nfrom torch.utils.data import DataLoader, random_split, TensorDataset\nfrom torch.optim.lr_scheduler import StepLR\nfrom PIL import Image\nimport torch.optim.lr_scheduler as lr_scheduler\n\n# auto. choose CPU or GPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n# Function to load CIFAR-10 dataset\ndef load_cifar_batch(file):\n    with open(file, 'rb') as fo:\n        dict = pickle.load(fo, encoding='bytes')\n    return dict\n\n# Specify the directory containing CIFAR-10 batches\ncifar10_dir = '/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py'\n\n# Load metadata (labels)\nmeta_data_dict = load_cifar_batch(os.path.join(cifar10_dir, 'batches.meta'))\nlabel_names = [label.decode('utf-8') for label in meta_data_dict[b'label_names']]\n\n# Load training data\ntrain_data = []\ntrain_labels = []\nfor i in range(1, 6):\n    batch = load_cifar_batch(os.path.join(cifar10_dir, f'data_batch_{i}'))\n    train_data.append(batch[b'data'])\n    train_labels += batch[b'labels']\n\ntrain_data = np.vstack(train_data).reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)  # Convert to HWC format\ntrain_labels = np.array(train_labels)\n\n# Data augmentation and normalization\ntransform = transforms.Compose([\n    transforms.ToPILImage(),  # Convert numpy array to PIL Image\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(brightness = 0.1,contrast = 0.1,saturation = 0.1),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomAdjustSharpness(sharpness_factor = 2,p = 0.2),\n    transforms.RandomCrop(32, padding=4),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n    transforms.RandomErasing(p=0.2,scale=(0.02, 0.1),value=1.0, inplace=False)\n])\n\n# Convert to TensorDataset and apply transformations\ntrain_dataset = [(transform(img), label) for img, label in zip(train_data, train_labels)]\n\n# Split into training and validation sets\ntrain_size = int(0.9 * len(train_dataset))\nval_size = len(train_dataset) - train_size\ntrain_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n\n# Load test dataset\ncifar_test_path = '/kaggle/input/deep-learning-spring-2025-project-1/cifar_test_nolabel.pkl'\ntest_batch = load_cifar_batch(cifar_test_path)\ntest_images = test_batch[b'data'].astype(np.float32) / 255.0\ntest_images = test_images.reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)  # Convert to HWC format\n\n# Convert test dataset to Tensor\ntest_dataset = [(transform(img)) for img in test_images]\ntest_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4)\n\n# DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=4)\n\n# Train function\ndef train_model(model, train_loader, val_loader, epochs=30):\n    criterion = nn.CrossEntropyLoss()\n    #optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n    #scheduler = StepLR(optimizer, step_size=20, gamma=0.1)\n    scheduler = StepLR(optimizer, step_size=5, gamma=0.8)\n\n    \n    for epoch in range(epochs):\n        model.train()\n        running_loss = 0.0\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        \n        model.eval()\n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                _, predicted = torch.max(outputs, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n        \n        scheduler.step()\n        print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}, Validation Accuracy: {100 * correct / total}%')\n\n# Define a custom ResNet model from scratch\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.skip = nn.Sequential()\n        if stride != 1 or in_channels != out_channels:\n            self.skip = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels)\n            )\n        self.dropout = nn.Dropout(0.2)\n    def forward(self, x):\n        identity = x \n        if self.skip:\n            identity = self.skip(x)\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out += identity\n        out = self.relu(out)\n        out = self.dropout(out)\n        return out\n\nclass CustomResNet(nn.Module):\n    def __init__(self, num_classes=10):\n        super(CustomResNet, self).__init__()\n        self.init_conv = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.init_bn = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.layer1 = self._make_layer(64, 64, 2, stride=1)\n        self.layer2 = self._make_layer(64, 128, 2, stride=2)\n        self.layer3 = self._make_layer(128, 256, 2, stride=2)\n        #self.layer4 = self._make_layer(256, 512, 2, stride=2)\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Linear(256, num_classes)\n\n    def _make_layer(self, in_channels, out_channels, blocks, stride):\n        layers = [ResidualBlock(in_channels, out_channels, stride)]\n        for _ in range(1, blocks):\n            layers.append(ResidualBlock(out_channels, out_channels))\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = self.init_conv(x)\n        out = self.init_bn(out)\n        out = self.relu(out)\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        #out = self.layer4(out)\n        out = self.avg_pool(out)\n        out = torch.flatten(out, 1)\n        out = self.fc(out)\n        return out\n\n# put models to devices (CPU/GPU)\nmodel = CustomResNet().to(device)\n\n# Print the number of parameters\nfrom torchsummary import summary\nsummary(model, (3, 32, 32))\n\n# Train the model\ntrain_model(model, train_loader, val_loader, epochs=30) #originally 50\n\n# Generate submission file\nmodel.eval()\npredictions = []\nwith torch.no_grad():\n    for images in test_loader:\n        images = images.to(device) \n        outputs = model(images) \n        _, predicted = torch.max(outputs, 1)\n        predictions.extend(predicted.cpu().numpy())\n\nsubmission = pd.DataFrame({'ID': np.arange(len(predictions)), 'Labels': predictions})\nsubmission.to_csv('/kaggle/working/submission.csv', index=False)\nprint(\"Submission file saved.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T19:04:45.673040Z","iopub.execute_input":"2025-03-07T19:04:45.673410Z","iopub.status.idle":"2025-03-07T19:20:19.879679Z","shell.execute_reply.started":"2025-03-07T19:04:45.673375Z","shell.execute_reply":"2025-03-07T19:20:19.878663Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1           [-1, 64, 32, 32]           1,728\n       BatchNorm2d-2           [-1, 64, 32, 32]             128\n              ReLU-3           [-1, 64, 32, 32]               0\n            Conv2d-4           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-5           [-1, 64, 32, 32]             128\n              ReLU-6           [-1, 64, 32, 32]               0\n            Conv2d-7           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-8           [-1, 64, 32, 32]             128\n              ReLU-9           [-1, 64, 32, 32]               0\n          Dropout-10           [-1, 64, 32, 32]               0\n    ResidualBlock-11           [-1, 64, 32, 32]               0\n           Conv2d-12           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-13           [-1, 64, 32, 32]             128\n             ReLU-14           [-1, 64, 32, 32]               0\n           Conv2d-15           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-16           [-1, 64, 32, 32]             128\n             ReLU-17           [-1, 64, 32, 32]               0\n          Dropout-18           [-1, 64, 32, 32]               0\n    ResidualBlock-19           [-1, 64, 32, 32]               0\n           Conv2d-20          [-1, 128, 16, 16]           8,192\n      BatchNorm2d-21          [-1, 128, 16, 16]             256\n           Conv2d-22          [-1, 128, 16, 16]          73,728\n      BatchNorm2d-23          [-1, 128, 16, 16]             256\n             ReLU-24          [-1, 128, 16, 16]               0\n           Conv2d-25          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-26          [-1, 128, 16, 16]             256\n             ReLU-27          [-1, 128, 16, 16]               0\n          Dropout-28          [-1, 128, 16, 16]               0\n    ResidualBlock-29          [-1, 128, 16, 16]               0\n           Conv2d-30          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-31          [-1, 128, 16, 16]             256\n             ReLU-32          [-1, 128, 16, 16]               0\n           Conv2d-33          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-34          [-1, 128, 16, 16]             256\n             ReLU-35          [-1, 128, 16, 16]               0\n          Dropout-36          [-1, 128, 16, 16]               0\n    ResidualBlock-37          [-1, 128, 16, 16]               0\n           Conv2d-38            [-1, 256, 8, 8]          32,768\n      BatchNorm2d-39            [-1, 256, 8, 8]             512\n           Conv2d-40            [-1, 256, 8, 8]         294,912\n      BatchNorm2d-41            [-1, 256, 8, 8]             512\n             ReLU-42            [-1, 256, 8, 8]               0\n           Conv2d-43            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-44            [-1, 256, 8, 8]             512\n             ReLU-45            [-1, 256, 8, 8]               0\n          Dropout-46            [-1, 256, 8, 8]               0\n    ResidualBlock-47            [-1, 256, 8, 8]               0\n           Conv2d-48            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-49            [-1, 256, 8, 8]             512\n             ReLU-50            [-1, 256, 8, 8]               0\n           Conv2d-51            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-52            [-1, 256, 8, 8]             512\n             ReLU-53            [-1, 256, 8, 8]               0\n          Dropout-54            [-1, 256, 8, 8]               0\n    ResidualBlock-55            [-1, 256, 8, 8]               0\nAdaptiveAvgPool2d-56            [-1, 256, 1, 1]               0\n           Linear-57                   [-1, 10]           2,570\n================================================================\nTotal params: 2,777,674\nTrainable params: 2,777,674\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.01\nForward/backward pass size (MB): 16.25\nParams size (MB): 10.60\nEstimated Total Size (MB): 26.86\n----------------------------------------------------------------\nEpoch 1, Loss: 1.6518613296476277, Validation Accuracy: 45.8%\nEpoch 2, Loss: 1.2366346760906957, Validation Accuracy: 57.4%\nEpoch 3, Loss: 1.0638997388834304, Validation Accuracy: 62.94%\nEpoch 4, Loss: 0.9451095451685515, Validation Accuracy: 65.28%\nEpoch 5, Loss: 0.8514094332402403, Validation Accuracy: 69.06%\nEpoch 6, Loss: 0.7431893590837717, Validation Accuracy: 73.72%\nEpoch 7, Loss: 0.6880561915141615, Validation Accuracy: 74.78%\nEpoch 8, Loss: 0.6392082818360492, Validation Accuracy: 72.18%\nEpoch 9, Loss: 0.5989587886936285, Validation Accuracy: 74.36%\nEpoch 10, Loss: 0.5569356201555241, Validation Accuracy: 76.76%\nEpoch 11, Loss: 0.4908081461590799, Validation Accuracy: 77.34%\nEpoch 12, Loss: 0.4647388913753358, Validation Accuracy: 78.86%\nEpoch 13, Loss: 0.4399693795395168, Validation Accuracy: 77.64%\nEpoch 14, Loss: 0.4179625504819507, Validation Accuracy: 75.36%\nEpoch 15, Loss: 0.3940395001237365, Validation Accuracy: 78.2%\nEpoch 16, Loss: 0.3469381809065288, Validation Accuracy: 79.62%\nEpoch 17, Loss: 0.3205954333428632, Validation Accuracy: 81.24%\nEpoch 18, Loss: 0.30623356968333776, Validation Accuracy: 79.46%\nEpoch 19, Loss: 0.2887411242435602, Validation Accuracy: 79.72%\nEpoch 20, Loss: 0.27872536767443473, Validation Accuracy: 80.36%\nEpoch 21, Loss: 0.23427330816841938, Validation Accuracy: 81.3%\nEpoch 22, Loss: 0.21952334222045133, Validation Accuracy: 81.52%\nEpoch 23, Loss: 0.2085139069028876, Validation Accuracy: 82.02%\nEpoch 24, Loss: 0.1989389641676098, Validation Accuracy: 82.14%\nEpoch 25, Loss: 0.18629498250613158, Validation Accuracy: 80.26%\nEpoch 26, Loss: 0.16068287485871802, Validation Accuracy: 81.82%\nEpoch 27, Loss: 0.14474500267004425, Validation Accuracy: 82.48%\nEpoch 28, Loss: 0.13745750457217748, Validation Accuracy: 82.66%\nEpoch 29, Loss: 0.13219300148458304, Validation Accuracy: 83.5%\nEpoch 30, Loss: 0.12382401557723907, Validation Accuracy: 83.38%\nSubmission file saved.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport pickle\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nfrom torch.utils.data import DataLoader, random_split, TensorDataset\nfrom torch.optim.lr_scheduler import StepLR\nfrom PIL import Image\nimport torch.optim.lr_scheduler as lr_scheduler\n\n# auto. choose CPU or GPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n# Function to load CIFAR-10 dataset\ndef load_cifar_batch(file):\n    with open(file, 'rb') as fo:\n        dict = pickle.load(fo, encoding='bytes')\n    return dict\n\n# Specify the directory containing CIFAR-10 batches\ncifar10_dir = '/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py'\n\n# Load metadata (labels)\nmeta_data_dict = load_cifar_batch(os.path.join(cifar10_dir, 'batches.meta'))\nlabel_names = [label.decode('utf-8') for label in meta_data_dict[b'label_names']]\n\n# Load training data\ntrain_data = []\ntrain_labels = []\nfor i in range(1, 6):\n    batch = load_cifar_batch(os.path.join(cifar10_dir, f'data_batch_{i}'))\n    train_data.append(batch[b'data'])\n    train_labels += batch[b'labels']\n\ntrain_data = np.vstack(train_data).reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)  # Convert to HWC format\ntrain_labels = np.array(train_labels)\n\n# Data augmentation and normalization\ntransform = transforms.Compose([\n    transforms.ToPILImage(),  # Convert numpy array to PIL Image\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(brightness = 0.1,contrast = 0.1,saturation = 0.1),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomAdjustSharpness(sharpness_factor = 2,p = 0.2),\n    transforms.RandomCrop(32, padding=4),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n    transforms.RandomErasing(p=0.2,scale=(0.02, 0.1),value=1.0, inplace=False)\n])\n\n# Convert to TensorDataset and apply transformations\ntrain_dataset = [(transform(img), label) for img, label in zip(train_data, train_labels)]\n\n# Split into training and validation sets\ntrain_size = int(0.9 * len(train_dataset))\nval_size = len(train_dataset) - train_size\ntrain_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n\n# Load test dataset\ncifar_test_path = '/kaggle/input/deep-learning-spring-2025-project-1/cifar_test_nolabel.pkl'\ntest_batch = load_cifar_batch(cifar_test_path)\ntest_images = test_batch[b'data'].astype(np.float32) / 255.0\ntest_images = test_images.reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)  # Convert to HWC format\n\n# Convert test dataset to Tensor\ntest_dataset = [(transform(img)) for img in test_images]\ntest_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4)\n\n# DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=4)\n\n# Train function\ndef train_model(model, train_loader, val_loader, epochs=30):\n    criterion = nn.CrossEntropyLoss()\n    #optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4) #change weight_decay\n    #scheduler = StepLR(optimizer, step_size=20, gamma=0.1)\n    scheduler = StepLR(optimizer, step_size=5, gamma=0.8)\n\n    \n    for epoch in range(epochs):\n        model.train()\n        running_loss = 0.0\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        \n        model.eval()\n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                _, predicted = torch.max(outputs, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n        \n        scheduler.step()\n        print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}, Validation Accuracy: {100 * correct / total}%')\n\n# Define a custom ResNet model from scratch\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.skip = nn.Sequential()\n        if stride != 1 or in_channels != out_channels:\n            self.skip = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels)\n            )\n        self.dropout = nn.Dropout(0.2)\n    def forward(self, x):\n        identity = x \n        if self.skip:\n            identity = self.skip(x)\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out += identity\n        out = self.relu(out)\n        out = self.dropout(out)\n        return out\n\nclass CustomResNet(nn.Module):\n    def __init__(self, num_classes=10):\n        super(CustomResNet, self).__init__()\n        self.init_conv = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.init_bn = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.layer1 = self._make_layer(64, 64, 2, stride=1)\n        self.layer2 = self._make_layer(64, 128, 2, stride=2)\n        self.layer3 = self._make_layer(128, 256, 2, stride=2)\n        #self.layer4 = self._make_layer(256, 512, 2, stride=2)\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Linear(256, num_classes)\n\n    def _make_layer(self, in_channels, out_channels, blocks, stride):\n        layers = [ResidualBlock(in_channels, out_channels, stride)]\n        for _ in range(1, blocks):\n            layers.append(ResidualBlock(out_channels, out_channels))\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = self.init_conv(x)\n        out = self.init_bn(out)\n        out = self.relu(out)\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        #out = self.layer4(out)\n        out = self.avg_pool(out)\n        out = torch.flatten(out, 1)\n        out = self.fc(out)\n        return out\n\n# put models to devices (CPU/GPU)\nmodel = CustomResNet().to(device)\n\n# Print the number of parameters\nfrom torchsummary import summary\nsummary(model, (3, 32, 32))\n\n# Train the model\ntrain_model(model, train_loader, val_loader, epochs=40) #originally 50\n\n# Generate submission file\nmodel.eval()\npredictions = []\nwith torch.no_grad():\n    for images in test_loader:\n        images = images.to(device) \n        outputs = model(images) \n        _, predicted = torch.max(outputs, 1)\n        predictions.extend(predicted.cpu().numpy())\n\nsubmission = pd.DataFrame({'ID': np.arange(len(predictions)), 'Labels': predictions})\nsubmission.to_csv('/kaggle/working/submission.csv', index=False)\nprint(\"Submission file saved.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T19:27:59.576903Z","iopub.execute_input":"2025-03-07T19:27:59.577228Z","iopub.status.idle":"2025-03-07T19:48:24.442499Z","shell.execute_reply.started":"2025-03-07T19:27:59.577202Z","shell.execute_reply":"2025-03-07T19:48:24.441333Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1           [-1, 64, 32, 32]           1,728\n       BatchNorm2d-2           [-1, 64, 32, 32]             128\n              ReLU-3           [-1, 64, 32, 32]               0\n            Conv2d-4           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-5           [-1, 64, 32, 32]             128\n              ReLU-6           [-1, 64, 32, 32]               0\n            Conv2d-7           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-8           [-1, 64, 32, 32]             128\n              ReLU-9           [-1, 64, 32, 32]               0\n          Dropout-10           [-1, 64, 32, 32]               0\n    ResidualBlock-11           [-1, 64, 32, 32]               0\n           Conv2d-12           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-13           [-1, 64, 32, 32]             128\n             ReLU-14           [-1, 64, 32, 32]               0\n           Conv2d-15           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-16           [-1, 64, 32, 32]             128\n             ReLU-17           [-1, 64, 32, 32]               0\n          Dropout-18           [-1, 64, 32, 32]               0\n    ResidualBlock-19           [-1, 64, 32, 32]               0\n           Conv2d-20          [-1, 128, 16, 16]           8,192\n      BatchNorm2d-21          [-1, 128, 16, 16]             256\n           Conv2d-22          [-1, 128, 16, 16]          73,728\n      BatchNorm2d-23          [-1, 128, 16, 16]             256\n             ReLU-24          [-1, 128, 16, 16]               0\n           Conv2d-25          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-26          [-1, 128, 16, 16]             256\n             ReLU-27          [-1, 128, 16, 16]               0\n          Dropout-28          [-1, 128, 16, 16]               0\n    ResidualBlock-29          [-1, 128, 16, 16]               0\n           Conv2d-30          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-31          [-1, 128, 16, 16]             256\n             ReLU-32          [-1, 128, 16, 16]               0\n           Conv2d-33          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-34          [-1, 128, 16, 16]             256\n             ReLU-35          [-1, 128, 16, 16]               0\n          Dropout-36          [-1, 128, 16, 16]               0\n    ResidualBlock-37          [-1, 128, 16, 16]               0\n           Conv2d-38            [-1, 256, 8, 8]          32,768\n      BatchNorm2d-39            [-1, 256, 8, 8]             512\n           Conv2d-40            [-1, 256, 8, 8]         294,912\n      BatchNorm2d-41            [-1, 256, 8, 8]             512\n             ReLU-42            [-1, 256, 8, 8]               0\n           Conv2d-43            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-44            [-1, 256, 8, 8]             512\n             ReLU-45            [-1, 256, 8, 8]               0\n          Dropout-46            [-1, 256, 8, 8]               0\n    ResidualBlock-47            [-1, 256, 8, 8]               0\n           Conv2d-48            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-49            [-1, 256, 8, 8]             512\n             ReLU-50            [-1, 256, 8, 8]               0\n           Conv2d-51            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-52            [-1, 256, 8, 8]             512\n             ReLU-53            [-1, 256, 8, 8]               0\n          Dropout-54            [-1, 256, 8, 8]               0\n    ResidualBlock-55            [-1, 256, 8, 8]               0\nAdaptiveAvgPool2d-56            [-1, 256, 1, 1]               0\n           Linear-57                   [-1, 10]           2,570\n================================================================\nTotal params: 2,777,674\nTrainable params: 2,777,674\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.01\nForward/backward pass size (MB): 16.25\nParams size (MB): 10.60\nEstimated Total Size (MB): 26.86\n----------------------------------------------------------------\nEpoch 1, Loss: 1.628553574735468, Validation Accuracy: 46.94%\nEpoch 2, Loss: 1.2354081442410296, Validation Accuracy: 53.42%\nEpoch 3, Loss: 1.0583912899548358, Validation Accuracy: 64.2%\nEpoch 4, Loss: 0.9480911251157522, Validation Accuracy: 64.32%\nEpoch 5, Loss: 0.8540978748351336, Validation Accuracy: 67.82%\nEpoch 6, Loss: 0.7568965918299827, Validation Accuracy: 71.68%\nEpoch 7, Loss: 0.6987015345895832, Validation Accuracy: 71.22%\nEpoch 8, Loss: 0.64498478225009, Validation Accuracy: 75.54%\nEpoch 9, Loss: 0.5959968350150369, Validation Accuracy: 75.12%\nEpoch 10, Loss: 0.5609357057308609, Validation Accuracy: 73.86%\nEpoch 11, Loss: 0.5001656711948189, Validation Accuracy: 79.48%\nEpoch 12, Loss: 0.46948416040024976, Validation Accuracy: 79.66%\nEpoch 13, Loss: 0.4449122021906078, Validation Accuracy: 80.54%\nEpoch 14, Loss: 0.4200484702702273, Validation Accuracy: 78.84%\nEpoch 15, Loss: 0.39642193278467114, Validation Accuracy: 78.2%\nEpoch 16, Loss: 0.34608470428396354, Validation Accuracy: 81.94%\nEpoch 17, Loss: 0.3250973485833542, Validation Accuracy: 81.64%\nEpoch 18, Loss: 0.30993150013752957, Validation Accuracy: 82.56%\nEpoch 19, Loss: 0.30119358701631427, Validation Accuracy: 82.52%\nEpoch 20, Loss: 0.2812915992584418, Validation Accuracy: 80.76%\nEpoch 21, Loss: 0.24638999992219562, Validation Accuracy: 83.1%\nEpoch 22, Loss: 0.2261774741875177, Validation Accuracy: 83.06%\nEpoch 23, Loss: 0.2176978858399459, Validation Accuracy: 83.18%\nEpoch 24, Loss: 0.20759503259746867, Validation Accuracy: 81.96%\nEpoch 25, Loss: 0.19341263344342058, Validation Accuracy: 83.4%\nEpoch 26, Loss: 0.16581893134438855, Validation Accuracy: 84.32%\nEpoch 27, Loss: 0.15339627053419297, Validation Accuracy: 84.26%\nEpoch 28, Loss: 0.14545308605937118, Validation Accuracy: 83.88%\nEpoch 29, Loss: 0.1414017579729923, Validation Accuracy: 85.52%\nEpoch 30, Loss: 0.13329801979390057, Validation Accuracy: 84.38%\nEpoch 31, Loss: 0.11584092645948245, Validation Accuracy: 84.26%\nEpoch 32, Loss: 0.10901587986683642, Validation Accuracy: 84.94%\nEpoch 33, Loss: 0.10156943846959621, Validation Accuracy: 84.7%\nEpoch 34, Loss: 0.09400474787054752, Validation Accuracy: 84.42%\nEpoch 35, Loss: 0.09120782176350159, Validation Accuracy: 85.52%\nEpoch 36, Loss: 0.08223044390218671, Validation Accuracy: 85.2%\nEpoch 37, Loss: 0.07701279257360677, Validation Accuracy: 85.38%\nEpoch 38, Loss: 0.06938959665024992, Validation Accuracy: 85.46%\nEpoch 39, Loss: 0.06698693178689362, Validation Accuracy: 85.62%\nEpoch 40, Loss: 0.0652606006690555, Validation Accuracy: 85.04%\nSubmission file saved.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport pickle\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nfrom torch.utils.data import DataLoader, random_split, TensorDataset\nfrom torch.optim.lr_scheduler import StepLR\nfrom PIL import Image\nimport torch.optim.lr_scheduler as lr_scheduler\n\n# auto. choose CPU or GPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n# Function to load CIFAR-10 dataset\ndef load_cifar_batch(file):\n    with open(file, 'rb') as fo:\n        dict = pickle.load(fo, encoding='bytes')\n    return dict\n\n# Specify the directory containing CIFAR-10 batches\ncifar10_dir = '/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py'\n\n# Load metadata (labels)\nmeta_data_dict = load_cifar_batch(os.path.join(cifar10_dir, 'batches.meta'))\nlabel_names = [label.decode('utf-8') for label in meta_data_dict[b'label_names']]\n\n# Load training data\ntrain_data = []\ntrain_labels = []\nfor i in range(1, 6):\n    batch = load_cifar_batch(os.path.join(cifar10_dir, f'data_batch_{i}'))\n    train_data.append(batch[b'data'])\n    train_labels += batch[b'labels']\n\ntrain_data = np.vstack(train_data).reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)  # Convert to HWC format\ntrain_labels = np.array(train_labels)\n\n# Data augmentation and normalization\ntransform = transforms.Compose([\n    transforms.ToPILImage(),  # Convert numpy array to PIL Image\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(brightness = 0.1,contrast = 0.1,saturation = 0.1),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomAdjustSharpness(sharpness_factor = 2,p = 0.2),\n    transforms.RandomCrop(32, padding=4),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n    transforms.RandomErasing(p=0.2,scale=(0.02, 0.1),value=1.0, inplace=False)\n])\n\n# Convert to TensorDataset and apply transformations\ntrain_dataset = [(transform(img), label) for img, label in zip(train_data, train_labels)]\n\n# Split into training and validation sets\ntrain_size = int(0.9 * len(train_dataset))\nval_size = len(train_dataset) - train_size\ntrain_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n\n# Load test dataset\ncifar_test_path = '/kaggle/input/deep-learning-spring-2025-project-1/cifar_test_nolabel.pkl'\ntest_batch = load_cifar_batch(cifar_test_path)\ntest_images = test_batch[b'data'].astype(np.float32) / 255.0\ntest_images = test_images.reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)  # Convert to HWC format\n\n# Convert test dataset to Tensor\ntest_dataset = [(transform(img)) for img in test_images]\ntest_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4)\n\n# DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=4)\n\n# Train function\ndef train_model(model, train_loader, val_loader, epochs=50):\n    criterion = nn.CrossEntropyLoss()\n    #optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n    optimizer = optim.SGD(model.parameters(), lr=0.008, momentum=0.9, weight_decay=1e-4) #change lr\n    #scheduler = StepLR(optimizer, step_size=20, gamma=0.1)\n    scheduler = StepLR(optimizer, step_size=5, gamma=0.9)\n\n    \n    for epoch in range(epochs):\n        model.train()\n        running_loss = 0.0\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        \n        model.eval()\n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                _, predicted = torch.max(outputs, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n        \n        scheduler.step()\n        print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}, Validation Accuracy: {100 * correct / total}%')\n\n# Define a custom ResNet model from scratch\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.skip = nn.Sequential()\n        if stride != 1 or in_channels != out_channels:\n            self.skip = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels)\n            )\n        self.dropout = nn.Dropout(0.2)\n    def forward(self, x):\n        identity = x \n        if self.skip:\n            identity = self.skip(x)\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out += identity\n        out = self.relu(out)\n        out = self.dropout(out)\n        return out\n\nclass CustomResNet(nn.Module):\n    def __init__(self, num_classes=10):\n        super(CustomResNet, self).__init__()\n        self.init_conv = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.init_bn = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.layer1 = self._make_layer(64, 64, 2, stride=1)\n        self.layer2 = self._make_layer(64, 128, 2, stride=2)\n        self.layer3 = self._make_layer(128, 256, 2, stride=2)\n        #self.layer4 = self._make_layer(256, 512, 2, stride=2)\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Linear(256, num_classes)\n\n    def _make_layer(self, in_channels, out_channels, blocks, stride):\n        layers = [ResidualBlock(in_channels, out_channels, stride)]\n        for _ in range(1, blocks):\n            layers.append(ResidualBlock(out_channels, out_channels))\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = self.init_conv(x)\n        out = self.init_bn(out)\n        out = self.relu(out)\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        #out = self.layer4(out)\n        out = self.avg_pool(out)\n        out = torch.flatten(out, 1)\n        out = self.fc(out)\n        return out\n\n# put models to devices (CPU/GPU)\nmodel = CustomResNet().to(device)\n\n# Print the number of parameters\nfrom torchsummary import summary\nsummary(model, (3, 32, 32))\n\n# Train the model\ntrain_model(model, train_loader, val_loader, epochs=50) #change epoch\n\n# Generate submission file\nmodel.eval()\npredictions = []\nwith torch.no_grad():\n    for images in test_loader:\n        images = images.to(device) \n        outputs = model(images) \n        _, predicted = torch.max(outputs, 1)\n        predictions.extend(predicted.cpu().numpy())\n\nsubmission = pd.DataFrame({'ID': np.arange(len(predictions)), 'Labels': predictions})\nsubmission.to_csv('/kaggle/working/submission.csv', index=False)\nprint(\"Submission file saved.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T19:49:10.789247Z","iopub.execute_input":"2025-03-07T19:49:10.789599Z","iopub.status.idle":"2025-03-07T20:14:27.853201Z","shell.execute_reply.started":"2025-03-07T19:49:10.789569Z","shell.execute_reply":"2025-03-07T20:14:27.852226Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1           [-1, 64, 32, 32]           1,728\n       BatchNorm2d-2           [-1, 64, 32, 32]             128\n              ReLU-3           [-1, 64, 32, 32]               0\n            Conv2d-4           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-5           [-1, 64, 32, 32]             128\n              ReLU-6           [-1, 64, 32, 32]               0\n            Conv2d-7           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-8           [-1, 64, 32, 32]             128\n              ReLU-9           [-1, 64, 32, 32]               0\n          Dropout-10           [-1, 64, 32, 32]               0\n    ResidualBlock-11           [-1, 64, 32, 32]               0\n           Conv2d-12           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-13           [-1, 64, 32, 32]             128\n             ReLU-14           [-1, 64, 32, 32]               0\n           Conv2d-15           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-16           [-1, 64, 32, 32]             128\n             ReLU-17           [-1, 64, 32, 32]               0\n          Dropout-18           [-1, 64, 32, 32]               0\n    ResidualBlock-19           [-1, 64, 32, 32]               0\n           Conv2d-20          [-1, 128, 16, 16]           8,192\n      BatchNorm2d-21          [-1, 128, 16, 16]             256\n           Conv2d-22          [-1, 128, 16, 16]          73,728\n      BatchNorm2d-23          [-1, 128, 16, 16]             256\n             ReLU-24          [-1, 128, 16, 16]               0\n           Conv2d-25          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-26          [-1, 128, 16, 16]             256\n             ReLU-27          [-1, 128, 16, 16]               0\n          Dropout-28          [-1, 128, 16, 16]               0\n    ResidualBlock-29          [-1, 128, 16, 16]               0\n           Conv2d-30          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-31          [-1, 128, 16, 16]             256\n             ReLU-32          [-1, 128, 16, 16]               0\n           Conv2d-33          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-34          [-1, 128, 16, 16]             256\n             ReLU-35          [-1, 128, 16, 16]               0\n          Dropout-36          [-1, 128, 16, 16]               0\n    ResidualBlock-37          [-1, 128, 16, 16]               0\n           Conv2d-38            [-1, 256, 8, 8]          32,768\n      BatchNorm2d-39            [-1, 256, 8, 8]             512\n           Conv2d-40            [-1, 256, 8, 8]         294,912\n      BatchNorm2d-41            [-1, 256, 8, 8]             512\n             ReLU-42            [-1, 256, 8, 8]               0\n           Conv2d-43            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-44            [-1, 256, 8, 8]             512\n             ReLU-45            [-1, 256, 8, 8]               0\n          Dropout-46            [-1, 256, 8, 8]               0\n    ResidualBlock-47            [-1, 256, 8, 8]               0\n           Conv2d-48            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-49            [-1, 256, 8, 8]             512\n             ReLU-50            [-1, 256, 8, 8]               0\n           Conv2d-51            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-52            [-1, 256, 8, 8]             512\n             ReLU-53            [-1, 256, 8, 8]               0\n          Dropout-54            [-1, 256, 8, 8]               0\n    ResidualBlock-55            [-1, 256, 8, 8]               0\nAdaptiveAvgPool2d-56            [-1, 256, 1, 1]               0\n           Linear-57                   [-1, 10]           2,570\n================================================================\nTotal params: 2,777,674\nTrainable params: 2,777,674\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.01\nForward/backward pass size (MB): 16.25\nParams size (MB): 10.60\nEstimated Total Size (MB): 26.86\n----------------------------------------------------------------\nEpoch 1, Loss: 1.657223388214003, Validation Accuracy: 42.3%\nEpoch 2, Loss: 1.2464566347612576, Validation Accuracy: 57.32%\nEpoch 3, Loss: 1.0603236811743542, Validation Accuracy: 58.78%\nEpoch 4, Loss: 0.9611738153140653, Validation Accuracy: 64.5%\nEpoch 5, Loss: 0.8776077667081897, Validation Accuracy: 68.96%\nEpoch 6, Loss: 0.78742516040802, Validation Accuracy: 68.86%\nEpoch 7, Loss: 0.7264276770028201, Validation Accuracy: 71.16%\nEpoch 8, Loss: 0.6782141608948057, Validation Accuracy: 72.3%\nEpoch 9, Loss: 0.628741767257452, Validation Accuracy: 69.52%\nEpoch 10, Loss: 0.5921509178693999, Validation Accuracy: 73.18%\nEpoch 11, Loss: 0.5358222852545705, Validation Accuracy: 79.46%\nEpoch 12, Loss: 0.5067505213347349, Validation Accuracy: 76.08%\nEpoch 13, Loss: 0.47802275139838457, Validation Accuracy: 79.7%\nEpoch 14, Loss: 0.44942573542622005, Validation Accuracy: 79.52%\nEpoch 15, Loss: 0.4352059935812246, Validation Accuracy: 81.06%\nEpoch 16, Loss: 0.38639651641080325, Validation Accuracy: 82.0%\nEpoch 17, Loss: 0.3698738943785429, Validation Accuracy: 80.22%\nEpoch 18, Loss: 0.3502491963603957, Validation Accuracy: 80.6%\nEpoch 19, Loss: 0.33369883319193666, Validation Accuracy: 82.68%\nEpoch 20, Loss: 0.31500089646909724, Validation Accuracy: 79.26%\nEpoch 21, Loss: 0.2782999141649766, Validation Accuracy: 81.84%\nEpoch 22, Loss: 0.26801529924639245, Validation Accuracy: 81.34%\nEpoch 23, Loss: 0.2540082957553254, Validation Accuracy: 82.3%\nEpoch 24, Loss: 0.24167638214897702, Validation Accuracy: 81.68%\nEpoch 25, Loss: 0.2286166015546769, Validation Accuracy: 81.5%\nEpoch 26, Loss: 0.2053130837580697, Validation Accuracy: 82.54%\nEpoch 27, Loss: 0.19522569298913534, Validation Accuracy: 83.52%\nEpoch 28, Loss: 0.18016244396990674, Validation Accuracy: 80.88%\nEpoch 29, Loss: 0.1720106811051003, Validation Accuracy: 83.36%\nEpoch 30, Loss: 0.1587991887301376, Validation Accuracy: 82.96%\nEpoch 31, Loss: 0.14587629680648784, Validation Accuracy: 81.66%\nEpoch 32, Loss: 0.13769901663445952, Validation Accuracy: 83.18%\nEpoch 33, Loss: 0.12224215460644866, Validation Accuracy: 83.6%\nEpoch 34, Loss: 0.11657302823468027, Validation Accuracy: 83.64%\nEpoch 35, Loss: 0.11863676029977134, Validation Accuracy: 83.16%\nEpoch 36, Loss: 0.10036949592176825, Validation Accuracy: 83.42%\nEpoch 37, Loss: 0.09207793142625385, Validation Accuracy: 83.96%\nEpoch 38, Loss: 0.08923351612545295, Validation Accuracy: 83.92%\nEpoch 39, Loss: 0.08474760046440431, Validation Accuracy: 84.36%\nEpoch 40, Loss: 0.08124615685929629, Validation Accuracy: 83.62%\nEpoch 41, Loss: 0.07235235937299546, Validation Accuracy: 84.44%\nEpoch 42, Loss: 0.06613991285187447, Validation Accuracy: 84.2%\nEpoch 43, Loss: 0.060954514097168365, Validation Accuracy: 84.34%\nEpoch 44, Loss: 0.06183081408115951, Validation Accuracy: 83.98%\nEpoch 45, Loss: 0.0588498338395518, Validation Accuracy: 84.12%\nEpoch 46, Loss: 0.052254468930186704, Validation Accuracy: 84.1%\nEpoch 47, Loss: 0.04796904092390006, Validation Accuracy: 84.64%\nEpoch 48, Loss: 0.04424152014226737, Validation Accuracy: 83.94%\nEpoch 49, Loss: 0.048263004507382655, Validation Accuracy: 84.68%\nEpoch 50, Loss: 0.044114986931989814, Validation Accuracy: 84.4%\nSubmission file saved.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport pickle\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nfrom torch.utils.data import DataLoader, random_split, TensorDataset\nfrom torch.optim.lr_scheduler import StepLR\nfrom PIL import Image\nimport torch.optim.lr_scheduler as lr_scheduler\n\n# auto. choose CPU or GPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n# Function to load CIFAR-10 dataset\ndef load_cifar_batch(file):\n    with open(file, 'rb') as fo:\n        dict = pickle.load(fo, encoding='bytes')\n    return dict\n\n# Specify the directory containing CIFAR-10 batches\ncifar10_dir = '/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py'\n\n# Load metadata (labels)\nmeta_data_dict = load_cifar_batch(os.path.join(cifar10_dir, 'batches.meta'))\nlabel_names = [label.decode('utf-8') for label in meta_data_dict[b'label_names']]\n\n# Load training data\ntrain_data = []\ntrain_labels = []\nfor i in range(1, 6):\n    batch = load_cifar_batch(os.path.join(cifar10_dir, f'data_batch_{i}'))\n    train_data.append(batch[b'data'])\n    train_labels += batch[b'labels']\n\ntrain_data = np.vstack(train_data).reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)  # Convert to HWC format\ntrain_labels = np.array(train_labels)\n\n# Data augmentation and normalization\ntransform = transforms.Compose([\n    transforms.ToPILImage(),  # Convert numpy array to PIL Image\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(brightness = 0.1,contrast = 0.1,saturation = 0.1),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomAdjustSharpness(sharpness_factor = 2,p = 0.2),\n    transforms.RandomCrop(32, padding=4),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n    transforms.RandomErasing(p=0.2,scale=(0.02, 0.1),value=1.0, inplace=False)\n])\n\n# Convert to TensorDataset and apply transformations\ntrain_dataset = [(transform(img), label) for img, label in zip(train_data, train_labels)]\n\n# Split into training and validation sets\ntrain_size = int(0.9 * len(train_dataset))\nval_size = len(train_dataset) - train_size\ntrain_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n\n# Load test dataset\ncifar_test_path = '/kaggle/input/deep-learning-spring-2025-project-1/cifar_test_nolabel.pkl'\ntest_batch = load_cifar_batch(cifar_test_path)\ntest_images = test_batch[b'data'].astype(np.float32) / 255.0\ntest_images = test_images.reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)  # Convert to HWC format\n\n# Convert test dataset to Tensor\ntest_dataset = [(transform(img)) for img in test_images]\ntest_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4)\n\n# DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=4)\n\n# Train function\ndef train_model(model, train_loader, val_loader, epochs=50):\n    criterion = nn.CrossEntropyLoss()\n    #optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n    optimizer = optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=1e-4) #change lr\n    #scheduler = StepLR(optimizer, step_size=20, gamma=0.1)\n    scheduler = StepLR(optimizer, step_size=6, gamma=0.85)\n\n    \n    for epoch in range(epochs):\n        model.train()\n        running_loss = 0.0\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        \n        model.eval()\n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                _, predicted = torch.max(outputs, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n        \n        scheduler.step()\n        print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}, Validation Accuracy: {100 * correct / total}%')\n\n# Define a custom ResNet model from scratch\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.skip = nn.Sequential()\n        if stride != 1 or in_channels != out_channels:\n            self.skip = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels)\n            )\n        self.dropout = nn.Dropout(0.2)\n    def forward(self, x):\n        identity = x \n        if self.skip:\n            identity = self.skip(x)\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out += identity\n        out = self.relu(out)\n        out = self.dropout(out)\n        return out\n\nclass CustomResNet(nn.Module):\n    def __init__(self, num_classes=10):\n        super(CustomResNet, self).__init__()\n        self.init_conv = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.init_bn = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.layer1 = self._make_layer(64, 64, 2, stride=1)\n        self.layer2 = self._make_layer(64, 128, 2, stride=2)\n        self.layer3 = self._make_layer(128, 256, 2, stride=2)\n        #self.layer4 = self._make_layer(256, 512, 2, stride=2)\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Linear(256, num_classes)\n\n    def _make_layer(self, in_channels, out_channels, blocks, stride):\n        layers = [ResidualBlock(in_channels, out_channels, stride)]\n        for _ in range(1, blocks):\n            layers.append(ResidualBlock(out_channels, out_channels))\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = self.init_conv(x)\n        out = self.init_bn(out)\n        out = self.relu(out)\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        #out = self.layer4(out)\n        out = self.avg_pool(out)\n        out = torch.flatten(out, 1)\n        out = self.fc(out)\n        return out\n\n# put models to devices (CPU/GPU)\nmodel = CustomResNet().to(device)\n\n# Print the number of parameters\nfrom torchsummary import summary\nsummary(model, (3, 32, 32))\n\n# Train the model\ntrain_model(model, train_loader, val_loader, epochs=60) #change epoch\n\n# Generate submission file\nmodel.eval()\npredictions = []\nwith torch.no_grad():\n    for images in test_loader:\n        images = images.to(device) \n        outputs = model(images) \n        _, predicted = torch.max(outputs, 1)\n        predictions.extend(predicted.cpu().numpy())\n\nsubmission = pd.DataFrame({'ID': np.arange(len(predictions)), 'Labels': predictions})\nsubmission.to_csv('/kaggle/working/submission.csv', index=False)\nprint(\"Submission file saved.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T02:09:55.906033Z","iopub.execute_input":"2025-03-08T02:09:55.906291Z","iopub.status.idle":"2025-03-08T02:40:41.585582Z","shell.execute_reply.started":"2025-03-08T02:09:55.906270Z","shell.execute_reply":"2025-03-08T02:40:41.584647Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1           [-1, 64, 32, 32]           1,728\n       BatchNorm2d-2           [-1, 64, 32, 32]             128\n              ReLU-3           [-1, 64, 32, 32]               0\n            Conv2d-4           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-5           [-1, 64, 32, 32]             128\n              ReLU-6           [-1, 64, 32, 32]               0\n            Conv2d-7           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-8           [-1, 64, 32, 32]             128\n              ReLU-9           [-1, 64, 32, 32]               0\n          Dropout-10           [-1, 64, 32, 32]               0\n    ResidualBlock-11           [-1, 64, 32, 32]               0\n           Conv2d-12           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-13           [-1, 64, 32, 32]             128\n             ReLU-14           [-1, 64, 32, 32]               0\n           Conv2d-15           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-16           [-1, 64, 32, 32]             128\n             ReLU-17           [-1, 64, 32, 32]               0\n          Dropout-18           [-1, 64, 32, 32]               0\n    ResidualBlock-19           [-1, 64, 32, 32]               0\n           Conv2d-20          [-1, 128, 16, 16]           8,192\n      BatchNorm2d-21          [-1, 128, 16, 16]             256\n           Conv2d-22          [-1, 128, 16, 16]          73,728\n      BatchNorm2d-23          [-1, 128, 16, 16]             256\n             ReLU-24          [-1, 128, 16, 16]               0\n           Conv2d-25          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-26          [-1, 128, 16, 16]             256\n             ReLU-27          [-1, 128, 16, 16]               0\n          Dropout-28          [-1, 128, 16, 16]               0\n    ResidualBlock-29          [-1, 128, 16, 16]               0\n           Conv2d-30          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-31          [-1, 128, 16, 16]             256\n             ReLU-32          [-1, 128, 16, 16]               0\n           Conv2d-33          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-34          [-1, 128, 16, 16]             256\n             ReLU-35          [-1, 128, 16, 16]               0\n          Dropout-36          [-1, 128, 16, 16]               0\n    ResidualBlock-37          [-1, 128, 16, 16]               0\n           Conv2d-38            [-1, 256, 8, 8]          32,768\n      BatchNorm2d-39            [-1, 256, 8, 8]             512\n           Conv2d-40            [-1, 256, 8, 8]         294,912\n      BatchNorm2d-41            [-1, 256, 8, 8]             512\n             ReLU-42            [-1, 256, 8, 8]               0\n           Conv2d-43            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-44            [-1, 256, 8, 8]             512\n             ReLU-45            [-1, 256, 8, 8]               0\n          Dropout-46            [-1, 256, 8, 8]               0\n    ResidualBlock-47            [-1, 256, 8, 8]               0\n           Conv2d-48            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-49            [-1, 256, 8, 8]             512\n             ReLU-50            [-1, 256, 8, 8]               0\n           Conv2d-51            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-52            [-1, 256, 8, 8]             512\n             ReLU-53            [-1, 256, 8, 8]               0\n          Dropout-54            [-1, 256, 8, 8]               0\n    ResidualBlock-55            [-1, 256, 8, 8]               0\nAdaptiveAvgPool2d-56            [-1, 256, 1, 1]               0\n           Linear-57                   [-1, 10]           2,570\n================================================================\nTotal params: 2,777,674\nTrainable params: 2,777,674\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.01\nForward/backward pass size (MB): 16.25\nParams size (MB): 10.60\nEstimated Total Size (MB): 26.86\n----------------------------------------------------------------\nEpoch 1, Loss: 1.6917069808325984, Validation Accuracy: 34.08%\nEpoch 2, Loss: 1.2979251085357233, Validation Accuracy: 45.94%\nEpoch 3, Loss: 1.116171351379969, Validation Accuracy: 60.84%\nEpoch 4, Loss: 1.005171491171826, Validation Accuracy: 59.16%\nEpoch 5, Loss: 0.9173898871310733, Validation Accuracy: 60.38%\nEpoch 6, Loss: 0.850291170687838, Validation Accuracy: 64.22%\nEpoch 7, Loss: 0.7698902567340569, Validation Accuracy: 71.76%\nEpoch 8, Loss: 0.7202955585989085, Validation Accuracy: 70.58%\nEpoch 9, Loss: 0.6716118664057418, Validation Accuracy: 71.54%\nEpoch 10, Loss: 0.6318089023063128, Validation Accuracy: 72.04%\nEpoch 11, Loss: 0.5937170353294774, Validation Accuracy: 75.2%\nEpoch 12, Loss: 0.5620137284594503, Validation Accuracy: 76.34%\nEpoch 13, Loss: 0.5076698307794604, Validation Accuracy: 77.56%\nEpoch 14, Loss: 0.4837496222250841, Validation Accuracy: 75.9%\nEpoch 15, Loss: 0.46521638096733525, Validation Accuracy: 78.36%\nEpoch 16, Loss: 0.4411487376994707, Validation Accuracy: 77.26%\nEpoch 17, Loss: 0.42337005310268566, Validation Accuracy: 79.1%\nEpoch 18, Loss: 0.403183669783175, Validation Accuracy: 78.98%\nEpoch 19, Loss: 0.3616795588538728, Validation Accuracy: 78.4%\nEpoch 20, Loss: 0.3458691880699586, Validation Accuracy: 79.4%\nEpoch 21, Loss: 0.3305243735878982, Validation Accuracy: 79.48%\nEpoch 22, Loss: 0.32279694512147794, Validation Accuracy: 78.98%\nEpoch 23, Loss: 0.30292088055813854, Validation Accuracy: 80.82%\nEpoch 24, Loss: 0.2931685922667384, Validation Accuracy: 81.82%\nEpoch 25, Loss: 0.26228826818987727, Validation Accuracy: 80.96%\nEpoch 26, Loss: 0.24893946937200698, Validation Accuracy: 81.68%\nEpoch 27, Loss: 0.2392436435488476, Validation Accuracy: 79.48%\nEpoch 28, Loss: 0.22250593860041012, Validation Accuracy: 82.06%\nEpoch 29, Loss: 0.2231236612000926, Validation Accuracy: 81.5%\nEpoch 30, Loss: 0.21159490835006264, Validation Accuracy: 82.24%\nEpoch 31, Loss: 0.1908478740475733, Validation Accuracy: 80.24%\nEpoch 32, Loss: 0.1814391045534814, Validation Accuracy: 82.18%\nEpoch 33, Loss: 0.16682103691114622, Validation Accuracy: 81.84%\nEpoch 34, Loss: 0.15940261661837046, Validation Accuracy: 82.64%\nEpoch 35, Loss: 0.15861541305837984, Validation Accuracy: 82.38%\nEpoch 36, Loss: 0.15001447991976005, Validation Accuracy: 83.36%\nEpoch 37, Loss: 0.1358100228561935, Validation Accuracy: 83.0%\nEpoch 38, Loss: 0.125502562594854, Validation Accuracy: 83.74%\nEpoch 39, Loss: 0.1173468809151514, Validation Accuracy: 83.02%\nEpoch 40, Loss: 0.11333675337532027, Validation Accuracy: 83.06%\nEpoch 41, Loss: 0.11051547509321774, Validation Accuracy: 81.98%\nEpoch 42, Loss: 0.1086686283603988, Validation Accuracy: 83.12%\nEpoch 43, Loss: 0.0954762495927174, Validation Accuracy: 83.26%\nEpoch 44, Loss: 0.09137335666772825, Validation Accuracy: 83.6%\nEpoch 45, Loss: 0.08669021602360193, Validation Accuracy: 82.94%\nEpoch 46, Loss: 0.08579275049057535, Validation Accuracy: 83.32%\nEpoch 47, Loss: 0.08365050410132178, Validation Accuracy: 82.98%\nEpoch 48, Loss: 0.08122781177040782, Validation Accuracy: 83.66%\nEpoch 49, Loss: 0.06859283049231056, Validation Accuracy: 83.68%\nEpoch 50, Loss: 0.06620243052020669, Validation Accuracy: 84.44%\nEpoch 51, Loss: 0.06341531299668449, Validation Accuracy: 83.8%\nEpoch 52, Loss: 0.061345546442846004, Validation Accuracy: 83.82%\nEpoch 53, Loss: 0.06106833738423037, Validation Accuracy: 83.78%\nEpoch 54, Loss: 0.060706087917258796, Validation Accuracy: 83.56%\nEpoch 55, Loss: 0.052226290815848515, Validation Accuracy: 83.8%\nEpoch 56, Loss: 0.05159541199100204, Validation Accuracy: 83.2%\nEpoch 57, Loss: 0.04859542947484773, Validation Accuracy: 84.28%\nEpoch 58, Loss: 0.048066657237623905, Validation Accuracy: 84.26%\nEpoch 59, Loss: 0.05064280980943956, Validation Accuracy: 84.06%\nEpoch 60, Loss: 0.04693444130614146, Validation Accuracy: 83.98%\nSubmission file saved.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport pickle\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nfrom torch.utils.data import DataLoader, random_split, TensorDataset\nfrom torch.optim.lr_scheduler import StepLR\nfrom PIL import Image\nimport torch.optim.lr_scheduler as lr_scheduler\n\n# auto. choose CPU or GPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n# Function to load CIFAR-10 dataset\ndef load_cifar_batch(file):\n    with open(file, 'rb') as fo:\n        dict = pickle.load(fo, encoding='bytes')\n    return dict\n\n# Specify the directory containing CIFAR-10 batches\ncifar10_dir = '/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py'\n\n# Load metadata (labels)\nmeta_data_dict = load_cifar_batch(os.path.join(cifar10_dir, 'batches.meta'))\nlabel_names = [label.decode('utf-8') for label in meta_data_dict[b'label_names']]\n\n# Load training data\ntrain_data = []\ntrain_labels = []\nfor i in range(1, 6):\n    batch = load_cifar_batch(os.path.join(cifar10_dir, f'data_batch_{i}'))\n    train_data.append(batch[b'data'])\n    train_labels += batch[b'labels']\n\ntrain_data = np.vstack(train_data).reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)  # Convert to HWC format\ntrain_labels = np.array(train_labels)\n\n# Data augmentation and normalization\ntransform = transforms.Compose([\n    transforms.ToPILImage(),  # Convert numpy array to PIL Image\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(brightness = 0.1,contrast = 0.1,saturation = 0.1),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomAdjustSharpness(sharpness_factor = 2,p = 0.2),\n    transforms.RandomCrop(32, padding=4),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n    transforms.RandomErasing(p=0.2,scale=(0.02, 0.1),value=1.0, inplace=False)\n])\n\n# Convert to TensorDataset and apply transformations\nclass CustomCIFAR10Dataset(torch.utils.data.Dataset):\n    def __init__(self, images, labels, transform=None):\n        self.images = images\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        img = self.images[idx]\n        label = self.labels[idx]\n\n        if self.transform:\n            img = self.transform(img)\n\n        return img, label\n\ntrain_dataset = CustomCIFAR10Dataset(train_data, train_labels, transform=transform)\n\n# Split into training and validation sets\ntrain_size = int(0.9 * len(train_dataset))\nval_size = len(train_dataset) - train_size\ntrain_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n\n\n# DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=4)\n\n# Train function\ndef train_model(model, train_loader, val_loader, epochs=50):\n    criterion = nn.CrossEntropyLoss()\n    #optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n    optimizer = optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=1e-4) #change lr\n    #scheduler = StepLR(optimizer, step_size=20, gamma=0.1)\n    scheduler = StepLR(optimizer, step_size=6, gamma=0.85)\n\n    \n    for epoch in range(epochs):\n        model.train()\n        running_loss = 0.0\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        \n        model.eval()\n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                _, predicted = torch.max(outputs, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n        \n        scheduler.step()\n        print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}, Validation Accuracy: {100 * correct / total}%')\n\n# Define a custom ResNet model from scratch\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.skip = nn.Sequential()\n        if stride != 1 or in_channels != out_channels:\n            self.skip = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels)\n            )\n    def forward(self, x):\n        identity = x \n        if self.skip:\n            identity = self.skip(x)\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out += identity\n        out = self.relu(out)\n        return out\n\nclass CustomResNet(nn.Module):\n    def __init__(self, num_classes=10):\n        super(CustomResNet, self).__init__()\n        self.init_conv = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.init_bn = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.layer1 = self._make_layer(64, 64, 2, stride=1)\n        self.layer2 = self._make_layer(64, 128, 2, stride=2)\n        self.layer3 = self._make_layer(128, 256, 2, stride=2)\n        #self.layer4 = self._make_layer(256, 512, 2, stride=2)\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Linear(256, num_classes)\n\n    def _make_layer(self, in_channels, out_channels, blocks, stride):\n        layers = [ResidualBlock(in_channels, out_channels, stride)]\n        for _ in range(1, blocks):\n            layers.append(ResidualBlock(out_channels, out_channels))\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = self.init_conv(x)\n        out = self.init_bn(out)\n        out = self.relu(out)\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        #out = self.layer4(out)\n        out = self.avg_pool(out)\n        out = torch.flatten(out, 1)\n        out = self.fc(out)\n        return out\n\n# put models to devices (CPU/GPU)\nmodel = CustomResNet().to(device)\n\n# Print the number of parameters\nfrom torchsummary import summary\nsummary(model, (3, 32, 32))\n\n# Train the model\ntrain_model(model, train_loader, val_loader, epochs=100) #change epoch\n\n# Generate submission file\nmodel.eval()\npredictions = []\nwith torch.no_grad():\n    for images in test_loader:\n        images = images.to(device) \n        outputs = model(images) \n        _, predicted = torch.max(outputs, 1)\n        predictions.extend(predicted.cpu().numpy())\n\nsubmission = pd.DataFrame({'ID': np.arange(len(predictions)), 'Labels': predictions})\nsubmission.to_csv('/kaggle/working/submission5.csv', index=False)\nprint(\"Submission5 file saved.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T03:50:10.025207Z","iopub.execute_input":"2025-03-08T03:50:10.025449Z","iopub.status.idle":"2025-03-08T04:41:35.231672Z","shell.execute_reply.started":"2025-03-08T03:50:10.025420Z","shell.execute_reply":"2025-03-08T04:41:35.230751Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1           [-1, 64, 32, 32]           1,728\n       BatchNorm2d-2           [-1, 64, 32, 32]             128\n              ReLU-3           [-1, 64, 32, 32]               0\n            Conv2d-4           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-5           [-1, 64, 32, 32]             128\n              ReLU-6           [-1, 64, 32, 32]               0\n            Conv2d-7           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-8           [-1, 64, 32, 32]             128\n              ReLU-9           [-1, 64, 32, 32]               0\n    ResidualBlock-10           [-1, 64, 32, 32]               0\n           Conv2d-11           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-12           [-1, 64, 32, 32]             128\n             ReLU-13           [-1, 64, 32, 32]               0\n           Conv2d-14           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-15           [-1, 64, 32, 32]             128\n             ReLU-16           [-1, 64, 32, 32]               0\n    ResidualBlock-17           [-1, 64, 32, 32]               0\n           Conv2d-18          [-1, 128, 16, 16]           8,192\n      BatchNorm2d-19          [-1, 128, 16, 16]             256\n           Conv2d-20          [-1, 128, 16, 16]          73,728\n      BatchNorm2d-21          [-1, 128, 16, 16]             256\n             ReLU-22          [-1, 128, 16, 16]               0\n           Conv2d-23          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-24          [-1, 128, 16, 16]             256\n             ReLU-25          [-1, 128, 16, 16]               0\n    ResidualBlock-26          [-1, 128, 16, 16]               0\n           Conv2d-27          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-28          [-1, 128, 16, 16]             256\n             ReLU-29          [-1, 128, 16, 16]               0\n           Conv2d-30          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-31          [-1, 128, 16, 16]             256\n             ReLU-32          [-1, 128, 16, 16]               0\n    ResidualBlock-33          [-1, 128, 16, 16]               0\n           Conv2d-34            [-1, 256, 8, 8]          32,768\n      BatchNorm2d-35            [-1, 256, 8, 8]             512\n           Conv2d-36            [-1, 256, 8, 8]         294,912\n      BatchNorm2d-37            [-1, 256, 8, 8]             512\n             ReLU-38            [-1, 256, 8, 8]               0\n           Conv2d-39            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-40            [-1, 256, 8, 8]             512\n             ReLU-41            [-1, 256, 8, 8]               0\n    ResidualBlock-42            [-1, 256, 8, 8]               0\n           Conv2d-43            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-44            [-1, 256, 8, 8]             512\n             ReLU-45            [-1, 256, 8, 8]               0\n           Conv2d-46            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-47            [-1, 256, 8, 8]             512\n             ReLU-48            [-1, 256, 8, 8]               0\n    ResidualBlock-49            [-1, 256, 8, 8]               0\nAdaptiveAvgPool2d-50            [-1, 256, 1, 1]               0\n           Linear-51                   [-1, 10]           2,570\n================================================================\nTotal params: 2,777,674\nTrainable params: 2,777,674\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.01\nForward/backward pass size (MB): 14.50\nParams size (MB): 10.60\nEstimated Total Size (MB): 25.11\n----------------------------------------------------------------\nEpoch 1, Loss: 1.5255745337768034, Validation Accuracy: 53.66%\nEpoch 2, Loss: 1.0948304528878494, Validation Accuracy: 62.26%\nEpoch 3, Loss: 0.9233855046331882, Validation Accuracy: 57.36%\nEpoch 4, Loss: 0.7946755984290079, Validation Accuracy: 70.42%\nEpoch 5, Loss: 0.7180077467452396, Validation Accuracy: 72.44%\nEpoch 6, Loss: 0.6524822569706223, Validation Accuracy: 70.44%\nEpoch 7, Loss: 0.5862917062741789, Validation Accuracy: 76.98%\nEpoch 8, Loss: 0.5530197308822111, Validation Accuracy: 77.06%\nEpoch 9, Loss: 0.5219151099127802, Validation Accuracy: 77.58%\nEpoch 10, Loss: 0.49989096667956223, Validation Accuracy: 78.54%\nEpoch 11, Loss: 0.4748129586435177, Validation Accuracy: 78.7%\nEpoch 12, Loss: 0.4517356561158191, Validation Accuracy: 79.5%\nEpoch 13, Loss: 0.4117726438086141, Validation Accuracy: 79.42%\nEpoch 14, Loss: 0.39587457685477356, Validation Accuracy: 81.14%\nEpoch 15, Loss: 0.3853813525373963, Validation Accuracy: 83.22%\nEpoch 16, Loss: 0.37577930169010704, Validation Accuracy: 80.44%\nEpoch 17, Loss: 0.36114483775401657, Validation Accuracy: 81.86%\nEpoch 18, Loss: 0.34856700084426184, Validation Accuracy: 83.04%\nEpoch 19, Loss: 0.32419105839322915, Validation Accuracy: 82.68%\nEpoch 20, Loss: 0.3139622245322574, Validation Accuracy: 84.0%\nEpoch 21, Loss: 0.2982900953343646, Validation Accuracy: 83.38%\nEpoch 22, Loss: 0.29792934469878674, Validation Accuracy: 83.98%\nEpoch 23, Loss: 0.28465583827346563, Validation Accuracy: 85.24%\nEpoch 24, Loss: 0.2795550227588551, Validation Accuracy: 84.9%\nEpoch 25, Loss: 0.25990187795832753, Validation Accuracy: 86.14%\nEpoch 26, Loss: 0.25364880371754145, Validation Accuracy: 86.2%\nEpoch 27, Loss: 0.24502912432547996, Validation Accuracy: 86.34%\nEpoch 28, Loss: 0.24097872265106576, Validation Accuracy: 86.7%\nEpoch 29, Loss: 0.2300427019045773, Validation Accuracy: 85.68%\nEpoch 30, Loss: 0.2259104366371916, Validation Accuracy: 86.48%\nEpoch 31, Loss: 0.21023500848307528, Validation Accuracy: 86.98%\nEpoch 32, Loss: 0.20270562972026793, Validation Accuracy: 86.94%\nEpoch 33, Loss: 0.20137914270162582, Validation Accuracy: 87.72%\nEpoch 34, Loss: 0.20093251258896833, Validation Accuracy: 87.98%\nEpoch 35, Loss: 0.19494621302212842, Validation Accuracy: 87.96%\nEpoch 36, Loss: 0.188317603579807, Validation Accuracy: 87.34%\nEpoch 37, Loss: 0.17688028065657074, Validation Accuracy: 88.24%\nEpoch 38, Loss: 0.17147486517205834, Validation Accuracy: 87.26%\nEpoch 39, Loss: 0.16543875814584846, Validation Accuracy: 87.88%\nEpoch 40, Loss: 0.16272688259116627, Validation Accuracy: 87.3%\nEpoch 41, Loss: 0.15948953388512813, Validation Accuracy: 88.2%\nEpoch 42, Loss: 0.15843320939562877, Validation Accuracy: 88.5%\nEpoch 43, Loss: 0.14391737391071563, Validation Accuracy: 88.42%\nEpoch 44, Loss: 0.13623822603205388, Validation Accuracy: 89.8%\nEpoch 45, Loss: 0.13974302969026295, Validation Accuracy: 88.64%\nEpoch 46, Loss: 0.13723468709610065, Validation Accuracy: 88.4%\nEpoch 47, Loss: 0.13559760567097162, Validation Accuracy: 88.92%\nEpoch 48, Loss: 0.13151080793150785, Validation Accuracy: 88.8%\nEpoch 49, Loss: 0.1241275769425556, Validation Accuracy: 89.22%\nEpoch 50, Loss: 0.11822589464612644, Validation Accuracy: 88.82%\nEpoch 51, Loss: 0.11749835266858678, Validation Accuracy: 89.2%\nEpoch 52, Loss: 0.11680140767500481, Validation Accuracy: 89.44%\nEpoch 53, Loss: 0.11501438335769555, Validation Accuracy: 89.3%\nEpoch 54, Loss: 0.11160370149776679, Validation Accuracy: 89.12%\nEpoch 55, Loss: 0.10455937211041931, Validation Accuracy: 89.2%\nEpoch 56, Loss: 0.1004822257885032, Validation Accuracy: 89.92%\nEpoch 57, Loss: 0.09845275317043574, Validation Accuracy: 89.36%\nEpoch 58, Loss: 0.0967973963548006, Validation Accuracy: 89.18%\nEpoch 59, Loss: 0.09813303893051026, Validation Accuracy: 89.84%\nEpoch 60, Loss: 0.0952719309346073, Validation Accuracy: 89.36%\nEpoch 61, Loss: 0.09072238010015678, Validation Accuracy: 89.78%\nEpoch 62, Loss: 0.0872938798433593, Validation Accuracy: 90.58%\nEpoch 63, Loss: 0.08533819249979305, Validation Accuracy: 90.2%\nEpoch 64, Loss: 0.0844625953362662, Validation Accuracy: 89.72%\nEpoch 65, Loss: 0.08294726942602376, Validation Accuracy: 89.14%\nEpoch 66, Loss: 0.08096252001335168, Validation Accuracy: 89.56%\nEpoch 67, Loss: 0.07657990261213854, Validation Accuracy: 89.76%\nEpoch 68, Loss: 0.07637999415535225, Validation Accuracy: 89.44%\nEpoch 69, Loss: 0.07673580713294954, Validation Accuracy: 89.22%\nEpoch 70, Loss: 0.07383510175647891, Validation Accuracy: 90.04%\nEpoch 71, Loss: 0.07569344933356413, Validation Accuracy: 89.9%\nEpoch 72, Loss: 0.06788232805080373, Validation Accuracy: 89.92%\nEpoch 73, Loss: 0.06945793398401955, Validation Accuracy: 90.46%\nEpoch 74, Loss: 0.06748457749596458, Validation Accuracy: 90.44%\nEpoch 75, Loss: 0.06593705633845688, Validation Accuracy: 90.16%\nEpoch 76, Loss: 0.06588436900214716, Validation Accuracy: 90.02%\nEpoch 77, Loss: 0.06747206186727536, Validation Accuracy: 90.48%\nEpoch 78, Loss: 0.06504884564360096, Validation Accuracy: 90.34%\nEpoch 79, Loss: 0.061164861338594084, Validation Accuracy: 90.34%\nEpoch 80, Loss: 0.05958660485339351, Validation Accuracy: 90.6%\nEpoch 81, Loss: 0.0616973293627697, Validation Accuracy: 90.6%\nEpoch 82, Loss: 0.058463676110312175, Validation Accuracy: 89.88%\nEpoch 83, Loss: 0.05574937804538587, Validation Accuracy: 90.56%\nEpoch 84, Loss: 0.05746401146990882, Validation Accuracy: 90.1%\nEpoch 85, Loss: 0.05498542347711257, Validation Accuracy: 90.4%\nEpoch 86, Loss: 0.053870947761672804, Validation Accuracy: 90.6%\nEpoch 87, Loss: 0.05422522172077813, Validation Accuracy: 91.04%\nEpoch 88, Loss: 0.053297343976076016, Validation Accuracy: 90.42%\nEpoch 89, Loss: 0.05194112691308626, Validation Accuracy: 90.94%\nEpoch 90, Loss: 0.054866828098469836, Validation Accuracy: 90.56%\nEpoch 91, Loss: 0.0534616528999653, Validation Accuracy: 90.68%\nEpoch 92, Loss: 0.05137550041333518, Validation Accuracy: 90.56%\nEpoch 93, Loss: 0.04761119219156998, Validation Accuracy: 90.76%\nEpoch 94, Loss: 0.05290341880754568, Validation Accuracy: 90.16%\nEpoch 95, Loss: 0.0502850328550928, Validation Accuracy: 90.44%\nEpoch 96, Loss: 0.049219420362285084, Validation Accuracy: 91.06%\nEpoch 97, Loss: 0.046515556872526016, Validation Accuracy: 90.32%\nEpoch 98, Loss: 0.04612135888204317, Validation Accuracy: 90.72%\nEpoch 99, Loss: 0.04823904264379631, Validation Accuracy: 91.1%\nEpoch 100, Loss: 0.04549937967253341, Validation Accuracy: 90.36%\nSubmission file saved.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pickle\nimport numpy as np\nimport torch\nimport pandas as pd\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\n\ndef load_cifar_batch(file):\n    with open(file, 'rb') as fo:\n        data_dict = pickle.load(fo, encoding='bytes')\n    return data_dict\n\n\ncifar_test_path = '/kaggle/input/deep-learning-spring-2025-project-1/cifar_test_nolabel.pkl'\ntest_batch = load_cifar_batch(cifar_test_path)\n\n# Convert images to tensor\nimages_tensor = torch.tensor(cifar10_batch[b'data'], dtype=torch.float32)\n\n# If you want to normalize the images (standard CIFAR-10 preprocessing)\ntest_images = images_tensor / 255.0\n\ntest_loader = DataLoader(test_images, batch_size=128, shuffle=False, num_workers=4)\n\n# Assuming 'model' is a pre-trained model and 'device' is defined (e.g., 'cuda' or 'cpu')\nmodel.eval()  # Set the model to evaluation mode\nmodel.to(device)  # Make sure the model is on the correct device\n\n# List to store predictions\npredictions = []\n\n# Make predictions without gradient calculation\nwith torch.no_grad():\n    for batch in test_loader:\n        batch = batch[0].to(device)  # Move batch to the correct device (GPU/CPU)\n        outputs = model(batch)  # Get model predictions\n        _, predicted = torch.max(outputs, 1)  # Get the predicted class\n        predictions.extend(predicted.cpu().numpy())  # Store predictions\n\n# Create a DataFrame for submission\nsubmission = pd.DataFrame({'ID': np.arange(len(predictions)), 'Labels': predictions})\n\n# Save the submission file\nsubmission.to_csv('submission2.csv', index=False)\nprint(\"Submission2 file saved.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T04:58:36.054740Z","iopub.execute_input":"2025-03-08T04:58:36.055017Z","iopub.status.idle":"2025-03-08T04:58:38.730949Z","shell.execute_reply.started":"2025-03-08T04:58:36.054996Z","shell.execute_reply":"2025-03-08T04:58:38.730005Z"}},"outputs":[{"name":"stdout","text":"Submission2 file saved.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport pickle\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nfrom torch.utils.data import DataLoader, random_split, TensorDataset\nfrom torch.optim.lr_scheduler import StepLR\nfrom PIL import Image\nimport torch.optim.lr_scheduler as lr_scheduler\n\n# auto. choose CPU or GPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n# Function to load CIFAR-10 dataset\ndef load_cifar_batch(file):\n    with open(file, 'rb') as fo:\n        dict = pickle.load(fo, encoding='bytes')\n    return dict\n\n# Specify the directory containing CIFAR-10 batches\ncifar10_dir = '/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py'\n\n# Load metadata (labels)\nmeta_data_dict = load_cifar_batch(os.path.join(cifar10_dir, 'batches.meta'))\nlabel_names = [label.decode('utf-8') for label in meta_data_dict[b'label_names']]\n\n# Load training data\ntrain_data = []\ntrain_labels = []\nfor i in range(1, 6):\n    batch = load_cifar_batch(os.path.join(cifar10_dir, f'data_batch_{i}'))\n    train_data.append(batch[b'data'])\n    train_labels += batch[b'labels']\n\ntrain_data = np.vstack(train_data).reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)  # Convert to HWC format\ntrain_labels = np.array(train_labels)\n\n# Data augmentation and normalization\ntransform = transforms.Compose([\n    transforms.ToPILImage(),  # Convert numpy array to PIL Image\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(brightness = 0.1,contrast = 0.1,saturation = 0.1),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomAdjustSharpness(sharpness_factor = 2,p = 0.2),\n    transforms.RandomCrop(32, padding=4),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n    transforms.RandomErasing(p=0.2,scale=(0.02, 0.1),value=1.0, inplace=False)\n])\n\n# Convert to TensorDataset and apply transformations\ntrain_dataset = [(transform(img), label) for img, label in zip(train_data, train_labels)]\n\n# Split into training and validation sets\ntrain_size = int(0.9 * len(train_dataset))\nval_size = len(train_dataset) - train_size\ntrain_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n\n# Load test dataset\ncifar_test_path = '/kaggle/input/deep-learning-spring-2025-project-1/cifar_test_nolabel.pkl'\ntest_batch = load_cifar_batch(cifar_test_path)\ntest_images = test_batch[b'data'].astype(np.float32) / 255.0\n\n# Convert test dataset to Tensor\ntest_dataset = [(transform(img),) for img in test_images]\ntest_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4)\n\n# DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=4)\n\n# Train function\ndef train_model(model, train_loader, val_loader, epochs=50):\n    criterion = nn.CrossEntropyLoss()\n    #optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n    optimizer = optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=1e-4) #change lr\n    #scheduler = StepLR(optimizer, step_size=20, gamma=0.1)\n    scheduler = StepLR(optimizer, step_size=6, gamma=0.85)\n\n    \n    for epoch in range(epochs):\n        model.train()\n        running_loss = 0.0\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        \n        model.eval()\n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                _, predicted = torch.max(outputs, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n        \n        scheduler.step()\n        print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}, Validation Accuracy: {100 * correct / total}%')\n\n# Define a custom ResNet model from scratch\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.skip = nn.Sequential()\n        if stride != 1 or in_channels != out_channels:\n            self.skip = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels)\n            )\n        self.dropout = nn.Dropout(0.2)\n    def forward(self, x):\n        identity = x \n        if self.skip:\n            identity = self.skip(x)\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out += identity\n        out = self.relu(out)\n        out = self.dropout(out)\n        return out\n\nclass CustomResNet(nn.Module):\n    def __init__(self, num_classes=10):\n        super(CustomResNet, self).__init__()\n        self.init_conv = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.init_bn = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.layer1 = self._make_layer(64, 64, 2, stride=1)\n        self.layer2 = self._make_layer(64, 128, 2, stride=2)\n        self.layer3 = self._make_layer(128, 256, 2, stride=2)\n        #self.layer4 = self._make_layer(256, 512, 2, stride=2)\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Linear(256, num_classes)\n\n    def _make_layer(self, in_channels, out_channels, blocks, stride):\n        layers = [ResidualBlock(in_channels, out_channels, stride)]\n        for _ in range(1, blocks):\n            layers.append(ResidualBlock(out_channels, out_channels))\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = self.init_conv(x)\n        out = self.init_bn(out)\n        out = self.relu(out)\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        #out = self.layer4(out)\n        out = self.avg_pool(out)\n        out = torch.flatten(out, 1)\n        out = self.fc(out)\n        return out\n\n# put models to devices (CPU/GPU)\nmodel = CustomResNet().to(device)\n\n# Print the number of parameters\nfrom torchsummary import summary\nsummary(model, (3, 32, 32))\n\n# Train the model\ntrain_model(model, train_loader, val_loader, epochs=60) #change epoch\n\n# Generate submission file\nmodel.eval()\npredictions = []\nwith torch.no_grad():\n    for images in test_loader:\n        images = images.to(device) \n        outputs = model(images) \n        _, predicted = torch.max(outputs, 1)\n        predictions.extend(predicted.cpu().numpy())\n\nsubmission = pd.DataFrame({'ID': np.arange(len(predictions)), 'Labels': predictions})\nsubmission.to_csv('/kaggle/working/submission.csv', index=False)\nprint(\"Submission file saved.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T06:49:16.714185Z","iopub.execute_input":"2025-03-08T06:49:16.714420Z","iopub.status.idle":"2025-03-08T07:20:07.868213Z","shell.execute_reply.started":"2025-03-08T06:49:16.714399Z","shell.execute_reply":"2025-03-08T07:20:07.866850Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1           [-1, 64, 32, 32]           1,728\n       BatchNorm2d-2           [-1, 64, 32, 32]             128\n              ReLU-3           [-1, 64, 32, 32]               0\n            Conv2d-4           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-5           [-1, 64, 32, 32]             128\n              ReLU-6           [-1, 64, 32, 32]               0\n            Conv2d-7           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-8           [-1, 64, 32, 32]             128\n              ReLU-9           [-1, 64, 32, 32]               0\n          Dropout-10           [-1, 64, 32, 32]               0\n    ResidualBlock-11           [-1, 64, 32, 32]               0\n           Conv2d-12           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-13           [-1, 64, 32, 32]             128\n             ReLU-14           [-1, 64, 32, 32]               0\n           Conv2d-15           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-16           [-1, 64, 32, 32]             128\n             ReLU-17           [-1, 64, 32, 32]               0\n          Dropout-18           [-1, 64, 32, 32]               0\n    ResidualBlock-19           [-1, 64, 32, 32]               0\n           Conv2d-20          [-1, 128, 16, 16]           8,192\n      BatchNorm2d-21          [-1, 128, 16, 16]             256\n           Conv2d-22          [-1, 128, 16, 16]          73,728\n      BatchNorm2d-23          [-1, 128, 16, 16]             256\n             ReLU-24          [-1, 128, 16, 16]               0\n           Conv2d-25          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-26          [-1, 128, 16, 16]             256\n             ReLU-27          [-1, 128, 16, 16]               0\n          Dropout-28          [-1, 128, 16, 16]               0\n    ResidualBlock-29          [-1, 128, 16, 16]               0\n           Conv2d-30          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-31          [-1, 128, 16, 16]             256\n             ReLU-32          [-1, 128, 16, 16]               0\n           Conv2d-33          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-34          [-1, 128, 16, 16]             256\n             ReLU-35          [-1, 128, 16, 16]               0\n          Dropout-36          [-1, 128, 16, 16]               0\n    ResidualBlock-37          [-1, 128, 16, 16]               0\n           Conv2d-38            [-1, 256, 8, 8]          32,768\n      BatchNorm2d-39            [-1, 256, 8, 8]             512\n           Conv2d-40            [-1, 256, 8, 8]         294,912\n      BatchNorm2d-41            [-1, 256, 8, 8]             512\n             ReLU-42            [-1, 256, 8, 8]               0\n           Conv2d-43            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-44            [-1, 256, 8, 8]             512\n             ReLU-45            [-1, 256, 8, 8]               0\n          Dropout-46            [-1, 256, 8, 8]               0\n    ResidualBlock-47            [-1, 256, 8, 8]               0\n           Conv2d-48            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-49            [-1, 256, 8, 8]             512\n             ReLU-50            [-1, 256, 8, 8]               0\n           Conv2d-51            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-52            [-1, 256, 8, 8]             512\n             ReLU-53            [-1, 256, 8, 8]               0\n          Dropout-54            [-1, 256, 8, 8]               0\n    ResidualBlock-55            [-1, 256, 8, 8]               0\nAdaptiveAvgPool2d-56            [-1, 256, 1, 1]               0\n           Linear-57                   [-1, 10]           2,570\n================================================================\nTotal params: 2,777,674\nTrainable params: 2,777,674\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.01\nForward/backward pass size (MB): 16.25\nParams size (MB): 10.60\nEstimated Total Size (MB): 26.86\n----------------------------------------------------------------\nEpoch 1, Loss: 1.7021183676340363, Validation Accuracy: 35.7%\nEpoch 2, Loss: 1.3191534863276915, Validation Accuracy: 51.42%\nEpoch 3, Loss: 1.123914555392482, Validation Accuracy: 54.54%\nEpoch 4, Loss: 1.0012829205529257, Validation Accuracy: 63.18%\nEpoch 5, Loss: 0.9280367681587284, Validation Accuracy: 67.78%\nEpoch 6, Loss: 0.8451592356643893, Validation Accuracy: 67.76%\nEpoch 7, Loss: 0.7677254373715683, Validation Accuracy: 72.6%\nEpoch 8, Loss: 0.7139884257181124, Validation Accuracy: 72.4%\nEpoch 9, Loss: 0.6706722775812853, Validation Accuracy: 74.0%\nEpoch 10, Loss: 0.6343455393375321, Validation Accuracy: 74.78%\nEpoch 11, Loss: 0.5915310001847419, Validation Accuracy: 75.42%\nEpoch 12, Loss: 0.5577216578478162, Validation Accuracy: 75.06%\nEpoch 13, Loss: 0.5165264749560844, Validation Accuracy: 72.98%\nEpoch 14, Loss: 0.4896320023319938, Validation Accuracy: 75.54%\nEpoch 15, Loss: 0.4702526434240016, Validation Accuracy: 79.72%\nEpoch 16, Loss: 0.44726684143428097, Validation Accuracy: 77.26%\nEpoch 17, Loss: 0.4250308254903013, Validation Accuracy: 80.04%\nEpoch 18, Loss: 0.40426264703273773, Validation Accuracy: 81.9%\nEpoch 19, Loss: 0.3752353383990174, Validation Accuracy: 78.88%\nEpoch 20, Loss: 0.35312141287563875, Validation Accuracy: 80.36%\nEpoch 21, Loss: 0.3334408156912435, Validation Accuracy: 82.22%\nEpoch 22, Loss: 0.3182243673046204, Validation Accuracy: 81.62%\nEpoch 23, Loss: 0.308888693805784, Validation Accuracy: 82.34%\nEpoch 24, Loss: 0.29563361537558114, Validation Accuracy: 81.58%\nEpoch 25, Loss: 0.26813657230443577, Validation Accuracy: 82.8%\nEpoch 26, Loss: 0.25600621006874874, Validation Accuracy: 82.9%\nEpoch 27, Loss: 0.2425150727556849, Validation Accuracy: 82.2%\nEpoch 28, Loss: 0.23322178319689224, Validation Accuracy: 83.68%\nEpoch 29, Loss: 0.22460863760418512, Validation Accuracy: 83.1%\nEpoch 30, Loss: 0.21156909805722535, Validation Accuracy: 83.06%\nEpoch 31, Loss: 0.19208353383212604, Validation Accuracy: 83.14%\nEpoch 32, Loss: 0.17759085692126642, Validation Accuracy: 82.38%\nEpoch 33, Loss: 0.17393732288937, Validation Accuracy: 82.96%\nEpoch 34, Loss: 0.16552904102189298, Validation Accuracy: 83.54%\nEpoch 35, Loss: 0.16109830524179747, Validation Accuracy: 83.26%\nEpoch 36, Loss: 0.1545715245143087, Validation Accuracy: 82.42%\nEpoch 37, Loss: 0.1361350511645221, Validation Accuracy: 82.76%\nEpoch 38, Loss: 0.1278444253416224, Validation Accuracy: 83.88%\nEpoch 39, Loss: 0.1218289898771962, Validation Accuracy: 83.46%\nEpoch 40, Loss: 0.11824916137001393, Validation Accuracy: 83.26%\nEpoch 41, Loss: 0.11205788609169592, Validation Accuracy: 83.96%\nEpoch 42, Loss: 0.10629402030661533, Validation Accuracy: 83.32%\nEpoch 43, Loss: 0.09579306510700421, Validation Accuracy: 84.14%\nEpoch 44, Loss: 0.09312047238927335, Validation Accuracy: 84.32%\nEpoch 45, Loss: 0.0886191401778805, Validation Accuracy: 84.04%\nEpoch 46, Loss: 0.08504824390084567, Validation Accuracy: 83.6%\nEpoch 47, Loss: 0.08258939035956493, Validation Accuracy: 84.56%\nEpoch 48, Loss: 0.07972325661896983, Validation Accuracy: 84.54%\nEpoch 49, Loss: 0.07221400828778067, Validation Accuracy: 84.68%\nEpoch 50, Loss: 0.07081703801470046, Validation Accuracy: 84.78%\nEpoch 51, Loss: 0.06436086832863194, Validation Accuracy: 84.54%\nEpoch 52, Loss: 0.06021601762834259, Validation Accuracy: 84.56%\nEpoch 53, Loss: 0.06290865828685294, Validation Accuracy: 84.32%\nEpoch 54, Loss: 0.05836971589120698, Validation Accuracy: 84.7%\nEpoch 55, Loss: 0.05258105796052736, Validation Accuracy: 84.96%\nEpoch 56, Loss: 0.05002638829120604, Validation Accuracy: 84.9%\nEpoch 57, Loss: 0.04844333650808866, Validation Accuracy: 85.42%\nEpoch 58, Loss: 0.0478700923373584, Validation Accuracy: 84.92%\nEpoch 59, Loss: 0.044512418789302254, Validation Accuracy: 85.46%\nEpoch 60, Loss: 0.0450647658567918, Validation Accuracy: 85.04%\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-2f5e50c3479b>\u001b[0m in \u001b[0;36m<cell line: 187>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'to'"],"ename":"AttributeError","evalue":"'list' object has no attribute 'to'","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"model.eval()\npredictions = []\nwith torch.no_grad():\n    for batch in test_loader:\n        images = batch[0].to(device)  # Get images tensor from tuple and move to device\n        outputs = model(images) \n        _, predicted = torch.max(outputs, 1)\n        predictions.extend(predicted.cpu().numpy())\n\n# Generate submission file\nsubmission = pd.DataFrame({'ID': np.arange(len(predictions)), 'Labels': predictions})\nsubmission.to_csv('/kaggle/working/submission.csv', index=False)\nprint(\"Submission file saved.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T07:21:25.589077Z","iopub.execute_input":"2025-03-08T07:21:25.589463Z","iopub.status.idle":"2025-03-08T07:21:27.747636Z","shell.execute_reply.started":"2025-03-08T07:21:25.589428Z","shell.execute_reply":"2025-03-08T07:21:27.746668Z"}},"outputs":[{"name":"stdout","text":"Submission file saved.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# cross check: https://colab.research.google.com/drive/1eI2nQYt2EH88-17wrKx-4E_wO4ZCAL9K#scrollTo=JUK7G7_Dboyf\n# class name: https://medium.com/@thatchawin.ler/cifar10-with-resnet-in-pytorch-a86fe18049df\n# 70%\n\nimport numpy as np\nimport pandas as pd\nimport os\nimport pickle\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nfrom torch.utils.data import DataLoader, random_split, TensorDataset\nfrom torch.optim.lr_scheduler import StepLR\nfrom PIL import Image\nimport torch.optim.lr_scheduler as lr_scheduler\n\n# auto. choose CPU or GPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n# Function to load CIFAR-10 dataset\ndef load_cifar_batch(file):\n    with open(file, 'rb') as fo:\n        dict = pickle.load(fo, encoding='bytes')\n    return dict\n\n# Specify the directory containing CIFAR-10 batches\ncifar10_dir = '/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py'\n\n# Load metadata (labels)\nmeta_data_dict = load_cifar_batch(os.path.join(cifar10_dir, 'batches.meta'))\nlabel_names = [label.decode('utf-8') for label in meta_data_dict[b'label_names']]\n\n# Load training data\ntrain_data = []\ntrain_labels = []\nfor i in range(1, 6):\n    batch = load_cifar_batch(os.path.join(cifar10_dir, f'data_batch_{i}'))\n    train_data.append(batch[b'data'])\n    train_labels += batch[b'labels']\n\ntrain_data = np.vstack(train_data).reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)  # Convert to HWC format\ntrain_labels = np.array(train_labels)\n\n# Data augmentation and normalization\ntransform = transforms.Compose([\n    transforms.ToPILImage(),  # Convert numpy array to PIL Image\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(brightness = 0.1,contrast = 0.1,saturation = 0.1),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomAdjustSharpness(sharpness_factor = 2,p = 0.2),\n    transforms.RandomCrop(32, padding=4),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n    transforms.RandomErasing(p=0.2,scale=(0.02, 0.1),value=1.0, inplace=False)\n])\n\n# Convert to TensorDataset and apply transformations\ntrain_dataset = [(transform(img), label) for img, label in zip(train_data, train_labels)]\n\n# Split into training and validation sets\ntrain_size = int(0.9 * len(train_dataset))\nval_size = len(train_dataset) - train_size\ntrain_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n\n# Load test dataset\ncifar_test_path = '/kaggle/input/deep-learning-spring-2025-project-1/cifar_test_nolabel.pkl'\ntest_batch = load_cifar_batch(cifar_test_path)\ntest_images = test_batch[b'data'].astype(np.float32) / 255.0\n\n# Convert test dataset to Tensor\ntest_dataset = [(transform(img),) for img in test_images]\ntest_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4)\n\n# DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=4)\n\n# Train function\ndef train_model(model, train_loader, val_loader, epochs=50):\n    criterion = nn.CrossEntropyLoss()\n    #optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n    optimizer = optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=1e-4) #change lr\n    #scheduler = StepLR(optimizer, step_size=20, gamma=0.1)\n    scheduler = StepLR(optimizer, step_size=6, gamma=0.85)\n\n    \n    for epoch in range(epochs):\n        model.train()\n        running_loss = 0.0\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        \n        model.eval()\n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                _, predicted = torch.max(outputs, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n        \n        scheduler.step()\n        print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}, Validation Accuracy: {100 * correct / total}%')\n\n# Define a custom ResNet model from scratch\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.skip = nn.Sequential()\n        if stride != 1 or in_channels != out_channels:\n            self.skip = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels)\n            )\n        self.dropout = nn.Dropout(0.2)\n    def forward(self, x):\n        identity = x \n        if self.skip:\n            identity = self.skip(x)\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out += identity\n        out = self.relu(out)\n        out = self.dropout(out)\n        return out\n\nclass CustomResNet(nn.Module):\n    def __init__(self, num_classes=10):\n        super(CustomResNet, self).__init__()\n        self.init_conv = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.init_bn = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.layer1 = self._make_layer(64, 64, 2, stride=1)\n        self.layer2 = self._make_layer(64, 128, 2, stride=2)\n        self.layer3 = self._make_layer(128, 256, 2, stride=2)\n        #self.layer4 = self._make_layer(256, 512, 2, stride=2)\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Linear(256, num_classes)\n\n    def _make_layer(self, in_channels, out_channels, blocks, stride):\n        layers = [ResidualBlock(in_channels, out_channels, stride)]\n        for _ in range(1, blocks):\n            layers.append(ResidualBlock(out_channels, out_channels))\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = self.init_conv(x)\n        out = self.init_bn(out)\n        out = self.relu(out)\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        #out = self.layer4(out)\n        out = self.avg_pool(out)\n        out = torch.flatten(out, 1)\n        out = self.fc(out)\n        return out\n\n# put models to devices (CPU/GPU)\nmodel = CustomResNet().to(device)\n\n# Print the number of parameters\nfrom torchsummary import summary\nsummary(model, (3, 32, 32))\n\n# Train the model\ntrain_model(model, train_loader, val_loader, epochs=60) #change epoch\n# Generate submission file\nmodel.eval()\npredictions = []\nwith torch.no_grad():\n    for batch in test_loader:\n        images = batch[0].to(device)  # Get images tensor from tuple and move to device\n        outputs = model(images) \n        _, predicted = torch.max(outputs, 1)\n        predictions.extend(predicted.cpu().numpy())\n\n# Generate submission file\nsubmission = pd.DataFrame({'ID': np.arange(len(predictions)), 'Labels': predictions})\nsubmission.to_csv('/kaggle/working/submission.csv', index=False)\nprint(\"Submission file saved.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T19:35:51.694012Z","iopub.execute_input":"2025-03-08T19:35:51.694347Z","iopub.status.idle":"2025-03-08T20:06:19.651276Z","shell.execute_reply.started":"2025-03-08T19:35:51.694318Z","shell.execute_reply":"2025-03-08T20:06:19.650401Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1           [-1, 64, 32, 32]           1,728\n       BatchNorm2d-2           [-1, 64, 32, 32]             128\n              ReLU-3           [-1, 64, 32, 32]               0\n            Conv2d-4           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-5           [-1, 64, 32, 32]             128\n              ReLU-6           [-1, 64, 32, 32]               0\n            Conv2d-7           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-8           [-1, 64, 32, 32]             128\n              ReLU-9           [-1, 64, 32, 32]               0\n          Dropout-10           [-1, 64, 32, 32]               0\n    ResidualBlock-11           [-1, 64, 32, 32]               0\n           Conv2d-12           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-13           [-1, 64, 32, 32]             128\n             ReLU-14           [-1, 64, 32, 32]               0\n           Conv2d-15           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-16           [-1, 64, 32, 32]             128\n             ReLU-17           [-1, 64, 32, 32]               0\n          Dropout-18           [-1, 64, 32, 32]               0\n    ResidualBlock-19           [-1, 64, 32, 32]               0\n           Conv2d-20          [-1, 128, 16, 16]           8,192\n      BatchNorm2d-21          [-1, 128, 16, 16]             256\n           Conv2d-22          [-1, 128, 16, 16]          73,728\n      BatchNorm2d-23          [-1, 128, 16, 16]             256\n             ReLU-24          [-1, 128, 16, 16]               0\n           Conv2d-25          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-26          [-1, 128, 16, 16]             256\n             ReLU-27          [-1, 128, 16, 16]               0\n          Dropout-28          [-1, 128, 16, 16]               0\n    ResidualBlock-29          [-1, 128, 16, 16]               0\n           Conv2d-30          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-31          [-1, 128, 16, 16]             256\n             ReLU-32          [-1, 128, 16, 16]               0\n           Conv2d-33          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-34          [-1, 128, 16, 16]             256\n             ReLU-35          [-1, 128, 16, 16]               0\n          Dropout-36          [-1, 128, 16, 16]               0\n    ResidualBlock-37          [-1, 128, 16, 16]               0\n           Conv2d-38            [-1, 256, 8, 8]          32,768\n      BatchNorm2d-39            [-1, 256, 8, 8]             512\n           Conv2d-40            [-1, 256, 8, 8]         294,912\n      BatchNorm2d-41            [-1, 256, 8, 8]             512\n             ReLU-42            [-1, 256, 8, 8]               0\n           Conv2d-43            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-44            [-1, 256, 8, 8]             512\n             ReLU-45            [-1, 256, 8, 8]               0\n          Dropout-46            [-1, 256, 8, 8]               0\n    ResidualBlock-47            [-1, 256, 8, 8]               0\n           Conv2d-48            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-49            [-1, 256, 8, 8]             512\n             ReLU-50            [-1, 256, 8, 8]               0\n           Conv2d-51            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-52            [-1, 256, 8, 8]             512\n             ReLU-53            [-1, 256, 8, 8]               0\n          Dropout-54            [-1, 256, 8, 8]               0\n    ResidualBlock-55            [-1, 256, 8, 8]               0\nAdaptiveAvgPool2d-56            [-1, 256, 1, 1]               0\n           Linear-57                   [-1, 10]           2,570\n================================================================\nTotal params: 2,777,674\nTrainable params: 2,777,674\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.01\nForward/backward pass size (MB): 16.25\nParams size (MB): 10.60\nEstimated Total Size (MB): 26.86\n----------------------------------------------------------------\nEpoch 1, Loss: 1.6972004100680351, Validation Accuracy: 42.76%\nEpoch 2, Loss: 1.2878001357682727, Validation Accuracy: 52.38%\nEpoch 3, Loss: 1.0934762329879133, Validation Accuracy: 56.32%\nEpoch 4, Loss: 0.9847610100087795, Validation Accuracy: 63.46%\nEpoch 5, Loss: 0.8955097278072075, Validation Accuracy: 65.8%\nEpoch 6, Loss: 0.8263765568421646, Validation Accuracy: 68.86%\nEpoch 7, Loss: 0.7431637118147179, Validation Accuracy: 72.04%\nEpoch 8, Loss: 0.6955497836355459, Validation Accuracy: 69.78%\nEpoch 9, Loss: 0.6478189741345969, Validation Accuracy: 75.12%\nEpoch 10, Loss: 0.6156842602755536, Validation Accuracy: 74.56%\nEpoch 11, Loss: 0.5831320600753481, Validation Accuracy: 75.0%\nEpoch 12, Loss: 0.5502807803621347, Validation Accuracy: 76.46%\nEpoch 13, Loss: 0.5047582543709062, Validation Accuracy: 78.32%\nEpoch 14, Loss: 0.4790728413076563, Validation Accuracy: 76.9%\nEpoch 15, Loss: 0.4605881327932531, Validation Accuracy: 79.86%\nEpoch 16, Loss: 0.43330988321791997, Validation Accuracy: 80.42%\nEpoch 17, Loss: 0.4147125238722021, Validation Accuracy: 80.06%\nEpoch 18, Loss: 0.4008617304604162, Validation Accuracy: 79.0%\nEpoch 19, Loss: 0.3626756400547244, Validation Accuracy: 80.02%\nEpoch 20, Loss: 0.3460527228360826, Validation Accuracy: 80.46%\nEpoch 21, Loss: 0.3311401219953867, Validation Accuracy: 81.6%\nEpoch 22, Loss: 0.3197361351498826, Validation Accuracy: 80.26%\nEpoch 23, Loss: 0.29919709371064196, Validation Accuracy: 81.14%\nEpoch 24, Loss: 0.295477153648707, Validation Accuracy: 81.72%\nEpoch 25, Loss: 0.26089344802312553, Validation Accuracy: 81.92%\nEpoch 26, Loss: 0.24799542552368206, Validation Accuracy: 82.66%\nEpoch 27, Loss: 0.23982652733949097, Validation Accuracy: 82.42%\nEpoch 28, Loss: 0.22787587361579592, Validation Accuracy: 82.62%\nEpoch 29, Loss: 0.22060757225633346, Validation Accuracy: 82.86%\nEpoch 30, Loss: 0.2103047438219867, Validation Accuracy: 82.7%\nEpoch 31, Loss: 0.1866277740760283, Validation Accuracy: 83.28%\nEpoch 32, Loss: 0.18043306198987094, Validation Accuracy: 82.12%\nEpoch 33, Loss: 0.17144373571500182, Validation Accuracy: 82.84%\nEpoch 34, Loss: 0.16252787644043565, Validation Accuracy: 83.1%\nEpoch 35, Loss: 0.1546628073027188, Validation Accuracy: 83.4%\nEpoch 36, Loss: 0.15093788273886524, Validation Accuracy: 82.86%\nEpoch 37, Loss: 0.13449281837198546, Validation Accuracy: 84.22%\nEpoch 38, Loss: 0.12552913003177804, Validation Accuracy: 82.56%\nEpoch 39, Loss: 0.12292581445283511, Validation Accuracy: 83.2%\nEpoch 40, Loss: 0.11527357306543061, Validation Accuracy: 83.08%\nEpoch 41, Loss: 0.11029172546907583, Validation Accuracy: 84.26%\nEpoch 42, Loss: 0.10391043715009635, Validation Accuracy: 83.96%\nEpoch 43, Loss: 0.09160649291747673, Validation Accuracy: 83.38%\nEpoch 44, Loss: 0.0888402119744569, Validation Accuracy: 84.68%\nEpoch 45, Loss: 0.08885182774181223, Validation Accuracy: 83.92%\nEpoch 46, Loss: 0.08586691605160013, Validation Accuracy: 84.7%\nEpoch 47, Loss: 0.08066352167357267, Validation Accuracy: 84.6%\nEpoch 48, Loss: 0.07931506430031732, Validation Accuracy: 84.72%\nEpoch 49, Loss: 0.07165288682550784, Validation Accuracy: 84.56%\nEpoch 50, Loss: 0.0659472350909544, Validation Accuracy: 84.68%\nEpoch 51, Loss: 0.06304243067014878, Validation Accuracy: 84.72%\nEpoch 52, Loss: 0.06194785353727639, Validation Accuracy: 83.38%\nEpoch 53, Loss: 0.0618327647944997, Validation Accuracy: 83.94%\nEpoch 54, Loss: 0.05864373309569518, Validation Accuracy: 83.84%\nEpoch 55, Loss: 0.05449049440159632, Validation Accuracy: 84.56%\nEpoch 56, Loss: 0.04828091149366545, Validation Accuracy: 85.04%\nEpoch 57, Loss: 0.049491203916576604, Validation Accuracy: 84.86%\nEpoch 58, Loss: 0.04615429615792395, Validation Accuracy: 85.1%\nEpoch 59, Loss: 0.046859846900174904, Validation Accuracy: 85.14%\nEpoch 60, Loss: 0.046007136671422894, Validation Accuracy: 84.66%\nSubmission file saved.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# cross check: https://colab.research.google.com/drive/1eI2nQYt2EH88-17wrKx-4E_wO4ZCAL9K#scrollTo=JUK7G7_Dboyf\n# class name: https://medium.com/@thatchawin.ler/cifar10-with-resnet-in-pytorch-a86fe18049df\n\nimport numpy as np\nimport pandas as pd\nimport os\nimport pickle\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nfrom torch.utils.data import DataLoader, random_split, TensorDataset\nfrom torch.optim.lr_scheduler import StepLR\nfrom PIL import Image\nimport torch.optim.lr_scheduler as lr_scheduler\n\n# auto. choose CPU or GPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n# Function to load CIFAR-10 dataset\ndef load_cifar_batch(file):\n    with open(file, 'rb') as fo:\n        dict = pickle.load(fo, encoding='bytes')\n    return dict\n\n# Specify the directory containing CIFAR-10 batches\ncifar10_dir = '/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py'\n\n# Load metadata (labels)\nmeta_data_dict = load_cifar_batch(os.path.join(cifar10_dir, 'batches.meta'))\nlabel_names = [label.decode('utf-8') for label in meta_data_dict[b'label_names']]\n\n# Load training data\ntrain_data = []\ntrain_labels = []\nfor i in range(1, 6):\n    batch = load_cifar_batch(os.path.join(cifar10_dir, f'data_batch_{i}'))\n    train_data.append(batch[b'data'])\n    train_labels += batch[b'labels']\n\ntrain_data = np.vstack(train_data).reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)  # Convert to HWC format\ntrain_labels = np.array(train_labels)\n\n# Data augmentation and normalization\ntransform = transforms.Compose([\n    transforms.ToPILImage(),  # Convert numpy array to PIL Image\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(brightness = 0.1,contrast = 0.1,saturation = 0.1),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomAdjustSharpness(sharpness_factor = 2,p = 0.2),\n    transforms.RandomCrop(32, padding=4),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n    transforms.RandomErasing(p=0.2,scale=(0.02, 0.1),value=1.0, inplace=False)\n])\n\n# Convert to TensorDataset and apply transformations\ntrain_dataset = [(transform(img), label) for img, label in zip(train_data, train_labels)]\n\n# Split into training and validation sets\ntrain_size = int(0.9 * len(train_dataset))\nval_size = len(train_dataset) - train_size\ntrain_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n\n# Load test dataset\ncifar_test_path = '/kaggle/input/deep-learning-spring-2025-project-1/cifar_test_nolabel.pkl'\ntest_batch = load_cifar_batch(cifar_test_path)\ntest_images = test_batch[b'data'].astype(np.float32) / 255.0\n\n# Convert test dataset to Tensor\ntest_dataset = [(transform(img),) for img in test_images]\ntest_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4)\n\n# DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=4)\n\n# Train function\ndef train_model(model, train_loader, val_loader, epochs=50):\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.003, weight_decay=1e-4)\n    #optimizer = optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=1e-4) #change lr\n    #scheduler = StepLR(optimizer, step_size=20, gamma=0.1)\n    scheduler = StepLR(optimizer, step_size=10, gamma=0.9)\n\n    \n    for epoch in range(epochs):\n        model.train()\n        running_loss = 0.0\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        \n        model.eval()\n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                _, predicted = torch.max(outputs, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n        \n        scheduler.step()\n        print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}, Validation Accuracy: {100 * correct / total}%')\n\n# Define a custom ResNet model from scratch\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.skip = nn.Sequential()\n        if stride != 1 or in_channels != out_channels:\n            self.skip = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels)\n            )\n        self.dropout = nn.Dropout(0.2)\n    def forward(self, x):\n        identity = x \n        if self.skip:\n            identity = self.skip(x)\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out += identity\n        out = self.relu(out)\n        out = self.dropout(out)\n        return out\n\nclass CustomResNet(nn.Module):\n    def __init__(self, num_classes=10):\n        super(CustomResNet, self).__init__()\n        self.init_conv = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.init_bn = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.layer1 = self._make_layer(64, 64, 3, stride=1)\n        self.layer2 = self._make_layer(64, 64, 4, stride=2)\n        self.layer3 = self._make_layer(64, 128, 4, stride=2)\n        self.layer4 = self._make_layer(128, 256, 3, stride=2)\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Linear(256, num_classes)\n\n    def _make_layer(self, in_channels, out_channels, blocks, stride):\n        layers = [ResidualBlock(in_channels, out_channels, stride)]\n        for _ in range(1, blocks):\n            layers.append(ResidualBlock(out_channels, out_channels))\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = self.init_conv(x)\n        out = self.init_bn(out)\n        out = self.relu(out)\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = self.avg_pool(out)\n        out = torch.flatten(out, 1)\n        out = self.fc(out)\n        return out\n\n# put models to devices (CPU/GPU)\nmodel = CustomResNet().to(device)\n\n# Print the number of parameters\nfrom torchsummary import summary\nsummary(model, (3, 32, 32))\n\n# Train the model\ntrain_model(model, train_loader, val_loader, epochs=100) #change epoch\n# Generate submission file\nmodel.eval()\npredictions = []\nwith torch.no_grad():\n    for batch in test_loader:\n        images = batch[0].to(device)  # Get images tensor from tuple and move to device\n        outputs = model(images) \n        _, predicted = torch.max(outputs, 1)\n        predictions.extend(predicted.cpu().numpy())\n\n# Generate submission file\nsubmission = pd.DataFrame({'ID': np.arange(len(predictions)), 'Labels': predictions})\nsubmission.to_csv('/kaggle/working/submission3.csv', index=False)\nprint(\"Submission3 file saved.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T07:49:11.109787Z","iopub.execute_input":"2025-03-09T07:49:11.110064Z","iopub.status.idle":"2025-03-09T08:52:18.905292Z","shell.execute_reply.started":"2025-03-09T07:49:11.110039Z","shell.execute_reply":"2025-03-09T08:52:18.904310Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1           [-1, 64, 32, 32]           1,728\n       BatchNorm2d-2           [-1, 64, 32, 32]             128\n              ReLU-3           [-1, 64, 32, 32]               0\n            Conv2d-4           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-5           [-1, 64, 32, 32]             128\n              ReLU-6           [-1, 64, 32, 32]               0\n            Conv2d-7           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-8           [-1, 64, 32, 32]             128\n              ReLU-9           [-1, 64, 32, 32]               0\n          Dropout-10           [-1, 64, 32, 32]               0\n    ResidualBlock-11           [-1, 64, 32, 32]               0\n           Conv2d-12           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-13           [-1, 64, 32, 32]             128\n             ReLU-14           [-1, 64, 32, 32]               0\n           Conv2d-15           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-16           [-1, 64, 32, 32]             128\n             ReLU-17           [-1, 64, 32, 32]               0\n          Dropout-18           [-1, 64, 32, 32]               0\n    ResidualBlock-19           [-1, 64, 32, 32]               0\n           Conv2d-20           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-21           [-1, 64, 32, 32]             128\n             ReLU-22           [-1, 64, 32, 32]               0\n           Conv2d-23           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-24           [-1, 64, 32, 32]             128\n             ReLU-25           [-1, 64, 32, 32]               0\n          Dropout-26           [-1, 64, 32, 32]               0\n    ResidualBlock-27           [-1, 64, 32, 32]               0\n           Conv2d-28           [-1, 64, 16, 16]           4,096\n      BatchNorm2d-29           [-1, 64, 16, 16]             128\n           Conv2d-30           [-1, 64, 16, 16]          36,864\n      BatchNorm2d-31           [-1, 64, 16, 16]             128\n             ReLU-32           [-1, 64, 16, 16]               0\n           Conv2d-33           [-1, 64, 16, 16]          36,864\n      BatchNorm2d-34           [-1, 64, 16, 16]             128\n             ReLU-35           [-1, 64, 16, 16]               0\n          Dropout-36           [-1, 64, 16, 16]               0\n    ResidualBlock-37           [-1, 64, 16, 16]               0\n           Conv2d-38           [-1, 64, 16, 16]          36,864\n      BatchNorm2d-39           [-1, 64, 16, 16]             128\n             ReLU-40           [-1, 64, 16, 16]               0\n           Conv2d-41           [-1, 64, 16, 16]          36,864\n      BatchNorm2d-42           [-1, 64, 16, 16]             128\n             ReLU-43           [-1, 64, 16, 16]               0\n          Dropout-44           [-1, 64, 16, 16]               0\n    ResidualBlock-45           [-1, 64, 16, 16]               0\n           Conv2d-46           [-1, 64, 16, 16]          36,864\n      BatchNorm2d-47           [-1, 64, 16, 16]             128\n             ReLU-48           [-1, 64, 16, 16]               0\n           Conv2d-49           [-1, 64, 16, 16]          36,864\n      BatchNorm2d-50           [-1, 64, 16, 16]             128\n             ReLU-51           [-1, 64, 16, 16]               0\n          Dropout-52           [-1, 64, 16, 16]               0\n    ResidualBlock-53           [-1, 64, 16, 16]               0\n           Conv2d-54           [-1, 64, 16, 16]          36,864\n      BatchNorm2d-55           [-1, 64, 16, 16]             128\n             ReLU-56           [-1, 64, 16, 16]               0\n           Conv2d-57           [-1, 64, 16, 16]          36,864\n      BatchNorm2d-58           [-1, 64, 16, 16]             128\n             ReLU-59           [-1, 64, 16, 16]               0\n          Dropout-60           [-1, 64, 16, 16]               0\n    ResidualBlock-61           [-1, 64, 16, 16]               0\n           Conv2d-62            [-1, 128, 8, 8]           8,192\n      BatchNorm2d-63            [-1, 128, 8, 8]             256\n           Conv2d-64            [-1, 128, 8, 8]          73,728\n      BatchNorm2d-65            [-1, 128, 8, 8]             256\n             ReLU-66            [-1, 128, 8, 8]               0\n           Conv2d-67            [-1, 128, 8, 8]         147,456\n      BatchNorm2d-68            [-1, 128, 8, 8]             256\n             ReLU-69            [-1, 128, 8, 8]               0\n          Dropout-70            [-1, 128, 8, 8]               0\n    ResidualBlock-71            [-1, 128, 8, 8]               0\n           Conv2d-72            [-1, 128, 8, 8]         147,456\n      BatchNorm2d-73            [-1, 128, 8, 8]             256\n             ReLU-74            [-1, 128, 8, 8]               0\n           Conv2d-75            [-1, 128, 8, 8]         147,456\n      BatchNorm2d-76            [-1, 128, 8, 8]             256\n             ReLU-77            [-1, 128, 8, 8]               0\n          Dropout-78            [-1, 128, 8, 8]               0\n    ResidualBlock-79            [-1, 128, 8, 8]               0\n           Conv2d-80            [-1, 128, 8, 8]         147,456\n      BatchNorm2d-81            [-1, 128, 8, 8]             256\n             ReLU-82            [-1, 128, 8, 8]               0\n           Conv2d-83            [-1, 128, 8, 8]         147,456\n      BatchNorm2d-84            [-1, 128, 8, 8]             256\n             ReLU-85            [-1, 128, 8, 8]               0\n          Dropout-86            [-1, 128, 8, 8]               0\n    ResidualBlock-87            [-1, 128, 8, 8]               0\n           Conv2d-88            [-1, 128, 8, 8]         147,456\n      BatchNorm2d-89            [-1, 128, 8, 8]             256\n             ReLU-90            [-1, 128, 8, 8]               0\n           Conv2d-91            [-1, 128, 8, 8]         147,456\n      BatchNorm2d-92            [-1, 128, 8, 8]             256\n             ReLU-93            [-1, 128, 8, 8]               0\n          Dropout-94            [-1, 128, 8, 8]               0\n    ResidualBlock-95            [-1, 128, 8, 8]               0\n           Conv2d-96            [-1, 256, 4, 4]          32,768\n      BatchNorm2d-97            [-1, 256, 4, 4]             512\n           Conv2d-98            [-1, 256, 4, 4]         294,912\n      BatchNorm2d-99            [-1, 256, 4, 4]             512\n            ReLU-100            [-1, 256, 4, 4]               0\n          Conv2d-101            [-1, 256, 4, 4]         589,824\n     BatchNorm2d-102            [-1, 256, 4, 4]             512\n            ReLU-103            [-1, 256, 4, 4]               0\n         Dropout-104            [-1, 256, 4, 4]               0\n   ResidualBlock-105            [-1, 256, 4, 4]               0\n          Conv2d-106            [-1, 256, 4, 4]         589,824\n     BatchNorm2d-107            [-1, 256, 4, 4]             512\n            ReLU-108            [-1, 256, 4, 4]               0\n          Conv2d-109            [-1, 256, 4, 4]         589,824\n     BatchNorm2d-110            [-1, 256, 4, 4]             512\n            ReLU-111            [-1, 256, 4, 4]               0\n         Dropout-112            [-1, 256, 4, 4]               0\n   ResidualBlock-113            [-1, 256, 4, 4]               0\n          Conv2d-114            [-1, 256, 4, 4]         589,824\n     BatchNorm2d-115            [-1, 256, 4, 4]             512\n            ReLU-116            [-1, 256, 4, 4]               0\n          Conv2d-117            [-1, 256, 4, 4]         589,824\n     BatchNorm2d-118            [-1, 256, 4, 4]             512\n            ReLU-119            [-1, 256, 4, 4]               0\n         Dropout-120            [-1, 256, 4, 4]               0\n   ResidualBlock-121            [-1, 256, 4, 4]               0\nAdaptiveAvgPool2d-122            [-1, 256, 1, 1]               0\n          Linear-123                   [-1, 10]           2,570\n================================================================\nTotal params: 4,923,338\nTrainable params: 4,923,338\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.01\nForward/backward pass size (MB): 20.69\nParams size (MB): 18.78\nEstimated Total Size (MB): 39.48\n----------------------------------------------------------------\nEpoch 1, Loss: 1.767448257993568, Validation Accuracy: 38.3%\nEpoch 2, Loss: 1.440752056173303, Validation Accuracy: 47.92%\nEpoch 3, Loss: 1.2735729623924603, Validation Accuracy: 53.18%\nEpoch 4, Loss: 1.1727169508283788, Validation Accuracy: 52.48%\nEpoch 5, Loss: 1.0923004340041766, Validation Accuracy: 59.58%\nEpoch 6, Loss: 1.0143744891340083, Validation Accuracy: 60.52%\nEpoch 7, Loss: 0.9521198083053936, Validation Accuracy: 65.48%\nEpoch 8, Loss: 0.9041840525513346, Validation Accuracy: 70.26%\nEpoch 9, Loss: 0.8563445059751923, Validation Accuracy: 66.92%\nEpoch 10, Loss: 0.8105256877500903, Validation Accuracy: 64.94%\nEpoch 11, Loss: 0.7575549315661192, Validation Accuracy: 70.72%\nEpoch 12, Loss: 0.7243006054142659, Validation Accuracy: 73.1%\nEpoch 13, Loss: 0.6946575126864694, Validation Accuracy: 73.66%\nEpoch 14, Loss: 0.6708062837239016, Validation Accuracy: 69.92%\nEpoch 15, Loss: 0.6480389763177796, Validation Accuracy: 76.96%\nEpoch 16, Loss: 0.6344232781874862, Validation Accuracy: 77.22%\nEpoch 17, Loss: 0.6141124067150734, Validation Accuracy: 75.6%\nEpoch 18, Loss: 0.5957830963148312, Validation Accuracy: 77.18%\nEpoch 19, Loss: 0.585134729150344, Validation Accuracy: 77.16%\nEpoch 20, Loss: 0.5748301678421822, Validation Accuracy: 79.38%\nEpoch 21, Loss: 0.5482801653614099, Validation Accuracy: 76.54%\nEpoch 22, Loss: 0.5332912459800189, Validation Accuracy: 78.42%\nEpoch 23, Loss: 0.5246104879135435, Validation Accuracy: 80.06%\nEpoch 24, Loss: 0.5164836539294232, Validation Accuracy: 79.34%\nEpoch 25, Loss: 0.5130680042572997, Validation Accuracy: 77.6%\nEpoch 26, Loss: 0.5080132854425095, Validation Accuracy: 80.76%\nEpoch 27, Loss: 0.4899765764447776, Validation Accuracy: 80.88%\nEpoch 28, Loss: 0.48543762881308794, Validation Accuracy: 78.02%\nEpoch 29, Loss: 0.48045968772335484, Validation Accuracy: 77.94%\nEpoch 30, Loss: 0.4754511791027405, Validation Accuracy: 79.02%\nEpoch 31, Loss: 0.45245817832818086, Validation Accuracy: 80.02%\nEpoch 32, Loss: 0.4473672502420165, Validation Accuracy: 80.66%\nEpoch 33, Loss: 0.44263551104813814, Validation Accuracy: 80.32%\nEpoch 34, Loss: 0.4371386199173602, Validation Accuracy: 80.36%\nEpoch 35, Loss: 0.43118550641123543, Validation Accuracy: 80.78%\nEpoch 36, Loss: 0.43012743680314586, Validation Accuracy: 81.3%\nEpoch 37, Loss: 0.42615801180628216, Validation Accuracy: 80.78%\nEpoch 38, Loss: 0.42190409235825593, Validation Accuracy: 82.14%\nEpoch 39, Loss: 0.41782407416030765, Validation Accuracy: 81.92%\nEpoch 40, Loss: 0.41184782452712004, Validation Accuracy: 79.54%\nEpoch 41, Loss: 0.39421148115599697, Validation Accuracy: 80.86%\nEpoch 42, Loss: 0.3809883194467561, Validation Accuracy: 83.42%\nEpoch 43, Loss: 0.387649243443527, Validation Accuracy: 80.46%\nEpoch 44, Loss: 0.3826733309860257, Validation Accuracy: 81.66%\nEpoch 45, Loss: 0.3779698929072104, Validation Accuracy: 79.86%\nEpoch 46, Loss: 0.37177170791917225, Validation Accuracy: 81.02%\nEpoch 47, Loss: 0.375309137204154, Validation Accuracy: 82.28%\nEpoch 48, Loss: 0.3704531392167238, Validation Accuracy: 81.58%\nEpoch 49, Loss: 0.3640352609906007, Validation Accuracy: 82.54%\nEpoch 50, Loss: 0.3642073255032301, Validation Accuracy: 82.18%\nEpoch 51, Loss: 0.3384158459746025, Validation Accuracy: 82.86%\nEpoch 52, Loss: 0.34404626035724173, Validation Accuracy: 81.22%\nEpoch 53, Loss: 0.34147141651589086, Validation Accuracy: 82.94%\nEpoch 54, Loss: 0.3349643337794326, Validation Accuracy: 83.78%\nEpoch 55, Loss: 0.3359561145771295, Validation Accuracy: 82.4%\nEpoch 56, Loss: 0.3274009886451743, Validation Accuracy: 81.5%\nEpoch 57, Loss: 0.33197907146743755, Validation Accuracy: 81.84%\nEpoch 58, Loss: 0.32588593623685563, Validation Accuracy: 83.56%\nEpoch 59, Loss: 0.329771753993224, Validation Accuracy: 83.28%\nEpoch 60, Loss: 0.32642628908665344, Validation Accuracy: 82.22%\nEpoch 61, Loss: 0.30466688284650445, Validation Accuracy: 83.48%\nEpoch 62, Loss: 0.30032020718367264, Validation Accuracy: 82.0%\nEpoch 63, Loss: 0.3018997546539388, Validation Accuracy: 81.92%\nEpoch 64, Loss: 0.2989391135898503, Validation Accuracy: 84.24%\nEpoch 65, Loss: 0.29596640283919196, Validation Accuracy: 83.84%\nEpoch 66, Loss: 0.2874798414890062, Validation Accuracy: 82.42%\nEpoch 67, Loss: 0.29461178183555603, Validation Accuracy: 83.02%\nEpoch 68, Loss: 0.28695695335045457, Validation Accuracy: 83.5%\nEpoch 69, Loss: 0.2866071497767486, Validation Accuracy: 83.34%\nEpoch 70, Loss: 0.2867956224574961, Validation Accuracy: 84.06%\nEpoch 71, Loss: 0.2698710035024719, Validation Accuracy: 83.6%\nEpoch 72, Loss: 0.26514262570576236, Validation Accuracy: 84.7%\nEpoch 73, Loss: 0.2668157739310779, Validation Accuracy: 84.46%\nEpoch 74, Loss: 0.2612003068312664, Validation Accuracy: 84.38%\nEpoch 75, Loss: 0.26488380654799665, Validation Accuracy: 83.12%\nEpoch 76, Loss: 0.25663264171982353, Validation Accuracy: 83.42%\nEpoch 77, Loss: 0.260804389603436, Validation Accuracy: 84.04%\nEpoch 78, Loss: 0.257695696993985, Validation Accuracy: 84.46%\nEpoch 79, Loss: 0.25730691223659297, Validation Accuracy: 83.0%\nEpoch 80, Loss: 0.2525581757707352, Validation Accuracy: 83.62%\nEpoch 81, Loss: 0.24175433727743273, Validation Accuracy: 83.62%\nEpoch 82, Loss: 0.23812685401009565, Validation Accuracy: 83.92%\nEpoch 83, Loss: 0.23628931818529963, Validation Accuracy: 85.06%\nEpoch 84, Loss: 0.2382849635641006, Validation Accuracy: 83.8%\nEpoch 85, Loss: 0.23077247748998078, Validation Accuracy: 84.52%\nEpoch 86, Loss: 0.22603844023648312, Validation Accuracy: 81.48%\nEpoch 87, Loss: 0.23491260906766084, Validation Accuracy: 84.46%\nEpoch 88, Loss: 0.22832219165072523, Validation Accuracy: 82.36%\nEpoch 89, Loss: 0.22170172767205673, Validation Accuracy: 85.3%\nEpoch 90, Loss: 0.23028395174663852, Validation Accuracy: 83.28%\nEpoch 91, Loss: 0.21519217748110267, Validation Accuracy: 84.9%\nEpoch 92, Loss: 0.20726774004288018, Validation Accuracy: 84.1%\nEpoch 93, Loss: 0.20806944306770508, Validation Accuracy: 82.96%\nEpoch 94, Loss: 0.20686771754514088, Validation Accuracy: 85.62%\nEpoch 95, Loss: 0.20824635860679502, Validation Accuracy: 84.06%\nEpoch 96, Loss: 0.20761002856306732, Validation Accuracy: 83.58%\nEpoch 97, Loss: 0.20886123563501646, Validation Accuracy: 83.86%\nEpoch 98, Loss: 0.21091966519386254, Validation Accuracy: 84.16%\nEpoch 99, Loss: 0.19559230215170167, Validation Accuracy: 84.08%\nEpoch 100, Loss: 0.20694593200460076, Validation Accuracy: 85.24%\nSubmission3 file saved.\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# cross check: https://colab.research.google.com/drive/1eI2nQYt2EH88-17wrKx-4E_wO4ZCAL9K#scrollTo=JUK7G7_Dboyf\n# class name: https://medium.com/@thatchawin.ler/cifar10-with-resnet-in-pytorch-a86fe18049df\n\nimport numpy as np\nimport pandas as pd\nimport os\nimport pickle\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nfrom torch.utils.data import DataLoader, random_split, TensorDataset\nfrom torch.optim.lr_scheduler import StepLR\nfrom PIL import Image\nimport torch.optim.lr_scheduler as lr_scheduler\n\n# auto. choose CPU or GPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n# Function to load CIFAR-10 dataset\ndef load_cifar_batch(file):\n    with open(file, 'rb') as fo:\n        dict = pickle.load(fo, encoding='bytes')\n    return dict\n\n# Specify the directory containing CIFAR-10 batches\ncifar10_dir = '/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py'\n\n# Load metadata (labels)\nmeta_data_dict = load_cifar_batch(os.path.join(cifar10_dir, 'batches.meta'))\nlabel_names = [label.decode('utf-8') for label in meta_data_dict[b'label_names']]\n\n# Load training data\ntrain_data = []\ntrain_labels = []\nfor i in range(1, 6):\n    batch = load_cifar_batch(os.path.join(cifar10_dir, f'data_batch_{i}'))\n    train_data.append(batch[b'data'])\n    train_labels += batch[b'labels']\n\ntrain_data = np.vstack(train_data).reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)  # Convert to HWC format\ntrain_labels = np.array(train_labels)\n\n# Data augmentation and normalization\ntransform = transforms.Compose([\n    transforms.ToPILImage(),  # Convert numpy array to PIL Image\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(brightness = 0.1,contrast = 0.1,saturation = 0.1),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomAdjustSharpness(sharpness_factor = 2,p = 0.2),\n    transforms.RandomCrop(32, padding=4),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n    transforms.RandomErasing(p=0.2,scale=(0.02, 0.1),value=1.0, inplace=False)\n])\n\n# Convert to TensorDataset and apply transformations\ntrain_dataset = [(transform(img), label) for img, label in zip(train_data, train_labels)]\n\n# Split into training and validation sets\ntrain_size = int(0.9 * len(train_dataset))\nval_size = len(train_dataset) - train_size\ntrain_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n\n# Load test dataset\ncifar_test_path = '/kaggle/input/deep-learning-spring-2025-project-1/cifar_test_nolabel.pkl'\ntest_batch = load_cifar_batch(cifar_test_path)\ntest_images = test_batch[b'data'].astype(np.float32) / 255.0\n\n# Convert test dataset to Tensor\ntest_dataset = [(transform(img),) for img in test_images]\ntest_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4)\n\n# DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=4)\n\n# Train function\ndef train_model(model, train_loader, val_loader, epochs=50):\n    criterion = nn.CrossEntropyLoss()\n    #optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n    optimizer = optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=1e-4) #change lr\n    #scheduler = StepLR(optimizer, step_size=20, gamma=0.1)\n    scheduler = StepLR(optimizer, step_size=6, gamma=0.85)\n\n    \n    for epoch in range(epochs):\n        model.train()\n        running_loss = 0.0\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        \n        model.eval()\n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                _, predicted = torch.max(outputs, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n        \n        scheduler.step()\n        print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}, Validation Accuracy: {100 * correct / total}%')\n\n# Define a custom ResNet model from scratch\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.skip = nn.Sequential()\n        if stride != 1 or in_channels != out_channels:\n            self.skip = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels)\n            )\n    def forward(self, x):\n        identity = x \n        if self.skip:\n            identity = self.skip(x)\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out += identity\n        out = self.relu(out)\n        return out\n\nclass CustomResNet(nn.Module):\n    def __init__(self, num_classes=10):\n        super(CustomResNet, self).__init__()\n        self.init_conv = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.init_bn = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.layer1 = self._make_layer(64, 64, 3, stride=1)\n        self.layer2 = self._make_layer(64, 64, 4, stride=2)\n        self.layer3 = self._make_layer(64, 128, 4, stride=2)\n        self.layer4 = self._make_layer(128, 256, 3, stride=2)\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Linear(256, num_classes)\n\n    def _make_layer(self, in_channels, out_channels, blocks, stride):\n        layers = [ResidualBlock(in_channels, out_channels, stride)]\n        for _ in range(1, blocks):\n            layers.append(ResidualBlock(out_channels, out_channels))\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = self.init_conv(x)\n        out = self.init_bn(out)\n        out = self.relu(out)\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = self.avg_pool(out)\n        out = torch.flatten(out, 1)\n        out = self.fc(out)\n        return out\n\n# put models to devices (CPU/GPU)\nmodel = CustomResNet().to(device)\n\n# Print the number of parameters\nfrom torchsummary import summary\nsummary(model, (3, 32, 32))\n\n# Train the model\ntrain_model(model, train_loader, val_loader, epochs=100) #change epoch\n# Generate submission file\nmodel.eval()\npredictions = []\nwith torch.no_grad():\n    for batch in test_loader:\n        images = batch[0].to(device)  # Get images tensor from tuple and move to device\n        outputs = model(images) \n        _, predicted = torch.max(outputs, 1)\n        predictions.extend(predicted.cpu().numpy())\n\n# Generate submission file\nsubmission = pd.DataFrame({'ID': np.arange(len(predictions)), 'Labels': predictions})\nsubmission.to_csv('/kaggle/working/submission4.csv', index=False)\nprint(\"Submission4 file saved.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T09:13:57.271067Z","iopub.execute_input":"2025-03-09T09:13:57.271372Z","iopub.status.idle":"2025-03-09T10:15:38.205943Z","shell.execute_reply.started":"2025-03-09T09:13:57.271351Z","shell.execute_reply":"2025-03-09T10:15:38.204841Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1           [-1, 64, 32, 32]           1,728\n       BatchNorm2d-2           [-1, 64, 32, 32]             128\n              ReLU-3           [-1, 64, 32, 32]               0\n            Conv2d-4           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-5           [-1, 64, 32, 32]             128\n              ReLU-6           [-1, 64, 32, 32]               0\n            Conv2d-7           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-8           [-1, 64, 32, 32]             128\n              ReLU-9           [-1, 64, 32, 32]               0\n    ResidualBlock-10           [-1, 64, 32, 32]               0\n           Conv2d-11           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-12           [-1, 64, 32, 32]             128\n             ReLU-13           [-1, 64, 32, 32]               0\n           Conv2d-14           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-15           [-1, 64, 32, 32]             128\n             ReLU-16           [-1, 64, 32, 32]               0\n    ResidualBlock-17           [-1, 64, 32, 32]               0\n           Conv2d-18           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-19           [-1, 64, 32, 32]             128\n             ReLU-20           [-1, 64, 32, 32]               0\n           Conv2d-21           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-22           [-1, 64, 32, 32]             128\n             ReLU-23           [-1, 64, 32, 32]               0\n    ResidualBlock-24           [-1, 64, 32, 32]               0\n           Conv2d-25           [-1, 64, 16, 16]           4,096\n      BatchNorm2d-26           [-1, 64, 16, 16]             128\n           Conv2d-27           [-1, 64, 16, 16]          36,864\n      BatchNorm2d-28           [-1, 64, 16, 16]             128\n             ReLU-29           [-1, 64, 16, 16]               0\n           Conv2d-30           [-1, 64, 16, 16]          36,864\n      BatchNorm2d-31           [-1, 64, 16, 16]             128\n             ReLU-32           [-1, 64, 16, 16]               0\n    ResidualBlock-33           [-1, 64, 16, 16]               0\n           Conv2d-34           [-1, 64, 16, 16]          36,864\n      BatchNorm2d-35           [-1, 64, 16, 16]             128\n             ReLU-36           [-1, 64, 16, 16]               0\n           Conv2d-37           [-1, 64, 16, 16]          36,864\n      BatchNorm2d-38           [-1, 64, 16, 16]             128\n             ReLU-39           [-1, 64, 16, 16]               0\n    ResidualBlock-40           [-1, 64, 16, 16]               0\n           Conv2d-41           [-1, 64, 16, 16]          36,864\n      BatchNorm2d-42           [-1, 64, 16, 16]             128\n             ReLU-43           [-1, 64, 16, 16]               0\n           Conv2d-44           [-1, 64, 16, 16]          36,864\n      BatchNorm2d-45           [-1, 64, 16, 16]             128\n             ReLU-46           [-1, 64, 16, 16]               0\n    ResidualBlock-47           [-1, 64, 16, 16]               0\n           Conv2d-48           [-1, 64, 16, 16]          36,864\n      BatchNorm2d-49           [-1, 64, 16, 16]             128\n             ReLU-50           [-1, 64, 16, 16]               0\n           Conv2d-51           [-1, 64, 16, 16]          36,864\n      BatchNorm2d-52           [-1, 64, 16, 16]             128\n             ReLU-53           [-1, 64, 16, 16]               0\n    ResidualBlock-54           [-1, 64, 16, 16]               0\n           Conv2d-55            [-1, 128, 8, 8]           8,192\n      BatchNorm2d-56            [-1, 128, 8, 8]             256\n           Conv2d-57            [-1, 128, 8, 8]          73,728\n      BatchNorm2d-58            [-1, 128, 8, 8]             256\n             ReLU-59            [-1, 128, 8, 8]               0\n           Conv2d-60            [-1, 128, 8, 8]         147,456\n      BatchNorm2d-61            [-1, 128, 8, 8]             256\n             ReLU-62            [-1, 128, 8, 8]               0\n    ResidualBlock-63            [-1, 128, 8, 8]               0\n           Conv2d-64            [-1, 128, 8, 8]         147,456\n      BatchNorm2d-65            [-1, 128, 8, 8]             256\n             ReLU-66            [-1, 128, 8, 8]               0\n           Conv2d-67            [-1, 128, 8, 8]         147,456\n      BatchNorm2d-68            [-1, 128, 8, 8]             256\n             ReLU-69            [-1, 128, 8, 8]               0\n    ResidualBlock-70            [-1, 128, 8, 8]               0\n           Conv2d-71            [-1, 128, 8, 8]         147,456\n      BatchNorm2d-72            [-1, 128, 8, 8]             256\n             ReLU-73            [-1, 128, 8, 8]               0\n           Conv2d-74            [-1, 128, 8, 8]         147,456\n      BatchNorm2d-75            [-1, 128, 8, 8]             256\n             ReLU-76            [-1, 128, 8, 8]               0\n    ResidualBlock-77            [-1, 128, 8, 8]               0\n           Conv2d-78            [-1, 128, 8, 8]         147,456\n      BatchNorm2d-79            [-1, 128, 8, 8]             256\n             ReLU-80            [-1, 128, 8, 8]               0\n           Conv2d-81            [-1, 128, 8, 8]         147,456\n      BatchNorm2d-82            [-1, 128, 8, 8]             256\n             ReLU-83            [-1, 128, 8, 8]               0\n    ResidualBlock-84            [-1, 128, 8, 8]               0\n           Conv2d-85            [-1, 256, 4, 4]          32,768\n      BatchNorm2d-86            [-1, 256, 4, 4]             512\n           Conv2d-87            [-1, 256, 4, 4]         294,912\n      BatchNorm2d-88            [-1, 256, 4, 4]             512\n             ReLU-89            [-1, 256, 4, 4]               0\n           Conv2d-90            [-1, 256, 4, 4]         589,824\n      BatchNorm2d-91            [-1, 256, 4, 4]             512\n             ReLU-92            [-1, 256, 4, 4]               0\n    ResidualBlock-93            [-1, 256, 4, 4]               0\n           Conv2d-94            [-1, 256, 4, 4]         589,824\n      BatchNorm2d-95            [-1, 256, 4, 4]             512\n             ReLU-96            [-1, 256, 4, 4]               0\n           Conv2d-97            [-1, 256, 4, 4]         589,824\n      BatchNorm2d-98            [-1, 256, 4, 4]             512\n             ReLU-99            [-1, 256, 4, 4]               0\n   ResidualBlock-100            [-1, 256, 4, 4]               0\n          Conv2d-101            [-1, 256, 4, 4]         589,824\n     BatchNorm2d-102            [-1, 256, 4, 4]             512\n            ReLU-103            [-1, 256, 4, 4]               0\n          Conv2d-104            [-1, 256, 4, 4]         589,824\n     BatchNorm2d-105            [-1, 256, 4, 4]             512\n            ReLU-106            [-1, 256, 4, 4]               0\n   ResidualBlock-107            [-1, 256, 4, 4]               0\nAdaptiveAvgPool2d-108            [-1, 256, 1, 1]               0\n          Linear-109                   [-1, 10]           2,570\n================================================================\nTotal params: 4,923,338\nTrainable params: 4,923,338\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.01\nForward/backward pass size (MB): 18.35\nParams size (MB): 18.78\nEstimated Total Size (MB): 37.14\n----------------------------------------------------------------\nEpoch 1, Loss: 1.5965588868341662, Validation Accuracy: 51.12%\nEpoch 2, Loss: 1.1556285819546743, Validation Accuracy: 53.3%\nEpoch 3, Loss: 0.916001323949207, Validation Accuracy: 65.7%\nEpoch 4, Loss: 0.7374407157979228, Validation Accuracy: 67.0%\nEpoch 5, Loss: 0.6030251864682544, Validation Accuracy: 70.28%\nEpoch 6, Loss: 0.48977279878983443, Validation Accuracy: 67.6%\nEpoch 7, Loss: 0.33127948900007387, Validation Accuracy: 70.54%\nEpoch 8, Loss: 0.24505110288208182, Validation Accuracy: 69.96%\nEpoch 9, Loss: 0.19144720258191228, Validation Accuracy: 70.64%\nEpoch 10, Loss: 0.14989604824222624, Validation Accuracy: 71.1%\nEpoch 11, Loss: 0.11095385130664165, Validation Accuracy: 70.7%\nEpoch 12, Loss: 0.1015943736420013, Validation Accuracy: 70.86%\nEpoch 13, Loss: 0.04309818107338453, Validation Accuracy: 74.38%\nEpoch 14, Loss: 0.016495675090647473, Validation Accuracy: 75.54%\nEpoch 15, Loss: 0.006260968750707848, Validation Accuracy: 75.92%\nEpoch 16, Loss: 0.002101113766002527, Validation Accuracy: 76.3%\nEpoch 17, Loss: 0.0010386661835416983, Validation Accuracy: 76.54%\nEpoch 18, Loss: 0.0006591260090648244, Validation Accuracy: 76.94%\nEpoch 19, Loss: 0.0005649927656618688, Validation Accuracy: 76.86%\nEpoch 20, Loss: 0.0004645070495660713, Validation Accuracy: 76.66%\nEpoch 21, Loss: 0.00040503687081251303, Validation Accuracy: 76.5%\nEpoch 22, Loss: 0.0003988409210623186, Validation Accuracy: 76.86%\nEpoch 23, Loss: 0.0003582762157169451, Validation Accuracy: 76.6%\nEpoch 24, Loss: 0.0003293366188162591, Validation Accuracy: 76.62%\nEpoch 25, Loss: 0.0002986049291021945, Validation Accuracy: 76.6%\nEpoch 26, Loss: 0.0002941596375504477, Validation Accuracy: 76.74%\nEpoch 27, Loss: 0.0002747858136858254, Validation Accuracy: 76.58%\nEpoch 28, Loss: 0.00025885152068770947, Validation Accuracy: 76.76%\nEpoch 29, Loss: 0.0002419333675954311, Validation Accuracy: 76.68%\nEpoch 30, Loss: 0.0002483530866935656, Validation Accuracy: 76.76%\nEpoch 31, Loss: 0.00024102931192001878, Validation Accuracy: 76.56%\nEpoch 32, Loss: 0.00022160286646960066, Validation Accuracy: 76.82%\nEpoch 33, Loss: 0.00022034753892925934, Validation Accuracy: 76.68%\nEpoch 34, Loss: 0.00020922730914207932, Validation Accuracy: 76.72%\nEpoch 35, Loss: 0.00021690435005439213, Validation Accuracy: 76.72%\nEpoch 36, Loss: 0.00019998897171676205, Validation Accuracy: 76.84%\nEpoch 37, Loss: 0.00020500538944774732, Validation Accuracy: 76.7%\nEpoch 38, Loss: 0.00022410210104598346, Validation Accuracy: 76.58%\nEpoch 39, Loss: 0.00020340143166983827, Validation Accuracy: 76.8%\nEpoch 40, Loss: 0.0001955307343347489, Validation Accuracy: 77.0%\nEpoch 41, Loss: 0.0001827080368974004, Validation Accuracy: 76.84%\nEpoch 42, Loss: 0.00018732068289492335, Validation Accuracy: 76.96%\nEpoch 43, Loss: 0.00018805898149697566, Validation Accuracy: 77.02%\nEpoch 44, Loss: 0.00018469306678525754, Validation Accuracy: 76.84%\nEpoch 45, Loss: 0.0001783382625820774, Validation Accuracy: 76.9%\nEpoch 46, Loss: 0.0001793194482243879, Validation Accuracy: 76.86%\nEpoch 47, Loss: 0.00018193857578229324, Validation Accuracy: 77.0%\nEpoch 48, Loss: 0.00017661924532190326, Validation Accuracy: 76.76%\nEpoch 49, Loss: 0.0001873212634522629, Validation Accuracy: 76.96%\nEpoch 50, Loss: 0.00017583227938964475, Validation Accuracy: 76.82%\nEpoch 51, Loss: 0.00016767282413225487, Validation Accuracy: 76.86%\nEpoch 52, Loss: 0.00016210243313707906, Validation Accuracy: 76.96%\nEpoch 53, Loss: 0.00016344546544256775, Validation Accuracy: 76.82%\nEpoch 54, Loss: 0.00016202006448069866, Validation Accuracy: 76.78%\nEpoch 55, Loss: 0.0001569044004968005, Validation Accuracy: 76.86%\nEpoch 56, Loss: 0.00015536228784185369, Validation Accuracy: 76.76%\nEpoch 57, Loss: 0.00016828555173602084, Validation Accuracy: 76.84%\nEpoch 58, Loss: 0.00016670907256287717, Validation Accuracy: 76.96%\nEpoch 59, Loss: 0.0001652864082395602, Validation Accuracy: 76.9%\nEpoch 60, Loss: 0.0001538878911085042, Validation Accuracy: 76.8%\nEpoch 61, Loss: 0.00015373702417904994, Validation Accuracy: 76.86%\nEpoch 62, Loss: 0.00015424452482710132, Validation Accuracy: 76.84%\nEpoch 63, Loss: 0.0001644512967066641, Validation Accuracy: 76.8%\nEpoch 64, Loss: 0.0001541780249826016, Validation Accuracy: 76.86%\nEpoch 65, Loss: 0.00015306709134289451, Validation Accuracy: 76.82%\nEpoch 66, Loss: 0.00014847486031819491, Validation Accuracy: 76.82%\nEpoch 67, Loss: 0.00014743177462150925, Validation Accuracy: 76.82%\nEpoch 68, Loss: 0.00014745788278312168, Validation Accuracy: 76.9%\nEpoch 69, Loss: 0.00014663889738709588, Validation Accuracy: 76.62%\nEpoch 70, Loss: 0.00014804804347725374, Validation Accuracy: 76.88%\nEpoch 71, Loss: 0.00014956565903710063, Validation Accuracy: 76.84%\nEpoch 72, Loss: 0.00014350660546824656, Validation Accuracy: 76.92%\nEpoch 73, Loss: 0.00014747557299249985, Validation Accuracy: 76.66%\nEpoch 74, Loss: 0.00014969506273907675, Validation Accuracy: 76.96%\nEpoch 75, Loss: 0.00014705723673490536, Validation Accuracy: 76.84%\nEpoch 76, Loss: 0.00013871423762297624, Validation Accuracy: 76.74%\nEpoch 77, Loss: 0.00014247699206490242, Validation Accuracy: 76.8%\nEpoch 78, Loss: 0.0001491836661567835, Validation Accuracy: 77.02%\nEpoch 79, Loss: 0.0001420813780234973, Validation Accuracy: 76.9%\nEpoch 80, Loss: 0.00014613785228076185, Validation Accuracy: 76.82%\nEpoch 81, Loss: 0.00014233866462828618, Validation Accuracy: 76.82%\nEpoch 82, Loss: 0.00013871333571428707, Validation Accuracy: 76.64%\nEpoch 83, Loss: 0.00013657802632720134, Validation Accuracy: 76.64%\nEpoch 84, Loss: 0.0001451392445646475, Validation Accuracy: 76.78%\nEpoch 85, Loss: 0.00015267136921631226, Validation Accuracy: 76.64%\nEpoch 86, Loss: 0.00014756956442273474, Validation Accuracy: 76.9%\nEpoch 87, Loss: 0.00014475455471214943, Validation Accuracy: 76.98%\nEpoch 88, Loss: 0.00013195362943075782, Validation Accuracy: 76.72%\nEpoch 89, Loss: 0.00013203372844310996, Validation Accuracy: 76.76%\nEpoch 90, Loss: 0.00013669387558159295, Validation Accuracy: 76.92%\nEpoch 91, Loss: 0.00013633932173268641, Validation Accuracy: 76.88%\nEpoch 92, Loss: 0.00013323986504267603, Validation Accuracy: 76.94%\nEpoch 93, Loss: 0.0001397242874335544, Validation Accuracy: 76.88%\nEpoch 94, Loss: 0.0001384343135813734, Validation Accuracy: 76.88%\nEpoch 95, Loss: 0.0001502852620970688, Validation Accuracy: 76.9%\nEpoch 96, Loss: 0.0001386214858856957, Validation Accuracy: 76.96%\nEpoch 97, Loss: 0.00013335857386209682, Validation Accuracy: 76.84%\nEpoch 98, Loss: 0.0001373355499316114, Validation Accuracy: 76.92%\nEpoch 99, Loss: 0.0001328051584178783, Validation Accuracy: 76.98%\nEpoch 100, Loss: 0.00013447067833154009, Validation Accuracy: 77.08%\nSubmission4 file saved.\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# cross check: https://colab.research.google.com/drive/1eI2nQYt2EH88-17wrKx-4E_wO4ZCAL9K#scrollTo=JUK7G7_Dboyf\n# class name: https://medium.com/@thatchawin.ler/cifar10-with-resnet-in-pytorch-a86fe18049df\n\nimport numpy as np\nimport pandas as pd\nimport os\nimport pickle\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nfrom torch.utils.data import DataLoader, random_split, TensorDataset\nfrom torch.optim.lr_scheduler import StepLR\nfrom PIL import Image\nimport torch.optim.lr_scheduler as lr_scheduler\n\n# auto. choose CPU or GPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n# Function to load CIFAR-10 dataset\ndef load_cifar_batch(file):\n    with open(file, 'rb') as fo:\n        dict = pickle.load(fo, encoding='bytes')\n    return dict\n\n# Specify the directory containing CIFAR-10 batches\ncifar10_dir = '/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py'\n\n# Load metadata (labels)\nmeta_data_dict = load_cifar_batch(os.path.join(cifar10_dir, 'batches.meta'))\nlabel_names = [label.decode('utf-8') for label in meta_data_dict[b'label_names']]\n\n# Load training data\ntrain_data = []\ntrain_labels = []\nfor i in range(1, 6):\n    batch = load_cifar_batch(os.path.join(cifar10_dir, f'data_batch_{i}'))\n    train_data.append(batch[b'data'])\n    train_labels += batch[b'labels']\n\ntrain_data = np.vstack(train_data).reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)  # Convert to HWC format\ntrain_labels = np.array(train_labels)\n\n# Data augmentation and normalization\ntransform = transforms.Compose([\n    transforms.ToPILImage(),  # Convert numpy array to PIL Image\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(brightness = 0.1,contrast = 0.1,saturation = 0.1),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomAdjustSharpness(sharpness_factor = 2,p = 0.2),\n    transforms.RandomCrop(32, padding=4),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n    transforms.RandomErasing(p=0.2,scale=(0.02, 0.1),value=1.0, inplace=False)\n])\n\n# Convert to TensorDataset and apply transformations\ntrain_dataset = [(transform(img), label) for img, label in zip(train_data, train_labels)]\n\n# Split into training and validation sets\ntrain_size = int(0.9 * len(train_dataset))\nval_size = len(train_dataset) - train_size\ntrain_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n\n# Load test dataset\ncifar_test_path = '/kaggle/input/deep-learning-spring-2025-project-1/cifar_test_nolabel.pkl'\ntest_batch = load_cifar_batch(cifar_test_path)\ntest_images = test_batch[b'data'].astype(np.float32) / 255.0\n\n# Convert test dataset to Tensor\ntest_dataset = [(transform(img),) for img in test_images]\ntest_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4)\n\n# DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=4)\n\n# Train function\ndef train_model(model, train_loader, val_loader, epochs=50):\n    criterion = nn.CrossEntropyLoss()\n    #optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n    optimizer = optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=1e-4) #change lr\n    #scheduler = StepLR(optimizer, step_size=20, gamma=0.1)\n    scheduler = StepLR(optimizer, step_size=6, gamma=0.85)\n\n    \n    for epoch in range(epochs):\n        model.train()\n        running_loss = 0.0\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        \n        model.eval()\n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                _, predicted = torch.max(outputs, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n        \n        scheduler.step()\n        print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}, Validation Accuracy: {100 * correct / total}%')\n\n# Define a custom ResNet model from scratch\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.skip = nn.Sequential()\n        if stride != 1 or in_channels != out_channels:\n            self.skip = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels)\n            )\n    def forward(self, x):\n        identity = x \n        if self.skip:\n            identity = self.skip(x)\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out += identity\n        out = self.relu(out)\n        return out\n\nclass CustomResNet(nn.Module):\n    def __init__(self, num_classes=10):\n        super(CustomResNet, self).__init__()\n        self.init_conv = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.init_bn = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.layer1 = self._make_layer(64, 64, 2, stride=1)\n        self.layer2 = self._make_layer(64, 128, 2, stride=2)\n        self.layer3 = self._make_layer(128, 256, 2, stride=2)\n        #self.layer4 = self._make_layer(256, 512, 2, stride=2)\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Linear(256, num_classes)\n\n    def _make_layer(self, in_channels, out_channels, blocks, stride):\n        layers = [ResidualBlock(in_channels, out_channels, stride)]\n        for _ in range(1, blocks):\n            layers.append(ResidualBlock(out_channels, out_channels))\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = self.init_conv(x)\n        out = self.init_bn(out)\n        out = self.relu(out)\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        #out = self.layer4(out)\n        out = self.avg_pool(out)\n        out = torch.flatten(out, 1)\n        out = self.fc(out)\n        return out\n\n# put models to devices (CPU/GPU)\nmodel = CustomResNet().to(device)\n\n# Print the number of parameters\nfrom torchsummary import summary\nsummary(model, (3, 32, 32))\n\n# Train the model\ntrain_model(model, train_loader, val_loader, epochs=100) #change epoch\n# Generate submission file\nmodel.eval()\npredictions = []\nwith torch.no_grad():\n    for batch in test_loader:\n        images = batch[0].to(device)  # Get images tensor from tuple and move to device\n        outputs = model(images) \n        _, predicted = torch.max(outputs, 1)\n        predictions.extend(predicted.cpu().numpy())\n\n# Generate submission file\nsubmission = pd.DataFrame({'ID': np.arange(len(predictions)), 'Labels': predictions})\nsubmission.to_csv('/kaggle/working/submission5.csv', index=False)\nprint(\"Submission5 file saved.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T10:15:38.207927Z","iopub.execute_input":"2025-03-09T10:15:38.208201Z","iopub.status.idle":"2025-03-09T11:07:08.703724Z","shell.execute_reply.started":"2025-03-09T10:15:38.208178Z","shell.execute_reply":"2025-03-09T11:07:08.702865Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1           [-1, 64, 32, 32]           1,728\n       BatchNorm2d-2           [-1, 64, 32, 32]             128\n              ReLU-3           [-1, 64, 32, 32]               0\n            Conv2d-4           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-5           [-1, 64, 32, 32]             128\n              ReLU-6           [-1, 64, 32, 32]               0\n            Conv2d-7           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-8           [-1, 64, 32, 32]             128\n              ReLU-9           [-1, 64, 32, 32]               0\n    ResidualBlock-10           [-1, 64, 32, 32]               0\n           Conv2d-11           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-12           [-1, 64, 32, 32]             128\n             ReLU-13           [-1, 64, 32, 32]               0\n           Conv2d-14           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-15           [-1, 64, 32, 32]             128\n             ReLU-16           [-1, 64, 32, 32]               0\n    ResidualBlock-17           [-1, 64, 32, 32]               0\n           Conv2d-18          [-1, 128, 16, 16]           8,192\n      BatchNorm2d-19          [-1, 128, 16, 16]             256\n           Conv2d-20          [-1, 128, 16, 16]          73,728\n      BatchNorm2d-21          [-1, 128, 16, 16]             256\n             ReLU-22          [-1, 128, 16, 16]               0\n           Conv2d-23          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-24          [-1, 128, 16, 16]             256\n             ReLU-25          [-1, 128, 16, 16]               0\n    ResidualBlock-26          [-1, 128, 16, 16]               0\n           Conv2d-27          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-28          [-1, 128, 16, 16]             256\n             ReLU-29          [-1, 128, 16, 16]               0\n           Conv2d-30          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-31          [-1, 128, 16, 16]             256\n             ReLU-32          [-1, 128, 16, 16]               0\n    ResidualBlock-33          [-1, 128, 16, 16]               0\n           Conv2d-34            [-1, 256, 8, 8]          32,768\n      BatchNorm2d-35            [-1, 256, 8, 8]             512\n           Conv2d-36            [-1, 256, 8, 8]         294,912\n      BatchNorm2d-37            [-1, 256, 8, 8]             512\n             ReLU-38            [-1, 256, 8, 8]               0\n           Conv2d-39            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-40            [-1, 256, 8, 8]             512\n             ReLU-41            [-1, 256, 8, 8]               0\n    ResidualBlock-42            [-1, 256, 8, 8]               0\n           Conv2d-43            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-44            [-1, 256, 8, 8]             512\n             ReLU-45            [-1, 256, 8, 8]               0\n           Conv2d-46            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-47            [-1, 256, 8, 8]             512\n             ReLU-48            [-1, 256, 8, 8]               0\n    ResidualBlock-49            [-1, 256, 8, 8]               0\nAdaptiveAvgPool2d-50            [-1, 256, 1, 1]               0\n           Linear-51                   [-1, 10]           2,570\n================================================================\nTotal params: 2,777,674\nTrainable params: 2,777,674\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.01\nForward/backward pass size (MB): 14.50\nParams size (MB): 10.60\nEstimated Total Size (MB): 25.11\n----------------------------------------------------------------\nEpoch 1, Loss: 1.5303547314622186, Validation Accuracy: 47.74%\nEpoch 2, Loss: 1.1012307901612737, Validation Accuracy: 56.38%\nEpoch 3, Loss: 0.8934741670435126, Validation Accuracy: 64.28%\nEpoch 4, Loss: 0.7538909379562194, Validation Accuracy: 68.52%\nEpoch 5, Loss: 0.6356377340853214, Validation Accuracy: 66.98%\nEpoch 6, Loss: 0.5334410116245801, Validation Accuracy: 71.72%\nEpoch 7, Loss: 0.40763042079792783, Validation Accuracy: 73.32%\nEpoch 8, Loss: 0.3253315536897968, Validation Accuracy: 70.98%\nEpoch 9, Loss: 0.2504644541662525, Validation Accuracy: 73.12%\nEpoch 10, Loss: 0.1791367713277313, Validation Accuracy: 67.64%\nEpoch 11, Loss: 0.1281058092241768, Validation Accuracy: 73.44%\nEpoch 12, Loss: 0.08498096139572392, Validation Accuracy: 69.82%\nEpoch 13, Loss: 0.035981744130946354, Validation Accuracy: 72.24%\nEpoch 14, Loss: 0.01179926901121772, Validation Accuracy: 78.26%\nEpoch 15, Loss: 0.004981212030543247, Validation Accuracy: 79.04%\nEpoch 16, Loss: 0.002982865530859933, Validation Accuracy: 79.2%\nEpoch 17, Loss: 0.0023443999796820044, Validation Accuracy: 79.26%\nEpoch 18, Loss: 0.0018709893743520793, Validation Accuracy: 79.58%\nEpoch 19, Loss: 0.001640741612639183, Validation Accuracy: 79.52%\nEpoch 20, Loss: 0.0014375938967119014, Validation Accuracy: 79.36%\nEpoch 21, Loss: 0.0013069217367790936, Validation Accuracy: 79.26%\nEpoch 22, Loss: 0.0012797965755453333, Validation Accuracy: 79.36%\nEpoch 23, Loss: 0.001177205551522837, Validation Accuracy: 79.56%\nEpoch 24, Loss: 0.0011112164138467051, Validation Accuracy: 79.38%\nEpoch 25, Loss: 0.0010639517265438124, Validation Accuracy: 79.32%\nEpoch 26, Loss: 0.0010025007504737005, Validation Accuracy: 79.42%\nEpoch 27, Loss: 0.0009261854829674121, Validation Accuracy: 79.4%\nEpoch 28, Loss: 0.0009332643066128102, Validation Accuracy: 79.24%\nEpoch 29, Loss: 0.0008880069753186862, Validation Accuracy: 79.36%\nEpoch 30, Loss: 0.0008443928936685552, Validation Accuracy: 79.58%\nEpoch 31, Loss: 0.0008244160079067859, Validation Accuracy: 79.4%\nEpoch 32, Loss: 0.0008213227529267897, Validation Accuracy: 79.42%\nEpoch 33, Loss: 0.0007920161760921474, Validation Accuracy: 79.2%\nEpoch 34, Loss: 0.0007544827144143214, Validation Accuracy: 79.28%\nEpoch 35, Loss: 0.0007193760810960983, Validation Accuracy: 79.12%\nEpoch 36, Loss: 0.0006936554994932852, Validation Accuracy: 79.36%\nEpoch 37, Loss: 0.0006886027704240405, Validation Accuracy: 79.36%\nEpoch 38, Loss: 0.0006932923869581745, Validation Accuracy: 79.24%\nEpoch 39, Loss: 0.0007016052341813603, Validation Accuracy: 79.3%\nEpoch 40, Loss: 0.0006804134784694973, Validation Accuracy: 79.36%\nEpoch 41, Loss: 0.0006511252051330467, Validation Accuracy: 79.08%\nEpoch 42, Loss: 0.0006467296398940645, Validation Accuracy: 79.28%\nEpoch 43, Loss: 0.0006138691882039315, Validation Accuracy: 79.08%\nEpoch 44, Loss: 0.0006637755162625002, Validation Accuracy: 79.48%\nEpoch 45, Loss: 0.0006172170784669685, Validation Accuracy: 79.1%\nEpoch 46, Loss: 0.0005962440922799447, Validation Accuracy: 79.4%\nEpoch 47, Loss: 0.0005965488128574427, Validation Accuracy: 79.24%\nEpoch 48, Loss: 0.000601285923122222, Validation Accuracy: 79.3%\nEpoch 49, Loss: 0.0005995933260320188, Validation Accuracy: 79.16%\nEpoch 50, Loss: 0.0005715062541805145, Validation Accuracy: 79.24%\nEpoch 51, Loss: 0.0005678922400627264, Validation Accuracy: 79.36%\nEpoch 52, Loss: 0.0005656919890746146, Validation Accuracy: 79.28%\nEpoch 53, Loss: 0.00057428818085596, Validation Accuracy: 79.26%\nEpoch 54, Loss: 0.0005662345842707014, Validation Accuracy: 79.36%\nEpoch 55, Loss: 0.0005466378354619585, Validation Accuracy: 79.42%\nEpoch 56, Loss: 0.0005442013754707824, Validation Accuracy: 79.18%\nEpoch 57, Loss: 0.0005446295055497268, Validation Accuracy: 79.14%\nEpoch 58, Loss: 0.0005516662423278004, Validation Accuracy: 79.42%\nEpoch 59, Loss: 0.0005164180925434762, Validation Accuracy: 79.28%\nEpoch 60, Loss: 0.0005124374606153156, Validation Accuracy: 79.52%\nEpoch 61, Loss: 0.0005245823713266873, Validation Accuracy: 79.28%\nEpoch 62, Loss: 0.0005062918806453871, Validation Accuracy: 79.54%\nEpoch 63, Loss: 0.000516454150453104, Validation Accuracy: 79.56%\nEpoch 64, Loss: 0.0005216208779860277, Validation Accuracy: 79.12%\nEpoch 65, Loss: 0.0005166074658766527, Validation Accuracy: 79.12%\nEpoch 66, Loss: 0.000512789081602188, Validation Accuracy: 79.28%\nEpoch 67, Loss: 0.000515591465624642, Validation Accuracy: 79.44%\nEpoch 68, Loss: 0.0004961095940995041, Validation Accuracy: 79.26%\nEpoch 69, Loss: 0.00048175497993890366, Validation Accuracy: 79.34%\nEpoch 70, Loss: 0.000503667439261335, Validation Accuracy: 79.16%\nEpoch 71, Loss: 0.000501227866648564, Validation Accuracy: 79.24%\nEpoch 72, Loss: 0.00048599171552930124, Validation Accuracy: 79.28%\nEpoch 73, Loss: 0.0005034237116309338, Validation Accuracy: 79.5%\nEpoch 74, Loss: 0.0005031349251525667, Validation Accuracy: 79.14%\nEpoch 75, Loss: 0.0004889100569843405, Validation Accuracy: 79.58%\nEpoch 76, Loss: 0.00047588624974278815, Validation Accuracy: 78.98%\nEpoch 77, Loss: 0.0004909882595298272, Validation Accuracy: 79.32%\nEpoch 78, Loss: 0.000475160108883508, Validation Accuracy: 79.34%\nEpoch 79, Loss: 0.0005037042964514429, Validation Accuracy: 79.1%\nEpoch 80, Loss: 0.0004888904642774088, Validation Accuracy: 79.12%\nEpoch 81, Loss: 0.0004965420550681963, Validation Accuracy: 79.32%\nEpoch 82, Loss: 0.00048555889944426866, Validation Accuracy: 79.18%\nEpoch 83, Loss: 0.0004825910990058963, Validation Accuracy: 79.34%\nEpoch 84, Loss: 0.0004886560881542126, Validation Accuracy: 79.2%\nEpoch 85, Loss: 0.0004648208759218423, Validation Accuracy: 79.42%\nEpoch 86, Loss: 0.00046701894610702186, Validation Accuracy: 79.04%\nEpoch 87, Loss: 0.00045358213244319563, Validation Accuracy: 79.34%\nEpoch 88, Loss: 0.0004772308255848078, Validation Accuracy: 79.2%\nEpoch 89, Loss: 0.0004655774139130451, Validation Accuracy: 79.36%\nEpoch 90, Loss: 0.00047155708873767503, Validation Accuracy: 79.52%\nEpoch 91, Loss: 0.00046041515261921717, Validation Accuracy: 79.34%\nEpoch 92, Loss: 0.0004822724458790617, Validation Accuracy: 79.5%\nEpoch 93, Loss: 0.0004674211053580538, Validation Accuracy: 79.5%\nEpoch 94, Loss: 0.0004638505511552053, Validation Accuracy: 79.6%\nEpoch 95, Loss: 0.00046452331116597634, Validation Accuracy: 79.26%\nEpoch 96, Loss: 0.0004560160597396713, Validation Accuracy: 79.22%\nEpoch 97, Loss: 0.00046973436540363104, Validation Accuracy: 79.28%\nEpoch 98, Loss: 0.00045346055995568434, Validation Accuracy: 79.32%\nEpoch 99, Loss: 0.00045101492068252725, Validation Accuracy: 79.54%\nEpoch 100, Loss: 0.0004626968169842175, Validation Accuracy: 79.18%\nSubmission5 file saved.\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"# cross check: https://colab.research.google.com/drive/1eI2nQYt2EH88-17wrKx-4E_wO4ZCAL9K#scrollTo=JUK7G7_Dboyf\n# class name: https://medium.com/@thatchawin.ler/cifar10-with-resnet-in-pytorch-a86fe18049df\n\nimport numpy as np\nimport pandas as pd\nimport os\nimport pickle\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nfrom torch.utils.data import DataLoader, random_split, TensorDataset\nfrom torch.optim.lr_scheduler import StepLR\nfrom PIL import Image\nimport torch.optim.lr_scheduler as lr_scheduler\n\n# auto. choose CPU or GPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n# Function to load CIFAR-10 dataset\ndef load_cifar_batch(file):\n    with open(file, 'rb') as fo:\n        dict = pickle.load(fo, encoding='bytes')\n    return dict\n\n# Specify the directory containing CIFAR-10 batches\ncifar10_dir = '/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py'\n\n# Load metadata (labels)\nmeta_data_dict = load_cifar_batch(os.path.join(cifar10_dir, 'batches.meta'))\nlabel_names = [label.decode('utf-8') for label in meta_data_dict[b'label_names']]\n\n# Load training data\ntrain_data = []\ntrain_labels = []\nfor i in range(1, 6):\n    batch = load_cifar_batch(os.path.join(cifar10_dir, f'data_batch_{i}'))\n    train_data.append(batch[b'data'])\n    train_labels += batch[b'labels']\n\ntrain_data = np.vstack(train_data).reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)  # Convert to HWC format\ntrain_labels = np.array(train_labels)\n\n# Data augmentation and normalization\ntransform = transforms.Compose([\n    transforms.ToPILImage(),  # Convert numpy array to PIL Image\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(brightness = 0.1,contrast = 0.1,saturation = 0.1),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomAdjustSharpness(sharpness_factor = 2,p = 0.2),\n    transforms.RandomCrop(32, padding=4),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n    transforms.RandomErasing(p=0.2,scale=(0.02, 0.1),value=1.0, inplace=False)\n])\n\n# Convert to TensorDataset and apply transformations\ntrain_dataset = [(transform(img), label) for img, label in zip(train_data, train_labels)]\n\n# Split into training and validation sets\ntrain_size = int(0.9 * len(train_dataset))\nval_size = len(train_dataset) - train_size\ntrain_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n\n# Load test dataset\ncifar_test_path = '/kaggle/input/deep-learning-spring-2025-project-1/cifar_test_nolabel.pkl'\ntest_batch = load_cifar_batch(cifar_test_path)\ntest_images = test_batch[b'data'].astype(np.float32) / 255.0\n\n# Convert test dataset to Tensor\ntest_dataset = [(transform(img),) for img in test_images]\ntest_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4)\n\n# DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=4)\n\n# Train function\ndef train_model(model, train_loader, val_loader, epochs=50):\n    criterion = nn.CrossEntropyLoss()\n    #optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n    optimizer = optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=1e-4) #change lr\n    #scheduler = StepLR(optimizer, step_size=20, gamma=0.1)\n    scheduler = StepLR(optimizer, step_size=6, gamma=0.85)\n\n    \n    for epoch in range(epochs):\n        model.train()\n        running_loss = 0.0\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        \n        model.eval()\n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                _, predicted = torch.max(outputs, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n        \n        scheduler.step()\n        print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}, Validation Accuracy: {100 * correct / total}%')\n\n# Define a custom ResNet model from scratch\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.skip = nn.Sequential()\n        if stride != 1 or in_channels != out_channels:\n            self.skip = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels)\n            )\n    def forward(self, x):\n        identity = x \n        if self.skip:\n            identity = self.skip(x)\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out += identity\n        out = self.relu(out)\n        return out\n\nclass CustomResNet(nn.Module):\n    def __init__(self, num_classes=10):\n        super(CustomResNet, self).__init__()\n        self.init_conv = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.init_bn = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.layer1 = self._make_layer(64, 64, 3, stride=1)\n        self.layer2 = self._make_layer(64, 64, 4, stride=2)\n        self.layer3 = self._make_layer(64, 128, 4, stride=2)\n        self.layer4 = self._make_layer(128, 256, 3, stride=2)\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Linear(256, num_classes)\n\n    def _make_layer(self, in_channels, out_channels, blocks, stride):\n        layers = [ResidualBlock(in_channels, out_channels, stride)]\n        for _ in range(1, blocks):\n            layers.append(ResidualBlock(out_channels, out_channels))\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = self.init_conv(x)\n        out = self.init_bn(out)\n        out = self.relu(out)\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = self.avg_pool(out)\n        out = torch.flatten(out, 1)\n        out = self.fc(out)\n        return out\n\n# put models to devices (CPU/GPU)\nmodel = CustomResNet().to(device)\n\n# Print the number of parameters\nfrom torchsummary import summary\nsummary(model, (3, 32, 32))\n\n# Train the model\ntrain_model(model, train_loader, val_loader, epochs=200) #change epoch\n# Generate submission file\nmodel.eval()\npredictions = []\nwith torch.no_grad():\n    for batch in test_loader:\n        images = batch[0].to(device)  # Get images tensor from tuple and move to device\n        outputs = model(images) \n        _, predicted = torch.max(outputs, 1)\n        predictions.extend(predicted.cpu().numpy())\n\n# Generate submission file\nsubmission = pd.DataFrame({'ID': np.arange(len(predictions)), 'Labels': predictions})\nsubmission.to_csv('/kaggle/working/submission6.csv', index=False)\nprint(\"Submission6 file saved.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T11:07:08.705311Z","iopub.execute_input":"2025-03-09T11:07:08.705539Z","execution_failed":"2025-03-09T12:50:27.550Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1           [-1, 64, 32, 32]           1,728\n       BatchNorm2d-2           [-1, 64, 32, 32]             128\n              ReLU-3           [-1, 64, 32, 32]               0\n            Conv2d-4           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-5           [-1, 64, 32, 32]             128\n              ReLU-6           [-1, 64, 32, 32]               0\n            Conv2d-7           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-8           [-1, 64, 32, 32]             128\n              ReLU-9           [-1, 64, 32, 32]               0\n    ResidualBlock-10           [-1, 64, 32, 32]               0\n           Conv2d-11           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-12           [-1, 64, 32, 32]             128\n             ReLU-13           [-1, 64, 32, 32]               0\n           Conv2d-14           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-15           [-1, 64, 32, 32]             128\n             ReLU-16           [-1, 64, 32, 32]               0\n    ResidualBlock-17           [-1, 64, 32, 32]               0\n           Conv2d-18           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-19           [-1, 64, 32, 32]             128\n             ReLU-20           [-1, 64, 32, 32]               0\n           Conv2d-21           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-22           [-1, 64, 32, 32]             128\n             ReLU-23           [-1, 64, 32, 32]               0\n    ResidualBlock-24           [-1, 64, 32, 32]               0\n           Conv2d-25           [-1, 64, 16, 16]           4,096\n      BatchNorm2d-26           [-1, 64, 16, 16]             128\n           Conv2d-27           [-1, 64, 16, 16]          36,864\n      BatchNorm2d-28           [-1, 64, 16, 16]             128\n             ReLU-29           [-1, 64, 16, 16]               0\n           Conv2d-30           [-1, 64, 16, 16]          36,864\n      BatchNorm2d-31           [-1, 64, 16, 16]             128\n             ReLU-32           [-1, 64, 16, 16]               0\n    ResidualBlock-33           [-1, 64, 16, 16]               0\n           Conv2d-34           [-1, 64, 16, 16]          36,864\n      BatchNorm2d-35           [-1, 64, 16, 16]             128\n             ReLU-36           [-1, 64, 16, 16]               0\n           Conv2d-37           [-1, 64, 16, 16]          36,864\n      BatchNorm2d-38           [-1, 64, 16, 16]             128\n             ReLU-39           [-1, 64, 16, 16]               0\n    ResidualBlock-40           [-1, 64, 16, 16]               0\n           Conv2d-41           [-1, 64, 16, 16]          36,864\n      BatchNorm2d-42           [-1, 64, 16, 16]             128\n             ReLU-43           [-1, 64, 16, 16]               0\n           Conv2d-44           [-1, 64, 16, 16]          36,864\n      BatchNorm2d-45           [-1, 64, 16, 16]             128\n             ReLU-46           [-1, 64, 16, 16]               0\n    ResidualBlock-47           [-1, 64, 16, 16]               0\n           Conv2d-48           [-1, 64, 16, 16]          36,864\n      BatchNorm2d-49           [-1, 64, 16, 16]             128\n             ReLU-50           [-1, 64, 16, 16]               0\n           Conv2d-51           [-1, 64, 16, 16]          36,864\n      BatchNorm2d-52           [-1, 64, 16, 16]             128\n             ReLU-53           [-1, 64, 16, 16]               0\n    ResidualBlock-54           [-1, 64, 16, 16]               0\n           Conv2d-55            [-1, 128, 8, 8]           8,192\n      BatchNorm2d-56            [-1, 128, 8, 8]             256\n           Conv2d-57            [-1, 128, 8, 8]          73,728\n      BatchNorm2d-58            [-1, 128, 8, 8]             256\n             ReLU-59            [-1, 128, 8, 8]               0\n           Conv2d-60            [-1, 128, 8, 8]         147,456\n      BatchNorm2d-61            [-1, 128, 8, 8]             256\n             ReLU-62            [-1, 128, 8, 8]               0\n    ResidualBlock-63            [-1, 128, 8, 8]               0\n           Conv2d-64            [-1, 128, 8, 8]         147,456\n      BatchNorm2d-65            [-1, 128, 8, 8]             256\n             ReLU-66            [-1, 128, 8, 8]               0\n           Conv2d-67            [-1, 128, 8, 8]         147,456\n      BatchNorm2d-68            [-1, 128, 8, 8]             256\n             ReLU-69            [-1, 128, 8, 8]               0\n    ResidualBlock-70            [-1, 128, 8, 8]               0\n           Conv2d-71            [-1, 128, 8, 8]         147,456\n      BatchNorm2d-72            [-1, 128, 8, 8]             256\n             ReLU-73            [-1, 128, 8, 8]               0\n           Conv2d-74            [-1, 128, 8, 8]         147,456\n      BatchNorm2d-75            [-1, 128, 8, 8]             256\n             ReLU-76            [-1, 128, 8, 8]               0\n    ResidualBlock-77            [-1, 128, 8, 8]               0\n           Conv2d-78            [-1, 128, 8, 8]         147,456\n      BatchNorm2d-79            [-1, 128, 8, 8]             256\n             ReLU-80            [-1, 128, 8, 8]               0\n           Conv2d-81            [-1, 128, 8, 8]         147,456\n      BatchNorm2d-82            [-1, 128, 8, 8]             256\n             ReLU-83            [-1, 128, 8, 8]               0\n    ResidualBlock-84            [-1, 128, 8, 8]               0\n           Conv2d-85            [-1, 256, 4, 4]          32,768\n      BatchNorm2d-86            [-1, 256, 4, 4]             512\n           Conv2d-87            [-1, 256, 4, 4]         294,912\n      BatchNorm2d-88            [-1, 256, 4, 4]             512\n             ReLU-89            [-1, 256, 4, 4]               0\n           Conv2d-90            [-1, 256, 4, 4]         589,824\n      BatchNorm2d-91            [-1, 256, 4, 4]             512\n             ReLU-92            [-1, 256, 4, 4]               0\n    ResidualBlock-93            [-1, 256, 4, 4]               0\n           Conv2d-94            [-1, 256, 4, 4]         589,824\n      BatchNorm2d-95            [-1, 256, 4, 4]             512\n             ReLU-96            [-1, 256, 4, 4]               0\n           Conv2d-97            [-1, 256, 4, 4]         589,824\n      BatchNorm2d-98            [-1, 256, 4, 4]             512\n             ReLU-99            [-1, 256, 4, 4]               0\n   ResidualBlock-100            [-1, 256, 4, 4]               0\n          Conv2d-101            [-1, 256, 4, 4]         589,824\n     BatchNorm2d-102            [-1, 256, 4, 4]             512\n            ReLU-103            [-1, 256, 4, 4]               0\n          Conv2d-104            [-1, 256, 4, 4]         589,824\n     BatchNorm2d-105            [-1, 256, 4, 4]             512\n            ReLU-106            [-1, 256, 4, 4]               0\n   ResidualBlock-107            [-1, 256, 4, 4]               0\nAdaptiveAvgPool2d-108            [-1, 256, 1, 1]               0\n          Linear-109                   [-1, 10]           2,570\n================================================================\nTotal params: 4,923,338\nTrainable params: 4,923,338\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.01\nForward/backward pass size (MB): 18.35\nParams size (MB): 18.78\nEstimated Total Size (MB): 37.14\n----------------------------------------------------------------\nEpoch 1, Loss: 1.6043191829865628, Validation Accuracy: 47.68%\nEpoch 2, Loss: 1.1767668436196717, Validation Accuracy: 57.64%\nEpoch 3, Loss: 0.9412734862416983, Validation Accuracy: 65.08%\nEpoch 4, Loss: 0.7503722774880853, Validation Accuracy: 64.86%\nEpoch 5, Loss: 0.6122283179482276, Validation Accuracy: 69.16%\nEpoch 6, Loss: 0.4862242749130184, Validation Accuracy: 69.66%\nEpoch 7, Loss: 0.3344794587994164, Validation Accuracy: 63.42%\nEpoch 8, Loss: 0.2441101340704005, Validation Accuracy: 68.42%\nEpoch 9, Loss: 0.1784732136134566, Validation Accuracy: 68.8%\nEpoch 10, Loss: 0.1506506531785073, Validation Accuracy: 69.64%\nEpoch 11, Loss: 0.10958227278685874, Validation Accuracy: 67.74%\nEpoch 12, Loss: 0.0934551761972464, Validation Accuracy: 70.36%\nEpoch 13, Loss: 0.04406465749277479, Validation Accuracy: 71.66%\nEpoch 14, Loss: 0.0181579337083597, Validation Accuracy: 73.46%\nEpoch 15, Loss: 0.009171684989930574, Validation Accuracy: 74.92%\nEpoch 16, Loss: 0.0022356953873399602, Validation Accuracy: 75.5%\nEpoch 17, Loss: 0.001094466790784116, Validation Accuracy: 75.9%\nEpoch 18, Loss: 0.000673875882305517, Validation Accuracy: 75.76%\nEpoch 19, Loss: 0.0005238676625264237, Validation Accuracy: 75.74%\nEpoch 20, Loss: 0.0004834361644828856, Validation Accuracy: 75.9%\nEpoch 21, Loss: 0.00044671544258728153, Validation Accuracy: 76.0%\nEpoch 22, Loss: 0.0003765790140732861, Validation Accuracy: 75.8%\nEpoch 23, Loss: 0.00034132186572771224, Validation Accuracy: 75.92%\nEpoch 24, Loss: 0.000329667973036604, Validation Accuracy: 75.98%\nEpoch 25, Loss: 0.0003126421392855925, Validation Accuracy: 75.9%\nEpoch 26, Loss: 0.0002976406848864082, Validation Accuracy: 76.16%\nEpoch 27, Loss: 0.0002542393477101128, Validation Accuracy: 75.96%\nEpoch 28, Loss: 0.0002546279837671054, Validation Accuracy: 76.1%\nEpoch 29, Loss: 0.00023973974411588145, Validation Accuracy: 75.84%\nEpoch 30, Loss: 0.00026101371827280673, Validation Accuracy: 75.96%\nEpoch 31, Loss: 0.00022514509200019265, Validation Accuracy: 75.96%\nEpoch 32, Loss: 0.0002306304727012916, Validation Accuracy: 76.0%\nEpoch 33, Loss: 0.00020964380424133694, Validation Accuracy: 75.96%\nEpoch 34, Loss: 0.0002455150674698168, Validation Accuracy: 75.94%\nEpoch 35, Loss: 0.00021074825067237478, Validation Accuracy: 75.98%\nEpoch 36, Loss: 0.00021474844662737848, Validation Accuracy: 75.98%\nEpoch 37, Loss: 0.00019421721541138223, Validation Accuracy: 76.22%\nEpoch 38, Loss: 0.00019588923057447326, Validation Accuracy: 76.08%\nEpoch 39, Loss: 0.00019388042125518206, Validation Accuracy: 76.02%\nEpoch 40, Loss: 0.00018275251517769158, Validation Accuracy: 76.08%\nEpoch 41, Loss: 0.00017391950139385287, Validation Accuracy: 76.14%\nEpoch 42, Loss: 0.00017629308601127295, Validation Accuracy: 76.02%\nEpoch 43, Loss: 0.00019065524886421124, Validation Accuracy: 76.24%\nEpoch 44, Loss: 0.00017967512514422361, Validation Accuracy: 76.2%\nEpoch 45, Loss: 0.00016807985120563401, Validation Accuracy: 76.02%\nEpoch 46, Loss: 0.00018782546101192565, Validation Accuracy: 76.08%\nEpoch 47, Loss: 0.0001785813070682707, Validation Accuracy: 76.08%\nEpoch 48, Loss: 0.00016336474001573978, Validation Accuracy: 76.14%\nEpoch 49, Loss: 0.00017725132021372372, Validation Accuracy: 76.1%\nEpoch 50, Loss: 0.00016686541156022113, Validation Accuracy: 76.12%\nEpoch 51, Loss: 0.00015816007015184203, Validation Accuracy: 75.94%\nEpoch 52, Loss: 0.00015907721430349656, Validation Accuracy: 76.08%\nEpoch 53, Loss: 0.00015749146911564986, Validation Accuracy: 75.74%\nEpoch 54, Loss: 0.00015495839756402512, Validation Accuracy: 76.0%\nEpoch 55, Loss: 0.00016413852058990002, Validation Accuracy: 76.08%\nEpoch 56, Loss: 0.00014951320187347764, Validation Accuracy: 76.04%\nEpoch 57, Loss: 0.00015352933555525604, Validation Accuracy: 76.06%\nEpoch 58, Loss: 0.00017115179637337198, Validation Accuracy: 76.02%\nEpoch 59, Loss: 0.0001534786656210682, Validation Accuracy: 76.06%\nEpoch 60, Loss: 0.00015051391409832087, Validation Accuracy: 76.2%\nEpoch 61, Loss: 0.0001413743631866799, Validation Accuracy: 76.14%\nEpoch 62, Loss: 0.00015338546909953783, Validation Accuracy: 75.94%\nEpoch 63, Loss: 0.00015042221408831128, Validation Accuracy: 76.26%\nEpoch 64, Loss: 0.00015174429975931244, Validation Accuracy: 76.28%\nEpoch 65, Loss: 0.00014138242873038755, Validation Accuracy: 75.92%\nEpoch 66, Loss: 0.00014737308728482193, Validation Accuracy: 76.26%\nEpoch 67, Loss: 0.0001519301701323043, Validation Accuracy: 75.86%\nEpoch 68, Loss: 0.00014461411120175234, Validation Accuracy: 76.1%\nEpoch 69, Loss: 0.00015894368641511392, Validation Accuracy: 76.04%\nEpoch 70, Loss: 0.00014354124886556912, Validation Accuracy: 75.96%\nEpoch 71, Loss: 0.00014534426895806973, Validation Accuracy: 76.04%\nEpoch 72, Loss: 0.00014220236185089809, Validation Accuracy: 76.06%\nEpoch 73, Loss: 0.00015335133851253474, Validation Accuracy: 76.04%\nEpoch 74, Loss: 0.00013980369395870764, Validation Accuracy: 76.06%\nEpoch 75, Loss: 0.0001366237675442376, Validation Accuracy: 75.94%\nEpoch 76, Loss: 0.00014155841110798727, Validation Accuracy: 76.1%\nEpoch 77, Loss: 0.00015478483918617383, Validation Accuracy: 75.86%\nEpoch 78, Loss: 0.00013697200337115976, Validation Accuracy: 76.04%\nEpoch 79, Loss: 0.0001425237928639366, Validation Accuracy: 76.14%\nEpoch 80, Loss: 0.00014897016284397648, Validation Accuracy: 75.9%\nEpoch 81, Loss: 0.00013258958674875677, Validation Accuracy: 76.12%\nEpoch 82, Loss: 0.0001329150847327169, Validation Accuracy: 76.16%\nEpoch 83, Loss: 0.00013389790040657152, Validation Accuracy: 76.06%\nEpoch 84, Loss: 0.00013901805150660286, Validation Accuracy: 76.28%\nEpoch 85, Loss: 0.000136858696857251, Validation Accuracy: 76.0%\nEpoch 86, Loss: 0.0001357211863457699, Validation Accuracy: 76.04%\nEpoch 87, Loss: 0.0001374631403491962, Validation Accuracy: 75.96%\nEpoch 88, Loss: 0.00012973604687390022, Validation Accuracy: 75.96%\nEpoch 89, Loss: 0.00012486142695293395, Validation Accuracy: 76.16%\nEpoch 90, Loss: 0.0001336047559809892, Validation Accuracy: 76.14%\nEpoch 91, Loss: 0.00012988840344198914, Validation Accuracy: 75.94%\nEpoch 92, Loss: 0.0001338302972003062, Validation Accuracy: 76.26%\nEpoch 93, Loss: 0.00013206597934227332, Validation Accuracy: 76.28%\nEpoch 94, Loss: 0.00013725042266411367, Validation Accuracy: 76.2%\nEpoch 95, Loss: 0.00013419339655807892, Validation Accuracy: 76.2%\nEpoch 96, Loss: 0.0001324822399779309, Validation Accuracy: 76.12%\nEpoch 97, Loss: 0.00013101077221025744, Validation Accuracy: 76.04%\nEpoch 98, Loss: 0.00013074692755956428, Validation Accuracy: 76.02%\nEpoch 99, Loss: 0.00013451831064644054, Validation Accuracy: 76.2%\nEpoch 100, Loss: 0.00013662386957300689, Validation Accuracy: 75.82%\nEpoch 101, Loss: 0.00013131938261391372, Validation Accuracy: 76.24%\nEpoch 102, Loss: 0.000138314725652642, Validation Accuracy: 76.02%\nEpoch 103, Loss: 0.00013289890139069692, Validation Accuracy: 76.1%\nEpoch 104, Loss: 0.00012181772344568095, Validation Accuracy: 75.96%\nEpoch 105, Loss: 0.00012751822576071638, Validation Accuracy: 76.14%\nEpoch 106, Loss: 0.0001337190123897678, Validation Accuracy: 75.96%\nEpoch 107, Loss: 0.0001345275323232768, Validation Accuracy: 76.06%\nEpoch 108, Loss: 0.00012984938245029878, Validation Accuracy: 75.92%\nEpoch 109, Loss: 0.00012649752206719066, Validation Accuracy: 76.12%\nEpoch 110, Loss: 0.00014243829038853372, Validation Accuracy: 76.12%\nEpoch 111, Loss: 0.00012705064203931795, Validation Accuracy: 75.86%\nEpoch 112, Loss: 0.00013777845240590315, Validation Accuracy: 75.9%\nEpoch 113, Loss: 0.00013425082365549977, Validation Accuracy: 75.94%\nEpoch 114, Loss: 0.00012139406825636715, Validation Accuracy: 76.06%\nEpoch 115, Loss: 0.0001290039914155469, Validation Accuracy: 76.1%\nEpoch 116, Loss: 0.00012748320398259239, Validation Accuracy: 76.14%\nEpoch 117, Loss: 0.00013468513527021224, Validation Accuracy: 76.1%\nEpoch 118, Loss: 0.00013058202669278464, Validation Accuracy: 76.1%\nEpoch 119, Loss: 0.0001295136953248485, Validation Accuracy: 76.02%\nEpoch 120, Loss: 0.00013319146877289643, Validation Accuracy: 75.9%\nEpoch 121, Loss: 0.00012418198672424876, Validation Accuracy: 75.98%\nEpoch 122, Loss: 0.00012424067236596866, Validation Accuracy: 76.2%\nEpoch 123, Loss: 0.00013241627632189855, Validation Accuracy: 76.18%\nEpoch 124, Loss: 0.00012811736737396794, Validation Accuracy: 76.1%\nEpoch 125, Loss: 0.00012576758953483395, Validation Accuracy: 76.08%\nEpoch 126, Loss: 0.00012507037510286781, Validation Accuracy: 76.26%\nEpoch 127, Loss: 0.00012852726706569229, Validation Accuracy: 75.96%\nEpoch 128, Loss: 0.0001314721180278866, Validation Accuracy: 76.22%\nEpoch 129, Loss: 0.00012732218144926512, Validation Accuracy: 76.0%\nEpoch 130, Loss: 0.0001240295103198977, Validation Accuracy: 76.04%\nEpoch 131, Loss: 0.0001301944418876453, Validation Accuracy: 75.92%\nEpoch 132, Loss: 0.00013721419953650513, Validation Accuracy: 76.2%\nEpoch 133, Loss: 0.00012753632531505653, Validation Accuracy: 76.0%\nEpoch 134, Loss: 0.00012504380574476025, Validation Accuracy: 76.0%\nEpoch 135, Loss: 0.00012978849513894437, Validation Accuracy: 76.0%\nEpoch 136, Loss: 0.0001331614842001727, Validation Accuracy: 76.06%\nEpoch 137, Loss: 0.00012799613451038155, Validation Accuracy: 76.06%\nEpoch 138, Loss: 0.00012285774036255052, Validation Accuracy: 76.06%\nEpoch 139, Loss: 0.00012610056470211103, Validation Accuracy: 75.96%\nEpoch 140, Loss: 0.0001279681437980881, Validation Accuracy: 76.06%\nEpoch 141, Loss: 0.0001264528970688678, Validation Accuracy: 75.94%\nEpoch 142, Loss: 0.0001174126762903556, Validation Accuracy: 75.98%\nEpoch 143, Loss: 0.00012875904747033928, Validation Accuracy: 76.12%\nEpoch 144, Loss: 0.00011984314660780497, Validation Accuracy: 76.0%\nEpoch 145, Loss: 0.0001279793256633804, Validation Accuracy: 75.96%\nEpoch 146, Loss: 0.00012671819523678675, Validation Accuracy: 75.86%\nEpoch 147, Loss: 0.00012176804233893728, Validation Accuracy: 76.06%\nEpoch 148, Loss: 0.0001284688910139018, Validation Accuracy: 76.1%\nEpoch 149, Loss: 0.00012376197671735346, Validation Accuracy: 76.04%\nEpoch 150, Loss: 0.00013019611997771625, Validation Accuracy: 76.0%\nEpoch 151, Loss: 0.0001331981248065197, Validation Accuracy: 76.08%\nEpoch 152, Loss: 0.00013601594581690404, Validation Accuracy: 76.04%\nEpoch 153, Loss: 0.0001338150594640617, Validation Accuracy: 75.94%\nEpoch 154, Loss: 0.00012966484395995147, Validation Accuracy: 76.14%\nEpoch 155, Loss: 0.00012478073576651448, Validation Accuracy: 76.06%\nEpoch 156, Loss: 0.00012908919573171508, Validation Accuracy: 76.28%\nEpoch 157, Loss: 0.00013013756816607466, Validation Accuracy: 76.12%\nEpoch 158, Loss: 0.00012375851274141908, Validation Accuracy: 75.94%\nEpoch 159, Loss: 0.00013355707588661144, Validation Accuracy: 76.2%\nEpoch 160, Loss: 0.00012229493073722222, Validation Accuracy: 76.14%\nEpoch 161, Loss: 0.00012302850998160218, Validation Accuracy: 76.22%\nEpoch 162, Loss: 0.00013246615453061332, Validation Accuracy: 76.02%\nEpoch 163, Loss: 0.00012079334454607637, Validation Accuracy: 76.14%\nEpoch 164, Loss: 0.0001343360761852223, Validation Accuracy: 76.1%\nEpoch 165, Loss: 0.00012459683618585999, Validation Accuracy: 76.12%\nEpoch 166, Loss: 0.00012108424002897003, Validation Accuracy: 75.98%\nEpoch 167, Loss: 0.00013157392392961563, Validation Accuracy: 76.16%\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport pickle\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nfrom torch.utils.data import DataLoader, random_split, TensorDataset\nfrom torch.optim.lr_scheduler import StepLR\nfrom PIL import Image\nimport torch.optim.lr_scheduler as lr_scheduler\n\n# auto. choose CPU or GPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n# Function to load CIFAR-10 dataset\ndef load_cifar_batch(file):\n    with open(file, 'rb') as fo:\n        dict = pickle.load(fo, encoding='bytes')\n    return dict\n\n# Specify the directory containing CIFAR-10 batches\ncifar10_dir = '/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py'\n\n# Load metadata (labels)\nmeta_data_dict = load_cifar_batch(os.path.join(cifar10_dir, 'batches.meta'))\nlabel_names = [label.decode('utf-8') for label in meta_data_dict[b'label_names']]\n\n# Load training data\ntrain_data = []\ntrain_labels = []\nfor i in range(1, 6):\n    batch = load_cifar_batch(os.path.join(cifar10_dir, f'data_batch_{i}'))\n    train_data.append(batch[b'data'])\n    train_labels += batch[b'labels']\n\ntrain_data = np.vstack(train_data).reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)  # Convert to HWC format\ntrain_labels = np.array(train_labels)\n\n# Data augmentation and normalization\ntransform = transforms.Compose([\n    transforms.ToPILImage(),  # Convert numpy array to PIL Image\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(brightness = 0.1,contrast = 0.1,saturation = 0.1),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomAdjustSharpness(sharpness_factor = 2,p = 0.2),\n    transforms.RandomCrop(32, padding=4),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n    transforms.RandomErasing(p=0.2,scale=(0.02, 0.1),value=1.0, inplace=False)\n])\n\n# Convert to TensorDataset and apply transformations\nclass CustomCIFAR10Dataset(torch.utils.data.Dataset):\n    def __init__(self, images, labels, transform=None):\n        self.images = images\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        img = self.images[idx]\n        label = self.labels[idx]\n\n        if self.transform:\n            img = self.transform(img)\n\n        return img, label\n\ntrain_dataset = CustomCIFAR10Dataset(train_data, train_labels, transform=transform)\n\n# Split into training and validation sets\ntrain_size = int(0.9 * len(train_dataset))\nval_size = len(train_dataset) - train_size\ntrain_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n\n# DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=4)\n\n# Load test dataset\ncifar_test_path = '/kaggle/input/deep-learning-spring-2025-project-1/cifar_test_nolabel.pkl'\ntest_batch = load_cifar_batch(cifar_test_path)\ntest_images = test_batch[b'data'].astype(np.float32) / 255.0\n\ntest_transform = transforms.Compose([\n    transforms.ToPILImage(),  # Convert numpy array to PIL Image\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n])\n\n# Convert test dataset to Tensor\ntest_dataset = [(test_transform(img),) for img in test_images]\ntest_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4)\n\n# Train function\ndef train_model(model, train_loader, val_loader, epochs=50):\n    criterion = nn.CrossEntropyLoss()\n    #optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n    optimizer = optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=1e-4) #change lr\n    #scheduler = StepLR(optimizer, step_size=20, gamma=0.1)\n    scheduler = StepLR(optimizer, step_size=6, gamma=0.85)\n\n    \n    for epoch in range(epochs):\n        model.train()\n        running_loss = 0.0\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        \n        model.eval()\n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                _, predicted = torch.max(outputs, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n        \n        scheduler.step()\n        print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}, Validation Accuracy: {100 * correct / total}%')\n\n# Define a custom ResNet model from scratch\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.skip = nn.Sequential()\n        if stride != 1 or in_channels != out_channels:\n            self.skip = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels)\n            )\n    def forward(self, x):\n        identity = x \n        if self.skip:\n            identity = self.skip(x)\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out += identity\n        out = self.relu(out)\n        return out\n\nclass CustomResNet(nn.Module):\n    def __init__(self, num_classes=10):\n        super(CustomResNet, self).__init__()\n        self.init_conv = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.init_bn = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.layer1 = self._make_layer(64, 64, 2, stride=1)\n        self.layer2 = self._make_layer(64, 128, 2, stride=2)\n        self.layer3 = self._make_layer(128, 256, 2, stride=2)\n        #self.layer4 = self._make_layer(256, 512, 2, stride=2)\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Linear(256, num_classes)\n\n    def _make_layer(self, in_channels, out_channels, blocks, stride):\n        layers = [ResidualBlock(in_channels, out_channels, stride)]\n        for _ in range(1, blocks):\n            layers.append(ResidualBlock(out_channels, out_channels))\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = self.init_conv(x)\n        out = self.init_bn(out)\n        out = self.relu(out)\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        #out = self.layer4(out)\n        out = self.avg_pool(out)\n        out = torch.flatten(out, 1)\n        out = self.fc(out)\n        return out\n\n# put models to devices (CPU/GPU)\nmodel = CustomResNet().to(device)\n\n# Print the number of parameters\nfrom torchsummary import summary\nsummary(model, (3, 32, 32))\n\n# Train the model\ntrain_model(model, train_loader, val_loader, epochs=100) #change epoch\n\n# Generate submission file\nmodel.eval()\npredictions = []\nwith torch.no_grad():\n    for batch in test_loader:\n        images = batch[0].to(device)  # Get images tensor from tuple and move to device\n        outputs = model(images) \n        _, predicted = torch.max(outputs, 1)\n        predictions.extend(predicted.cpu().numpy())\n\n# Generate submission file\nsubmission = pd.DataFrame({'ID': np.arange(len(predictions)), 'Labels': predictions})\nsubmission.to_csv('/kaggle/working/submission6.csv', index=False)\nprint(\"Submission6 file saved.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T13:22:31.842522Z","iopub.execute_input":"2025-03-09T13:22:31.842855Z","iopub.status.idle":"2025-03-09T14:12:40.312995Z","shell.execute_reply.started":"2025-03-09T13:22:31.842827Z","shell.execute_reply":"2025-03-09T14:12:40.311823Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1           [-1, 64, 32, 32]           1,728\n       BatchNorm2d-2           [-1, 64, 32, 32]             128\n              ReLU-3           [-1, 64, 32, 32]               0\n            Conv2d-4           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-5           [-1, 64, 32, 32]             128\n              ReLU-6           [-1, 64, 32, 32]               0\n            Conv2d-7           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-8           [-1, 64, 32, 32]             128\n              ReLU-9           [-1, 64, 32, 32]               0\n    ResidualBlock-10           [-1, 64, 32, 32]               0\n           Conv2d-11           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-12           [-1, 64, 32, 32]             128\n             ReLU-13           [-1, 64, 32, 32]               0\n           Conv2d-14           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-15           [-1, 64, 32, 32]             128\n             ReLU-16           [-1, 64, 32, 32]               0\n    ResidualBlock-17           [-1, 64, 32, 32]               0\n           Conv2d-18          [-1, 128, 16, 16]           8,192\n      BatchNorm2d-19          [-1, 128, 16, 16]             256\n           Conv2d-20          [-1, 128, 16, 16]          73,728\n      BatchNorm2d-21          [-1, 128, 16, 16]             256\n             ReLU-22          [-1, 128, 16, 16]               0\n           Conv2d-23          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-24          [-1, 128, 16, 16]             256\n             ReLU-25          [-1, 128, 16, 16]               0\n    ResidualBlock-26          [-1, 128, 16, 16]               0\n           Conv2d-27          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-28          [-1, 128, 16, 16]             256\n             ReLU-29          [-1, 128, 16, 16]               0\n           Conv2d-30          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-31          [-1, 128, 16, 16]             256\n             ReLU-32          [-1, 128, 16, 16]               0\n    ResidualBlock-33          [-1, 128, 16, 16]               0\n           Conv2d-34            [-1, 256, 8, 8]          32,768\n      BatchNorm2d-35            [-1, 256, 8, 8]             512\n           Conv2d-36            [-1, 256, 8, 8]         294,912\n      BatchNorm2d-37            [-1, 256, 8, 8]             512\n             ReLU-38            [-1, 256, 8, 8]               0\n           Conv2d-39            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-40            [-1, 256, 8, 8]             512\n             ReLU-41            [-1, 256, 8, 8]               0\n    ResidualBlock-42            [-1, 256, 8, 8]               0\n           Conv2d-43            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-44            [-1, 256, 8, 8]             512\n             ReLU-45            [-1, 256, 8, 8]               0\n           Conv2d-46            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-47            [-1, 256, 8, 8]             512\n             ReLU-48            [-1, 256, 8, 8]               0\n    ResidualBlock-49            [-1, 256, 8, 8]               0\nAdaptiveAvgPool2d-50            [-1, 256, 1, 1]               0\n           Linear-51                   [-1, 10]           2,570\n================================================================\nTotal params: 2,777,674\nTrainable params: 2,777,674\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.01\nForward/backward pass size (MB): 14.50\nParams size (MB): 10.60\nEstimated Total Size (MB): 25.11\n----------------------------------------------------------------\nEpoch 1, Loss: 1.5312265929850666, Validation Accuracy: 51.04%\nEpoch 2, Loss: 1.1135703374377706, Validation Accuracy: 58.14%\nEpoch 3, Loss: 0.9401091323657469, Validation Accuracy: 66.14%\nEpoch 4, Loss: 0.8036765302108093, Validation Accuracy: 67.24%\nEpoch 5, Loss: 0.7207149188457564, Validation Accuracy: 69.44%\nEpoch 6, Loss: 0.6596554804762657, Validation Accuracy: 74.34%\nEpoch 7, Loss: 0.5863888330588286, Validation Accuracy: 76.32%\nEpoch 8, Loss: 0.5532390079884366, Validation Accuracy: 78.58%\nEpoch 9, Loss: 0.5169670395553112, Validation Accuracy: 77.28%\nEpoch 10, Loss: 0.4929731472141363, Validation Accuracy: 79.6%\nEpoch 11, Loss: 0.46922370241108263, Validation Accuracy: 79.56%\nEpoch 12, Loss: 0.44182803261686454, Validation Accuracy: 79.86%\nEpoch 13, Loss: 0.40938382261348044, Validation Accuracy: 82.42%\nEpoch 14, Loss: 0.39796243430199946, Validation Accuracy: 81.72%\nEpoch 15, Loss: 0.3822925748642195, Validation Accuracy: 81.82%\nEpoch 16, Loss: 0.3679005816494199, Validation Accuracy: 83.66%\nEpoch 17, Loss: 0.35657337828623975, Validation Accuracy: 82.5%\nEpoch 18, Loss: 0.34733965717764065, Validation Accuracy: 83.82%\nEpoch 19, Loss: 0.3179752739061686, Validation Accuracy: 85.76%\nEpoch 20, Loss: 0.31073153247548774, Validation Accuracy: 83.56%\nEpoch 21, Loss: 0.29754234067249025, Validation Accuracy: 85.9%\nEpoch 22, Loss: 0.2929854413748465, Validation Accuracy: 85.6%\nEpoch 23, Loss: 0.2803878314285116, Validation Accuracy: 83.88%\nEpoch 24, Loss: 0.2773398468059234, Validation Accuracy: 86.82%\nEpoch 25, Loss: 0.25596318317746575, Validation Accuracy: 86.38%\nEpoch 26, Loss: 0.2480827994348312, Validation Accuracy: 86.04%\nEpoch 27, Loss: 0.2427858799611303, Validation Accuracy: 85.36%\nEpoch 28, Loss: 0.23549896944314241, Validation Accuracy: 86.92%\nEpoch 29, Loss: 0.23270530380647292, Validation Accuracy: 86.32%\nEpoch 30, Loss: 0.2232404089405794, Validation Accuracy: 86.36%\nEpoch 31, Loss: 0.20345988518304445, Validation Accuracy: 87.22%\nEpoch 32, Loss: 0.20330486133355985, Validation Accuracy: 88.58%\nEpoch 33, Loss: 0.19296629724770106, Validation Accuracy: 87.7%\nEpoch 34, Loss: 0.18974140081131322, Validation Accuracy: 88.64%\nEpoch 35, Loss: 0.18858310491354627, Validation Accuracy: 87.18%\nEpoch 36, Loss: 0.18818676162680442, Validation Accuracy: 88.76%\nEpoch 37, Loss: 0.16903884258036586, Validation Accuracy: 88.78%\nEpoch 38, Loss: 0.16263594950379973, Validation Accuracy: 88.44%\nEpoch 39, Loss: 0.164055879375982, Validation Accuracy: 87.9%\nEpoch 40, Loss: 0.16156128553715957, Validation Accuracy: 88.5%\nEpoch 41, Loss: 0.15684399750634012, Validation Accuracy: 87.84%\nEpoch 42, Loss: 0.1507067804817449, Validation Accuracy: 88.8%\nEpoch 43, Loss: 0.14345790389713578, Validation Accuracy: 88.46%\nEpoch 44, Loss: 0.13656080509959298, Validation Accuracy: 88.88%\nEpoch 45, Loss: 0.13515597088685768, Validation Accuracy: 88.2%\nEpoch 46, Loss: 0.1329092684900388, Validation Accuracy: 89.6%\nEpoch 47, Loss: 0.13325779671272772, Validation Accuracy: 88.06%\nEpoch 48, Loss: 0.13200397993734275, Validation Accuracy: 88.96%\nEpoch 49, Loss: 0.11651304634076289, Validation Accuracy: 89.14%\nEpoch 50, Loss: 0.11516030093612657, Validation Accuracy: 88.92%\nEpoch 51, Loss: 0.11191888018087907, Validation Accuracy: 89.74%\nEpoch 52, Loss: 0.11149830554230986, Validation Accuracy: 89.94%\nEpoch 53, Loss: 0.10858714737167413, Validation Accuracy: 89.12%\nEpoch 54, Loss: 0.10999393189029599, Validation Accuracy: 88.98%\nEpoch 55, Loss: 0.09982848006554625, Validation Accuracy: 89.48%\nEpoch 56, Loss: 0.09920639133038507, Validation Accuracy: 88.88%\nEpoch 57, Loss: 0.0955154536799951, Validation Accuracy: 90.0%\nEpoch 58, Loss: 0.09563416845313358, Validation Accuracy: 89.2%\nEpoch 59, Loss: 0.0951716041573408, Validation Accuracy: 89.52%\nEpoch 60, Loss: 0.09434995301258327, Validation Accuracy: 89.96%\nEpoch 61, Loss: 0.08859367527871985, Validation Accuracy: 89.9%\nEpoch 62, Loss: 0.08176405318822204, Validation Accuracy: 89.46%\nEpoch 63, Loss: 0.08268252371238884, Validation Accuracy: 90.26%\nEpoch 64, Loss: 0.08251794210148299, Validation Accuracy: 89.62%\nEpoch 65, Loss: 0.08402840746037493, Validation Accuracy: 90.16%\nEpoch 66, Loss: 0.07929084450535645, Validation Accuracy: 89.84%\nEpoch 67, Loss: 0.07485166103155776, Validation Accuracy: 89.5%\nEpoch 68, Loss: 0.07232065098783509, Validation Accuracy: 90.0%\nEpoch 69, Loss: 0.07333219629733569, Validation Accuracy: 90.26%\nEpoch 70, Loss: 0.07314164008924061, Validation Accuracy: 89.92%\nEpoch 71, Loss: 0.06861641561210324, Validation Accuracy: 90.2%\nEpoch 72, Loss: 0.07083263660950417, Validation Accuracy: 90.6%\nEpoch 73, Loss: 0.06447164794239639, Validation Accuracy: 89.62%\nEpoch 74, Loss: 0.06553431611973792, Validation Accuracy: 90.32%\nEpoch 75, Loss: 0.06363840981132605, Validation Accuracy: 90.32%\nEpoch 76, Loss: 0.06274785004048185, Validation Accuracy: 89.98%\nEpoch 77, Loss: 0.0614606784788934, Validation Accuracy: 90.56%\nEpoch 78, Loss: 0.062358888776295564, Validation Accuracy: 89.92%\nEpoch 79, Loss: 0.06071656285679306, Validation Accuracy: 90.3%\nEpoch 80, Loss: 0.05669406533971513, Validation Accuracy: 90.26%\nEpoch 81, Loss: 0.05813410120158964, Validation Accuracy: 89.74%\nEpoch 82, Loss: 0.057345356175739486, Validation Accuracy: 90.66%\nEpoch 83, Loss: 0.058889068186875775, Validation Accuracy: 90.76%\nEpoch 84, Loss: 0.057338602981127966, Validation Accuracy: 89.86%\nEpoch 85, Loss: 0.05366402468114922, Validation Accuracy: 90.42%\nEpoch 86, Loss: 0.05342056181821549, Validation Accuracy: 90.72%\nEpoch 87, Loss: 0.053303043913646514, Validation Accuracy: 90.46%\nEpoch 88, Loss: 0.051491288796321234, Validation Accuracy: 91.04%\nEpoch 89, Loss: 0.051511210860388186, Validation Accuracy: 90.76%\nEpoch 90, Loss: 0.0499107781374319, Validation Accuracy: 90.26%\nEpoch 91, Loss: 0.05169944863882847, Validation Accuracy: 90.28%\nEpoch 92, Loss: 0.04878096554735252, Validation Accuracy: 90.14%\nEpoch 93, Loss: 0.04835367765521038, Validation Accuracy: 90.96%\nEpoch 94, Loss: 0.049875647252933544, Validation Accuracy: 90.5%\nEpoch 95, Loss: 0.047247339637992394, Validation Accuracy: 90.86%\nEpoch 96, Loss: 0.0488486585911067, Validation Accuracy: 90.26%\nEpoch 97, Loss: 0.046771497664105315, Validation Accuracy: 91.0%\nEpoch 98, Loss: 0.04660524454348805, Validation Accuracy: 90.12%\nEpoch 99, Loss: 0.044480886006071654, Validation Accuracy: 91.26%\nEpoch 100, Loss: 0.04621370226959698, Validation Accuracy: 90.62%\nSubmission6 file saved.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport pickle\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nfrom torch.utils.data import DataLoader, random_split, TensorDataset\nfrom torch.optim.lr_scheduler import StepLR\nfrom PIL import Image\nimport torch.optim.lr_scheduler as lr_scheduler\n\n# auto. choose CPU or GPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n# Function to load CIFAR-10 dataset\ndef load_cifar_batch(file):\n    with open(file, 'rb') as fo:\n        dict = pickle.load(fo, encoding='bytes')\n    return dict\n\n# Specify the directory containing CIFAR-10 batches\ncifar10_dir = '/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py'\n\n# Load metadata (labels)\nmeta_data_dict = load_cifar_batch(os.path.join(cifar10_dir, 'batches.meta'))\nlabel_names = [label.decode('utf-8') for label in meta_data_dict[b'label_names']]\n\n# Load training data\ntrain_data = []\ntrain_labels = []\nfor i in range(1, 6):\n    batch = load_cifar_batch(os.path.join(cifar10_dir, f'data_batch_{i}'))\n    train_data.append(batch[b'data'])\n    train_labels += batch[b'labels']\n\ntrain_data = np.vstack(train_data).reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)  # Convert to HWC format\ntrain_labels = np.array(train_labels)\n\n# Data augmentation and normalization\ntransform = transforms.Compose([\n    transforms.ToPILImage(),  # Convert numpy array to PIL Image\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(brightness = 0.1,contrast = 0.1,saturation = 0.1),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomAdjustSharpness(sharpness_factor = 2,p = 0.2),\n    transforms.RandomCrop(32, padding=4),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n    transforms.RandomErasing(p=0.2,scale=(0.02, 0.1),value=1.0, inplace=False)\n])\n\n# Convert to TensorDataset and apply transformations\nclass CustomCIFAR10Dataset(torch.utils.data.Dataset):\n    def __init__(self, images, labels, transform=None):\n        self.images = images\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        img = self.images[idx]\n        label = self.labels[idx]\n\n        if self.transform:\n            img = self.transform(img)\n\n        return img, label\n\ntrain_dataset = CustomCIFAR10Dataset(train_data, train_labels, transform=transform)\n\n# Split into training and validation sets\ntrain_size = int(0.9 * len(train_dataset))\nval_size = len(train_dataset) - train_size\ntrain_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n\n# DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=4)\n\n# Load test dataset\ncifar_test_path = '/kaggle/input/deep-learning-spring-2025-project-1/cifar_test_nolabel.pkl'\ntest_batch = load_cifar_batch(cifar_test_path)\ntest_images = test_batch[b'data'].astype(np.float32) / 255.0\n\ntest_transform = transforms.Compose([\n    transforms.ToPILImage(),  # Convert numpy array to PIL Image\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n])\n\n# Convert test dataset to Tensor\ntest_dataset = [(test_transform(img),) for img in test_images]\ntest_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4)\n\n# Train function\ndef train_model(model, train_loader, val_loader, epochs=50):\n    criterion = nn.CrossEntropyLoss()\n    #optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n    optimizer = optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=1e-4) #change lr\n    #scheduler = StepLR(optimizer, step_size=20, gamma=0.1)\n    scheduler = StepLR(optimizer, step_size=6, gamma=0.85)\n\n    \n    for epoch in range(epochs):\n        model.train()\n        running_loss = 0.0\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        \n        model.eval()\n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                _, predicted = torch.max(outputs, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n        \n        scheduler.step()\n        print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}, Validation Accuracy: {100 * correct / total}%')\n\n# Define a custom ResNet model from scratch\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.skip = nn.Sequential()\n        if stride != 1 or in_channels != out_channels:\n            self.skip = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels)\n            )\n    def forward(self, x):\n        identity = x \n        if self.skip:\n            identity = self.skip(x)\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out += identity\n        out = self.relu(out)\n        return out\n\nclass CustomResNet(nn.Module):\n    def __init__(self, num_classes=10):\n        super(CustomResNet, self).__init__()\n        self.init_conv = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.init_bn = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.layer1 = self._make_layer(64, 64, 3, stride=1)\n        self.layer2 = self._make_layer(64, 64, 4, stride=2)\n        self.layer3 = self._make_layer(64, 128, 4, stride=2)\n        self.layer4 = self._make_layer(128, 256, 3, stride=2)\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Linear(256, num_classes)\n\n    def _make_layer(self, in_channels, out_channels, blocks, stride):\n        layers = [ResidualBlock(in_channels, out_channels, stride)]\n        for _ in range(1, blocks):\n            layers.append(ResidualBlock(out_channels, out_channels))\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = self.init_conv(x)\n        out = self.init_bn(out)\n        out = self.relu(out)\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = self.avg_pool(out)\n        out = torch.flatten(out, 1)\n        out = self.fc(out)\n        return out\n\n# put models to devices (CPU/GPU)\nmodel = CustomResNet().to(device)\n\n# Print the number of parameters\nfrom torchsummary import summary\nsummary(model, (3, 32, 32))\n\n# Train the model\ntrain_model(model, train_loader, val_loader, epochs=150) #change epoch\n\n# Generate submission file\nmodel.eval()\npredictions = []\nwith torch.no_grad():\n    for batch in test_loader:\n        images = batch[0].to(device)  # Get images tensor from tuple and move to device\n        outputs = model(images) \n        _, predicted = torch.max(outputs, 1)\n        predictions.extend(predicted.cpu().numpy())\n\n# Generate submission file\nsubmission = pd.DataFrame({'ID': np.arange(len(predictions)), 'Labels': predictions})\nsubmission.to_csv('/kaggle/working/submission8.csv', index=False)\nprint(\"Submission8 file saved.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T14:21:08.672652Z","iopub.execute_input":"2025-03-09T14:21:08.672991Z","iopub.status.idle":"2025-03-09T15:52:11.099392Z","shell.execute_reply.started":"2025-03-09T14:21:08.672966Z","shell.execute_reply":"2025-03-09T15:52:11.098384Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1           [-1, 64, 32, 32]           1,728\n       BatchNorm2d-2           [-1, 64, 32, 32]             128\n              ReLU-3           [-1, 64, 32, 32]               0\n            Conv2d-4           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-5           [-1, 64, 32, 32]             128\n              ReLU-6           [-1, 64, 32, 32]               0\n            Conv2d-7           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-8           [-1, 64, 32, 32]             128\n              ReLU-9           [-1, 64, 32, 32]               0\n    ResidualBlock-10           [-1, 64, 32, 32]               0\n           Conv2d-11           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-12           [-1, 64, 32, 32]             128\n             ReLU-13           [-1, 64, 32, 32]               0\n           Conv2d-14           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-15           [-1, 64, 32, 32]             128\n             ReLU-16           [-1, 64, 32, 32]               0\n    ResidualBlock-17           [-1, 64, 32, 32]               0\n           Conv2d-18           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-19           [-1, 64, 32, 32]             128\n             ReLU-20           [-1, 64, 32, 32]               0\n           Conv2d-21           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-22           [-1, 64, 32, 32]             128\n             ReLU-23           [-1, 64, 32, 32]               0\n    ResidualBlock-24           [-1, 64, 32, 32]               0\n           Conv2d-25           [-1, 64, 16, 16]           4,096\n      BatchNorm2d-26           [-1, 64, 16, 16]             128\n           Conv2d-27           [-1, 64, 16, 16]          36,864\n      BatchNorm2d-28           [-1, 64, 16, 16]             128\n             ReLU-29           [-1, 64, 16, 16]               0\n           Conv2d-30           [-1, 64, 16, 16]          36,864\n      BatchNorm2d-31           [-1, 64, 16, 16]             128\n             ReLU-32           [-1, 64, 16, 16]               0\n    ResidualBlock-33           [-1, 64, 16, 16]               0\n           Conv2d-34           [-1, 64, 16, 16]          36,864\n      BatchNorm2d-35           [-1, 64, 16, 16]             128\n             ReLU-36           [-1, 64, 16, 16]               0\n           Conv2d-37           [-1, 64, 16, 16]          36,864\n      BatchNorm2d-38           [-1, 64, 16, 16]             128\n             ReLU-39           [-1, 64, 16, 16]               0\n    ResidualBlock-40           [-1, 64, 16, 16]               0\n           Conv2d-41           [-1, 64, 16, 16]          36,864\n      BatchNorm2d-42           [-1, 64, 16, 16]             128\n             ReLU-43           [-1, 64, 16, 16]               0\n           Conv2d-44           [-1, 64, 16, 16]          36,864\n      BatchNorm2d-45           [-1, 64, 16, 16]             128\n             ReLU-46           [-1, 64, 16, 16]               0\n    ResidualBlock-47           [-1, 64, 16, 16]               0\n           Conv2d-48           [-1, 64, 16, 16]          36,864\n      BatchNorm2d-49           [-1, 64, 16, 16]             128\n             ReLU-50           [-1, 64, 16, 16]               0\n           Conv2d-51           [-1, 64, 16, 16]          36,864\n      BatchNorm2d-52           [-1, 64, 16, 16]             128\n             ReLU-53           [-1, 64, 16, 16]               0\n    ResidualBlock-54           [-1, 64, 16, 16]               0\n           Conv2d-55            [-1, 128, 8, 8]           8,192\n      BatchNorm2d-56            [-1, 128, 8, 8]             256\n           Conv2d-57            [-1, 128, 8, 8]          73,728\n      BatchNorm2d-58            [-1, 128, 8, 8]             256\n             ReLU-59            [-1, 128, 8, 8]               0\n           Conv2d-60            [-1, 128, 8, 8]         147,456\n      BatchNorm2d-61            [-1, 128, 8, 8]             256\n             ReLU-62            [-1, 128, 8, 8]               0\n    ResidualBlock-63            [-1, 128, 8, 8]               0\n           Conv2d-64            [-1, 128, 8, 8]         147,456\n      BatchNorm2d-65            [-1, 128, 8, 8]             256\n             ReLU-66            [-1, 128, 8, 8]               0\n           Conv2d-67            [-1, 128, 8, 8]         147,456\n      BatchNorm2d-68            [-1, 128, 8, 8]             256\n             ReLU-69            [-1, 128, 8, 8]               0\n    ResidualBlock-70            [-1, 128, 8, 8]               0\n           Conv2d-71            [-1, 128, 8, 8]         147,456\n      BatchNorm2d-72            [-1, 128, 8, 8]             256\n             ReLU-73            [-1, 128, 8, 8]               0\n           Conv2d-74            [-1, 128, 8, 8]         147,456\n      BatchNorm2d-75            [-1, 128, 8, 8]             256\n             ReLU-76            [-1, 128, 8, 8]               0\n    ResidualBlock-77            [-1, 128, 8, 8]               0\n           Conv2d-78            [-1, 128, 8, 8]         147,456\n      BatchNorm2d-79            [-1, 128, 8, 8]             256\n             ReLU-80            [-1, 128, 8, 8]               0\n           Conv2d-81            [-1, 128, 8, 8]         147,456\n      BatchNorm2d-82            [-1, 128, 8, 8]             256\n             ReLU-83            [-1, 128, 8, 8]               0\n    ResidualBlock-84            [-1, 128, 8, 8]               0\n           Conv2d-85            [-1, 256, 4, 4]          32,768\n      BatchNorm2d-86            [-1, 256, 4, 4]             512\n           Conv2d-87            [-1, 256, 4, 4]         294,912\n      BatchNorm2d-88            [-1, 256, 4, 4]             512\n             ReLU-89            [-1, 256, 4, 4]               0\n           Conv2d-90            [-1, 256, 4, 4]         589,824\n      BatchNorm2d-91            [-1, 256, 4, 4]             512\n             ReLU-92            [-1, 256, 4, 4]               0\n    ResidualBlock-93            [-1, 256, 4, 4]               0\n           Conv2d-94            [-1, 256, 4, 4]         589,824\n      BatchNorm2d-95            [-1, 256, 4, 4]             512\n             ReLU-96            [-1, 256, 4, 4]               0\n           Conv2d-97            [-1, 256, 4, 4]         589,824\n      BatchNorm2d-98            [-1, 256, 4, 4]             512\n             ReLU-99            [-1, 256, 4, 4]               0\n   ResidualBlock-100            [-1, 256, 4, 4]               0\n          Conv2d-101            [-1, 256, 4, 4]         589,824\n     BatchNorm2d-102            [-1, 256, 4, 4]             512\n            ReLU-103            [-1, 256, 4, 4]               0\n          Conv2d-104            [-1, 256, 4, 4]         589,824\n     BatchNorm2d-105            [-1, 256, 4, 4]             512\n            ReLU-106            [-1, 256, 4, 4]               0\n   ResidualBlock-107            [-1, 256, 4, 4]               0\nAdaptiveAvgPool2d-108            [-1, 256, 1, 1]               0\n          Linear-109                   [-1, 10]           2,570\n================================================================\nTotal params: 4,923,338\nTrainable params: 4,923,338\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.01\nForward/backward pass size (MB): 18.35\nParams size (MB): 18.78\nEstimated Total Size (MB): 37.14\n----------------------------------------------------------------\nEpoch 1, Loss: 1.6243696121329612, Validation Accuracy: 45.96%\nEpoch 2, Loss: 1.1988153525374152, Validation Accuracy: 54.42%\nEpoch 3, Loss: 0.9695812621238556, Validation Accuracy: 64.46%\nEpoch 4, Loss: 0.8224419702521779, Validation Accuracy: 69.88%\nEpoch 5, Loss: 0.7315298766744408, Validation Accuracy: 72.76%\nEpoch 6, Loss: 0.6618831574239514, Validation Accuracy: 76.72%\nEpoch 7, Loss: 0.5957812791351568, Validation Accuracy: 78.12%\nEpoch 8, Loss: 0.554898099635135, Validation Accuracy: 79.06%\nEpoch 9, Loss: 0.5171093983067707, Validation Accuracy: 79.34%\nEpoch 10, Loss: 0.4993790061297742, Validation Accuracy: 80.6%\nEpoch 11, Loss: 0.47618707963688806, Validation Accuracy: 80.76%\nEpoch 12, Loss: 0.44791987021877006, Validation Accuracy: 81.46%\nEpoch 13, Loss: 0.4105751732872291, Validation Accuracy: 82.36%\nEpoch 14, Loss: 0.3974822963249277, Validation Accuracy: 79.5%\nEpoch 15, Loss: 0.3863178447142921, Validation Accuracy: 83.72%\nEpoch 16, Loss: 0.36842848775400355, Validation Accuracy: 84.08%\nEpoch 17, Loss: 0.35393407178873365, Validation Accuracy: 84.1%\nEpoch 18, Loss: 0.34704165694049816, Validation Accuracy: 84.02%\nEpoch 19, Loss: 0.3201990880664777, Validation Accuracy: 85.58%\nEpoch 20, Loss: 0.3046811548146335, Validation Accuracy: 83.56%\nEpoch 21, Loss: 0.29799306244504725, Validation Accuracy: 84.88%\nEpoch 22, Loss: 0.28746756907044485, Validation Accuracy: 85.64%\nEpoch 23, Loss: 0.2819368447261778, Validation Accuracy: 85.32%\nEpoch 24, Loss: 0.2741604888049716, Validation Accuracy: 83.78%\nEpoch 25, Loss: 0.2546910941177471, Validation Accuracy: 86.7%\nEpoch 26, Loss: 0.2488796136087992, Validation Accuracy: 85.96%\nEpoch 27, Loss: 0.23965916518037292, Validation Accuracy: 86.68%\nEpoch 28, Loss: 0.23401375212283296, Validation Accuracy: 86.44%\nEpoch 29, Loss: 0.22605010448023677, Validation Accuracy: 85.94%\nEpoch 30, Loss: 0.22469031647779047, Validation Accuracy: 87.38%\nEpoch 31, Loss: 0.20642326837828892, Validation Accuracy: 87.32%\nEpoch 32, Loss: 0.19980954732322556, Validation Accuracy: 87.8%\nEpoch 33, Loss: 0.1921557032672519, Validation Accuracy: 86.32%\nEpoch 34, Loss: 0.1961596780668267, Validation Accuracy: 87.6%\nEpoch 35, Loss: 0.18644332508979874, Validation Accuracy: 87.2%\nEpoch 36, Loss: 0.18626283803446728, Validation Accuracy: 86.52%\nEpoch 37, Loss: 0.16876742260699923, Validation Accuracy: 88.06%\nEpoch 38, Loss: 0.1673471159090034, Validation Accuracy: 87.02%\nEpoch 39, Loss: 0.16275433620268648, Validation Accuracy: 87.92%\nEpoch 40, Loss: 0.16196604588450017, Validation Accuracy: 87.86%\nEpoch 41, Loss: 0.1506575531305068, Validation Accuracy: 88.3%\nEpoch 42, Loss: 0.15550135752313177, Validation Accuracy: 88.04%\nEpoch 43, Loss: 0.1448065620974045, Validation Accuracy: 88.58%\nEpoch 44, Loss: 0.13879043065985155, Validation Accuracy: 88.42%\nEpoch 45, Loss: 0.1324177434964275, Validation Accuracy: 88.32%\nEpoch 46, Loss: 0.12811588611855934, Validation Accuracy: 87.74%\nEpoch 47, Loss: 0.1298337122425437, Validation Accuracy: 88.66%\nEpoch 48, Loss: 0.12305666217368773, Validation Accuracy: 88.68%\nEpoch 49, Loss: 0.12092969459693202, Validation Accuracy: 89.84%\nEpoch 50, Loss: 0.11244858613512902, Validation Accuracy: 88.76%\nEpoch 51, Loss: 0.11126478041776201, Validation Accuracy: 88.78%\nEpoch 52, Loss: 0.11001508599358865, Validation Accuracy: 89.52%\nEpoch 53, Loss: 0.10774522955762222, Validation Accuracy: 89.34%\nEpoch 54, Loss: 0.10890833296897737, Validation Accuracy: 88.74%\nEpoch 55, Loss: 0.09900558391183784, Validation Accuracy: 88.86%\nEpoch 56, Loss: 0.09382080541796643, Validation Accuracy: 89.1%\nEpoch 57, Loss: 0.09103157778736204, Validation Accuracy: 88.66%\nEpoch 58, Loss: 0.09478697085763667, Validation Accuracy: 89.28%\nEpoch 59, Loss: 0.09328189851525663, Validation Accuracy: 89.3%\nEpoch 60, Loss: 0.09089538352881474, Validation Accuracy: 88.98%\nEpoch 61, Loss: 0.08229512421266091, Validation Accuracy: 90.32%\nEpoch 62, Loss: 0.0834678671724925, Validation Accuracy: 89.54%\nEpoch 63, Loss: 0.07964891163812188, Validation Accuracy: 89.42%\nEpoch 64, Loss: 0.0832910807697441, Validation Accuracy: 89.36%\nEpoch 65, Loss: 0.07874363807919012, Validation Accuracy: 89.48%\nEpoch 66, Loss: 0.07954549886265093, Validation Accuracy: 89.06%\nEpoch 67, Loss: 0.07199649889000946, Validation Accuracy: 89.62%\nEpoch 68, Loss: 0.07112410278535787, Validation Accuracy: 89.58%\nEpoch 69, Loss: 0.07262464162671346, Validation Accuracy: 89.86%\nEpoch 70, Loss: 0.06882872588572685, Validation Accuracy: 89.2%\nEpoch 71, Loss: 0.06636675162537192, Validation Accuracy: 89.66%\nEpoch 72, Loss: 0.06986628471217542, Validation Accuracy: 89.48%\nEpoch 73, Loss: 0.0646047014981212, Validation Accuracy: 89.38%\nEpoch 74, Loss: 0.06216607563493943, Validation Accuracy: 90.16%\nEpoch 75, Loss: 0.06112421661964618, Validation Accuracy: 89.46%\nEpoch 76, Loss: 0.06279810929448683, Validation Accuracy: 89.32%\nEpoch 77, Loss: 0.06038197908360003, Validation Accuracy: 89.82%\nEpoch 78, Loss: 0.0599845318488819, Validation Accuracy: 89.3%\nEpoch 79, Loss: 0.054544649330306456, Validation Accuracy: 89.78%\nEpoch 80, Loss: 0.052927003177253275, Validation Accuracy: 90.14%\nEpoch 81, Loss: 0.05422531358040446, Validation Accuracy: 90.24%\nEpoch 82, Loss: 0.055533948387495584, Validation Accuracy: 89.28%\nEpoch 83, Loss: 0.05300683621846309, Validation Accuracy: 89.56%\nEpoch 84, Loss: 0.049371941885593434, Validation Accuracy: 89.64%\nEpoch 85, Loss: 0.050938697703796526, Validation Accuracy: 89.9%\nEpoch 86, Loss: 0.048909209509888155, Validation Accuracy: 90.18%\nEpoch 87, Loss: 0.04800255756576503, Validation Accuracy: 90.16%\nEpoch 88, Loss: 0.04905584582064131, Validation Accuracy: 90.54%\nEpoch 89, Loss: 0.04895330661648503, Validation Accuracy: 89.8%\nEpoch 90, Loss: 0.04765153211800763, Validation Accuracy: 90.2%\nEpoch 91, Loss: 0.045343194252134046, Validation Accuracy: 90.32%\nEpoch 92, Loss: 0.04295853616018907, Validation Accuracy: 90.04%\nEpoch 93, Loss: 0.04067071621433239, Validation Accuracy: 90.74%\nEpoch 94, Loss: 0.0420191700104624, Validation Accuracy: 90.06%\nEpoch 95, Loss: 0.042997131565987896, Validation Accuracy: 90.02%\nEpoch 96, Loss: 0.04059213396976702, Validation Accuracy: 89.9%\nEpoch 97, Loss: 0.04082967775651592, Validation Accuracy: 90.6%\nEpoch 98, Loss: 0.04195434958621098, Validation Accuracy: 90.42%\nEpoch 99, Loss: 0.0425445998883912, Validation Accuracy: 90.36%\nEpoch 100, Loss: 0.040977118878799956, Validation Accuracy: 90.16%\nEpoch 101, Loss: 0.040948716619327155, Validation Accuracy: 90.6%\nEpoch 102, Loss: 0.04042176789186091, Validation Accuracy: 90.18%\nEpoch 103, Loss: 0.03955156827710611, Validation Accuracy: 90.26%\nEpoch 104, Loss: 0.03675248796604468, Validation Accuracy: 90.2%\nEpoch 105, Loss: 0.03888350310444366, Validation Accuracy: 90.42%\nEpoch 106, Loss: 0.03690844374068547, Validation Accuracy: 90.16%\nEpoch 107, Loss: 0.036400980165291745, Validation Accuracy: 90.34%\nEpoch 108, Loss: 0.03529408950205173, Validation Accuracy: 89.8%\nEpoch 109, Loss: 0.037686415981707716, Validation Accuracy: 90.34%\nEpoch 110, Loss: 0.036400963447786955, Validation Accuracy: 90.0%\nEpoch 111, Loss: 0.036283430372184906, Validation Accuracy: 90.1%\nEpoch 112, Loss: 0.034604945770380174, Validation Accuracy: 90.7%\nEpoch 113, Loss: 0.03479922662981236, Validation Accuracy: 90.18%\nEpoch 114, Loss: 0.0353012372109912, Validation Accuracy: 90.4%\nEpoch 115, Loss: 0.037009811437614684, Validation Accuracy: 91.06%\nEpoch 116, Loss: 0.03516853755123024, Validation Accuracy: 90.34%\nEpoch 117, Loss: 0.03289225621185985, Validation Accuracy: 90.26%\nEpoch 118, Loss: 0.03598394694695757, Validation Accuracy: 90.28%\nEpoch 119, Loss: 0.0338312314190923, Validation Accuracy: 90.56%\nEpoch 120, Loss: 0.033355007905232596, Validation Accuracy: 90.28%\nEpoch 121, Loss: 0.03261270093935309, Validation Accuracy: 90.76%\nEpoch 122, Loss: 0.03152462243054866, Validation Accuracy: 90.86%\nEpoch 123, Loss: 0.034067993645625065, Validation Accuracy: 90.58%\nEpoch 124, Loss: 0.03180682372674875, Validation Accuracy: 90.36%\nEpoch 125, Loss: 0.031869332859059796, Validation Accuracy: 90.54%\nEpoch 126, Loss: 0.03200817570640621, Validation Accuracy: 90.3%\nEpoch 127, Loss: 0.030447478115092963, Validation Accuracy: 90.18%\nEpoch 128, Loss: 0.03088398007788452, Validation Accuracy: 90.9%\nEpoch 129, Loss: 0.03240492477991872, Validation Accuracy: 90.26%\nEpoch 130, Loss: 0.03157414742004634, Validation Accuracy: 90.64%\nEpoch 131, Loss: 0.030584479012759402, Validation Accuracy: 90.5%\nEpoch 132, Loss: 0.030191676469588525, Validation Accuracy: 90.26%\nEpoch 133, Loss: 0.030511720195301514, Validation Accuracy: 90.56%\nEpoch 134, Loss: 0.028693326622570483, Validation Accuracy: 90.56%\nEpoch 135, Loss: 0.0308625992283024, Validation Accuracy: 90.14%\nEpoch 136, Loss: 0.03234181661007989, Validation Accuracy: 90.54%\nEpoch 137, Loss: 0.027320876144751146, Validation Accuracy: 90.3%\nEpoch 138, Loss: 0.03224542907330694, Validation Accuracy: 90.76%\nEpoch 139, Loss: 0.02945190916546959, Validation Accuracy: 90.62%\nEpoch 140, Loss: 0.029825920397839087, Validation Accuracy: 90.9%\nEpoch 141, Loss: 0.029665352586148816, Validation Accuracy: 90.62%\nEpoch 142, Loss: 0.028378355956109855, Validation Accuracy: 90.56%\nEpoch 143, Loss: 0.027969287858550986, Validation Accuracy: 90.26%\nEpoch 144, Loss: 0.029665699165806556, Validation Accuracy: 90.22%\nEpoch 145, Loss: 0.028333688317864224, Validation Accuracy: 89.96%\nEpoch 146, Loss: 0.028300803072687068, Validation Accuracy: 90.4%\nEpoch 147, Loss: 0.030136864816912832, Validation Accuracy: 90.68%\nEpoch 148, Loss: 0.03019786113244746, Validation Accuracy: 90.82%\nEpoch 149, Loss: 0.02787044121313639, Validation Accuracy: 90.58%\nEpoch 150, Loss: 0.027385299843444955, Validation Accuracy: 90.34%\nSubmission8 file saved.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# add dropout\nimport numpy as np\nimport pandas as pd\nimport os\nimport pickle\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nfrom torch.utils.data import DataLoader, random_split, TensorDataset\nfrom torch.optim.lr_scheduler import StepLR\nfrom PIL import Image\nimport torch.optim.lr_scheduler as lr_scheduler\n\n# auto. choose CPU or GPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n# Function to load CIFAR-10 dataset\ndef load_cifar_batch(file):\n    with open(file, 'rb') as fo:\n        dict = pickle.load(fo, encoding='bytes')\n    return dict\n\n# Specify the directory containing CIFAR-10 batches\ncifar10_dir = '/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py'\n\n# Load metadata (labels)\nmeta_data_dict = load_cifar_batch(os.path.join(cifar10_dir, 'batches.meta'))\nlabel_names = [label.decode('utf-8') for label in meta_data_dict[b'label_names']]\n\n# Load training data\ntrain_data = []\ntrain_labels = []\nfor i in range(1, 6):\n    batch = load_cifar_batch(os.path.join(cifar10_dir, f'data_batch_{i}'))\n    train_data.append(batch[b'data'])\n    train_labels += batch[b'labels']\n\ntrain_data = np.vstack(train_data).reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)  # Convert to HWC format\ntrain_labels = np.array(train_labels)\n\n# Data augmentation and normalization\ntransform = transforms.Compose([\n    transforms.ToPILImage(),  # Convert numpy array to PIL Image\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(brightness = 0.1,contrast = 0.1,saturation = 0.1),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomAdjustSharpness(sharpness_factor = 2,p = 0.2),\n    transforms.RandomCrop(32, padding=4),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n    transforms.RandomErasing(p=0.2,scale=(0.02, 0.1),value=1.0, inplace=False)\n])\n\n# Convert to TensorDataset and apply transformations\nclass CustomCIFAR10Dataset(torch.utils.data.Dataset):\n    def __init__(self, images, labels, transform=None):\n        self.images = images\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        img = self.images[idx]\n        label = self.labels[idx]\n\n        if self.transform:\n            img = self.transform(img)\n\n        return img, label\n\ntrain_dataset = CustomCIFAR10Dataset(train_data, train_labels, transform=transform)\n\n# Split into training and validation sets\ntrain_size = int(0.9 * len(train_dataset))\nval_size = len(train_dataset) - train_size\ntrain_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n\n# DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=4)\n\n# Load test dataset\ncifar_test_path = '/kaggle/input/deep-learning-spring-2025-project-1/cifar_test_nolabel.pkl'\ntest_batch = load_cifar_batch(cifar_test_path)\ntest_images = test_batch[b'data'].astype(np.float32) / 255.0\n\ntest_transform = transforms.Compose([\n    transforms.ToPILImage(),  # Convert numpy array to PIL Image\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n])\n\n# Convert test dataset to Tensor\ntest_dataset = [(test_transform(img),) for img in test_images]\ntest_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4)\n\n# Train function\ndef train_model(model, train_loader, val_loader, epochs=50):\n    criterion = nn.CrossEntropyLoss()\n    #optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n    optimizer = optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=1e-4) #change lr\n    #scheduler = StepLR(optimizer, step_size=20, gamma=0.1)\n    scheduler = StepLR(optimizer, step_size=6, gamma=0.85)\n\n    \n    for epoch in range(epochs):\n        model.train()\n        running_loss = 0.0\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        \n        model.eval()\n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                _, predicted = torch.max(outputs, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n        \n        scheduler.step()\n        print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}, Validation Accuracy: {100 * correct / total}%')\n\n# Define a custom ResNet model from scratch\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.skip = nn.Sequential()\n        if stride != 1 or in_channels != out_channels:\n            self.skip = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels)\n            )\n    def forward(self, x):\n        identity = x \n        if self.skip:\n            identity = self.skip(x)\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out += identity\n        out = self.relu(out)\n        return out\n\nclass CustomResNet(nn.Module):\n    def __init__(self, num_classes=10):\n        super(CustomResNet, self).__init__()\n        self.init_conv = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.init_bn = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.layer1 = self._make_layer(64, 64, 2, stride=1)\n        self.layer2 = self._make_layer(64, 128, 2, stride=2)\n        self.layer3 = self._make_layer(128, 256, 2, stride=2)\n        #self.layer4 = self._make_layer(256, 512, 2, stride=2)\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Linear(256, num_classes)\n        self.dropout = nn.Dropout(0.3)\n\n    def _make_layer(self, in_channels, out_channels, blocks, stride):\n        layers = [ResidualBlock(in_channels, out_channels, stride)]\n        for _ in range(1, blocks):\n            layers.append(ResidualBlock(out_channels, out_channels))\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = self.init_conv(x)\n        out = self.init_bn(out)\n        out = self.relu(out)\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        #out = self.layer4(out)\n        out = self.avg_pool(out)\n        out = torch.flatten(out, 1)\n        out = self.dropout(out)\n        out = self.fc(out)\n        return out\n\n# put models to devices (CPU/GPU)\nmodel = CustomResNet().to(device)\n\n# Print the number of parameters\nfrom torchsummary import summary\nsummary(model, (3, 32, 32))\n\n# Train the model\ntrain_model(model, train_loader, val_loader, epochs=100) #change epoch\n\n# Generate submission file\nmodel.eval()\npredictions = []\nwith torch.no_grad():\n    for batch in test_loader:\n        images = batch[0].to(device)  # Get images tensor from tuple and move to device\n        outputs = model(images) \n        _, predicted = torch.max(outputs, 1)\n        predictions.extend(predicted.cpu().numpy())\n\n# Generate submission file\nsubmission = pd.DataFrame({'ID': np.arange(len(predictions)), 'Labels': predictions})\nsubmission.to_csv('/kaggle/working/submission9.csv', index=False)\nprint(\"Submission9 file saved.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T15:53:48.561331Z","iopub.execute_input":"2025-03-09T15:53:48.561711Z","iopub.status.idle":"2025-03-09T16:44:05.903626Z","shell.execute_reply.started":"2025-03-09T15:53:48.561679Z","shell.execute_reply":"2025-03-09T16:44:05.902504Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1           [-1, 64, 32, 32]           1,728\n       BatchNorm2d-2           [-1, 64, 32, 32]             128\n              ReLU-3           [-1, 64, 32, 32]               0\n            Conv2d-4           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-5           [-1, 64, 32, 32]             128\n              ReLU-6           [-1, 64, 32, 32]               0\n            Conv2d-7           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-8           [-1, 64, 32, 32]             128\n              ReLU-9           [-1, 64, 32, 32]               0\n    ResidualBlock-10           [-1, 64, 32, 32]               0\n           Conv2d-11           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-12           [-1, 64, 32, 32]             128\n             ReLU-13           [-1, 64, 32, 32]               0\n           Conv2d-14           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-15           [-1, 64, 32, 32]             128\n             ReLU-16           [-1, 64, 32, 32]               0\n    ResidualBlock-17           [-1, 64, 32, 32]               0\n           Conv2d-18          [-1, 128, 16, 16]           8,192\n      BatchNorm2d-19          [-1, 128, 16, 16]             256\n           Conv2d-20          [-1, 128, 16, 16]          73,728\n      BatchNorm2d-21          [-1, 128, 16, 16]             256\n             ReLU-22          [-1, 128, 16, 16]               0\n           Conv2d-23          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-24          [-1, 128, 16, 16]             256\n             ReLU-25          [-1, 128, 16, 16]               0\n    ResidualBlock-26          [-1, 128, 16, 16]               0\n           Conv2d-27          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-28          [-1, 128, 16, 16]             256\n             ReLU-29          [-1, 128, 16, 16]               0\n           Conv2d-30          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-31          [-1, 128, 16, 16]             256\n             ReLU-32          [-1, 128, 16, 16]               0\n    ResidualBlock-33          [-1, 128, 16, 16]               0\n           Conv2d-34            [-1, 256, 8, 8]          32,768\n      BatchNorm2d-35            [-1, 256, 8, 8]             512\n           Conv2d-36            [-1, 256, 8, 8]         294,912\n      BatchNorm2d-37            [-1, 256, 8, 8]             512\n             ReLU-38            [-1, 256, 8, 8]               0\n           Conv2d-39            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-40            [-1, 256, 8, 8]             512\n             ReLU-41            [-1, 256, 8, 8]               0\n    ResidualBlock-42            [-1, 256, 8, 8]               0\n           Conv2d-43            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-44            [-1, 256, 8, 8]             512\n             ReLU-45            [-1, 256, 8, 8]               0\n           Conv2d-46            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-47            [-1, 256, 8, 8]             512\n             ReLU-48            [-1, 256, 8, 8]               0\n    ResidualBlock-49            [-1, 256, 8, 8]               0\nAdaptiveAvgPool2d-50            [-1, 256, 1, 1]               0\n          Dropout-51                  [-1, 256]               0\n           Linear-52                   [-1, 10]           2,570\n================================================================\nTotal params: 2,777,674\nTrainable params: 2,777,674\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.01\nForward/backward pass size (MB): 14.50\nParams size (MB): 10.60\nEstimated Total Size (MB): 25.11\n----------------------------------------------------------------\nEpoch 1, Loss: 1.5953152067959309, Validation Accuracy: 46.12%\nEpoch 2, Loss: 1.1775664045390757, Validation Accuracy: 60.4%\nEpoch 3, Loss: 0.9973278370770541, Validation Accuracy: 65.1%\nEpoch 4, Loss: 0.8787910294803706, Validation Accuracy: 68.62%\nEpoch 5, Loss: 0.7832522077316587, Validation Accuracy: 67.04%\nEpoch 6, Loss: 0.708811428905888, Validation Accuracy: 70.48%\nEpoch 7, Loss: 0.6377251675691117, Validation Accuracy: 74.68%\nEpoch 8, Loss: 0.6046223029155623, Validation Accuracy: 77.52%\nEpoch 9, Loss: 0.5708521403033625, Validation Accuracy: 75.9%\nEpoch 10, Loss: 0.538494909690185, Validation Accuracy: 78.2%\nEpoch 11, Loss: 0.5140899162400853, Validation Accuracy: 77.96%\nEpoch 12, Loss: 0.489961229857396, Validation Accuracy: 78.28%\nEpoch 13, Loss: 0.45509874346581375, Validation Accuracy: 82.16%\nEpoch 14, Loss: 0.4327279637059705, Validation Accuracy: 81.86%\nEpoch 15, Loss: 0.42033807073973795, Validation Accuracy: 80.18%\nEpoch 16, Loss: 0.40933435410261154, Validation Accuracy: 80.08%\nEpoch 17, Loss: 0.3923369662582197, Validation Accuracy: 83.7%\nEpoch 18, Loss: 0.38266810042444954, Validation Accuracy: 82.7%\nEpoch 19, Loss: 0.3590302014808086, Validation Accuracy: 83.48%\nEpoch 20, Loss: 0.34829674796624616, Validation Accuracy: 84.28%\nEpoch 21, Loss: 0.3325377083806829, Validation Accuracy: 83.28%\nEpoch 22, Loss: 0.32680858358402143, Validation Accuracy: 83.32%\nEpoch 23, Loss: 0.3214395743879405, Validation Accuracy: 83.7%\nEpoch 24, Loss: 0.31142826010049746, Validation Accuracy: 84.0%\nEpoch 25, Loss: 0.2929729135199027, Validation Accuracy: 86.44%\nEpoch 26, Loss: 0.280061284693974, Validation Accuracy: 86.14%\nEpoch 27, Loss: 0.2756450071676888, Validation Accuracy: 85.0%\nEpoch 28, Loss: 0.26980081471529876, Validation Accuracy: 84.96%\nEpoch 29, Loss: 0.26388112925501034, Validation Accuracy: 84.08%\nEpoch 30, Loss: 0.2573391215833412, Validation Accuracy: 86.78%\nEpoch 31, Loss: 0.23786560896868733, Validation Accuracy: 86.44%\nEpoch 32, Loss: 0.23632555137473074, Validation Accuracy: 86.26%\nEpoch 33, Loss: 0.2284648938485506, Validation Accuracy: 86.92%\nEpoch 34, Loss: 0.22524658647704532, Validation Accuracy: 86.52%\nEpoch 35, Loss: 0.22197529643943364, Validation Accuracy: 87.72%\nEpoch 36, Loss: 0.2179436698682945, Validation Accuracy: 86.2%\nEpoch 37, Loss: 0.20243430099534718, Validation Accuracy: 87.88%\nEpoch 38, Loss: 0.19450428228909997, Validation Accuracy: 86.64%\nEpoch 39, Loss: 0.1968719474547966, Validation Accuracy: 87.98%\nEpoch 40, Loss: 0.1901343063112687, Validation Accuracy: 87.34%\nEpoch 41, Loss: 0.1883844350760972, Validation Accuracy: 86.66%\nEpoch 42, Loss: 0.1812009444481439, Validation Accuracy: 87.64%\nEpoch 43, Loss: 0.17226325813680887, Validation Accuracy: 88.34%\nEpoch 44, Loss: 0.16660446634473788, Validation Accuracy: 88.24%\nEpoch 45, Loss: 0.16610317828599364, Validation Accuracy: 88.1%\nEpoch 46, Loss: 0.16039100333794273, Validation Accuracy: 88.2%\nEpoch 47, Loss: 0.15980457186444916, Validation Accuracy: 88.2%\nEpoch 48, Loss: 0.15647350313057276, Validation Accuracy: 88.84%\nEpoch 49, Loss: 0.15004291252063756, Validation Accuracy: 88.8%\nEpoch 50, Loss: 0.14136023742189122, Validation Accuracy: 88.4%\nEpoch 51, Loss: 0.13914847776124423, Validation Accuracy: 88.94%\nEpoch 52, Loss: 0.14018302915660155, Validation Accuracy: 89.58%\nEpoch 53, Loss: 0.13826413644181396, Validation Accuracy: 88.34%\nEpoch 54, Loss: 0.13500076572580094, Validation Accuracy: 88.16%\nEpoch 55, Loss: 0.1295355064582757, Validation Accuracy: 89.26%\nEpoch 56, Loss: 0.11961251814765009, Validation Accuracy: 89.08%\nEpoch 57, Loss: 0.12121138515331867, Validation Accuracy: 88.34%\nEpoch 58, Loss: 0.11852194706443697, Validation Accuracy: 89.2%\nEpoch 59, Loss: 0.12120843945409764, Validation Accuracy: 89.4%\nEpoch 60, Loss: 0.11912707568527284, Validation Accuracy: 89.22%\nEpoch 61, Loss: 0.11405737923500552, Validation Accuracy: 89.96%\nEpoch 62, Loss: 0.10737719075669619, Validation Accuracy: 89.38%\nEpoch 63, Loss: 0.11084268541625616, Validation Accuracy: 89.6%\nEpoch 64, Loss: 0.10589124333769591, Validation Accuracy: 89.08%\nEpoch 65, Loss: 0.10594856481343, Validation Accuracy: 89.18%\nEpoch 66, Loss: 0.09811619291378354, Validation Accuracy: 88.88%\nEpoch 67, Loss: 0.09850052964810113, Validation Accuracy: 89.7%\nEpoch 68, Loss: 0.09511958120856434, Validation Accuracy: 88.98%\nEpoch 69, Loss: 0.09578050415835936, Validation Accuracy: 89.56%\nEpoch 70, Loss: 0.09507692328506065, Validation Accuracy: 90.12%\nEpoch 71, Loss: 0.09362488859650595, Validation Accuracy: 89.72%\nEpoch 72, Loss: 0.09181180997455324, Validation Accuracy: 89.48%\nEpoch 73, Loss: 0.08643231811319393, Validation Accuracy: 89.98%\nEpoch 74, Loss: 0.08697446194921875, Validation Accuracy: 89.76%\nEpoch 75, Loss: 0.0830468545212749, Validation Accuracy: 89.72%\nEpoch 76, Loss: 0.08335173305716705, Validation Accuracy: 89.9%\nEpoch 77, Loss: 0.07870241772616282, Validation Accuracy: 89.7%\nEpoch 78, Loss: 0.08274206881601871, Validation Accuracy: 89.62%\nEpoch 79, Loss: 0.07820803486339917, Validation Accuracy: 89.82%\nEpoch 80, Loss: 0.07434085671345449, Validation Accuracy: 89.58%\nEpoch 81, Loss: 0.07678948676171289, Validation Accuracy: 90.22%\nEpoch 82, Loss: 0.07559388924114914, Validation Accuracy: 89.86%\nEpoch 83, Loss: 0.07441544120030646, Validation Accuracy: 88.86%\nEpoch 84, Loss: 0.07533120205996303, Validation Accuracy: 89.8%\nEpoch 85, Loss: 0.07105676419715481, Validation Accuracy: 90.0%\nEpoch 86, Loss: 0.0684998351472049, Validation Accuracy: 90.06%\nEpoch 87, Loss: 0.06953940261684527, Validation Accuracy: 89.64%\nEpoch 88, Loss: 0.06929174210579897, Validation Accuracy: 89.44%\nEpoch 89, Loss: 0.067964162039888, Validation Accuracy: 90.16%\nEpoch 90, Loss: 0.0687670100173405, Validation Accuracy: 89.78%\nEpoch 91, Loss: 0.06450102784649724, Validation Accuracy: 90.14%\nEpoch 92, Loss: 0.06287802269798703, Validation Accuracy: 90.5%\nEpoch 93, Loss: 0.06463041557104919, Validation Accuracy: 90.5%\nEpoch 94, Loss: 0.06462011688431217, Validation Accuracy: 90.1%\nEpoch 95, Loss: 0.0639743209837682, Validation Accuracy: 89.92%\nEpoch 96, Loss: 0.06212838632001711, Validation Accuracy: 89.9%\nEpoch 97, Loss: 0.06169482304936868, Validation Accuracy: 90.02%\nEpoch 98, Loss: 0.06136779581852765, Validation Accuracy: 90.14%\nEpoch 99, Loss: 0.0577495618278838, Validation Accuracy: 90.28%\nEpoch 100, Loss: 0.058867948574268004, Validation Accuracy: 90.2%\nSubmission9 file saved.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# adjust scheduler\nimport numpy as np\nimport pandas as pd\nimport os\nimport pickle\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nfrom torch.utils.data import DataLoader, random_split, TensorDataset\nfrom torch.optim.lr_scheduler import StepLR\nfrom PIL import Image\nimport torch.optim.lr_scheduler as lr_scheduler\n\n# auto. choose CPU or GPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n# Function to load CIFAR-10 dataset\ndef load_cifar_batch(file):\n    with open(file, 'rb') as fo:\n        dict = pickle.load(fo, encoding='bytes')\n    return dict\n\n# Specify the directory containing CIFAR-10 batches\ncifar10_dir = '/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py'\n\n# Load metadata (labels)\nmeta_data_dict = load_cifar_batch(os.path.join(cifar10_dir, 'batches.meta'))\nlabel_names = [label.decode('utf-8') for label in meta_data_dict[b'label_names']]\n\n# Load training data\ntrain_data = []\ntrain_labels = []\nfor i in range(1, 6):\n    batch = load_cifar_batch(os.path.join(cifar10_dir, f'data_batch_{i}'))\n    train_data.append(batch[b'data'])\n    train_labels += batch[b'labels']\n\ntrain_data = np.vstack(train_data).reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)  # Convert to HWC format\ntrain_labels = np.array(train_labels)\n\n# Data augmentation and normalization\ntransform = transforms.Compose([\n    transforms.ToPILImage(),  # Convert numpy array to PIL Image\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(brightness = 0.1,contrast = 0.1,saturation = 0.1),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomAdjustSharpness(sharpness_factor = 2,p = 0.2),\n    transforms.RandomCrop(32, padding=4),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n    transforms.RandomErasing(p=0.2,scale=(0.02, 0.1),value=1.0, inplace=False)\n])\n\n# Convert to TensorDataset and apply transformations\nclass CustomCIFAR10Dataset(torch.utils.data.Dataset):\n    def __init__(self, images, labels, transform=None):\n        self.images = images\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        img = self.images[idx]\n        label = self.labels[idx]\n\n        if self.transform:\n            img = self.transform(img)\n\n        return img, label\n\ntrain_dataset = CustomCIFAR10Dataset(train_data, train_labels, transform=transform)\n\n# Split into training and validation sets\ntrain_size = int(0.9 * len(train_dataset))\nval_size = len(train_dataset) - train_size\ntrain_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n\n# DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=4)\n\n# Load test dataset\ncifar_test_path = '/kaggle/input/deep-learning-spring-2025-project-1/cifar_test_nolabel.pkl'\ntest_batch = load_cifar_batch(cifar_test_path)\ntest_images = test_batch[b'data'].astype(np.float32) / 255.0\n\ntest_transform = transforms.Compose([\n    transforms.ToPILImage(),  # Convert numpy array to PIL Image\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n])\n\n# Convert test dataset to Tensor\ntest_dataset = [(test_transform(img),) for img in test_images]\ntest_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4)\n\n# Train function\ndef train_model(model, train_loader, val_loader, epochs=50):\n    criterion = nn.CrossEntropyLoss()\n    #optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n    optimizer = optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=1e-4) #change lr\n    #scheduler = StepLR(optimizer, step_size=20, gamma=0.1)\n    scheduler = StepLR(optimizer, step_size=10, gamma=0.9)\n\n    \n    for epoch in range(epochs):\n        model.train()\n        running_loss = 0.0\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        \n        model.eval()\n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                _, predicted = torch.max(outputs, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n        \n        scheduler.step()\n        print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}, Validation Accuracy: {100 * correct / total}%')\n\n# Define a custom ResNet model from scratch\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.skip = nn.Sequential()\n        if stride != 1 or in_channels != out_channels:\n            self.skip = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels)\n            )\n    def forward(self, x):\n        identity = x \n        if self.skip:\n            identity = self.skip(x)\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out += identity\n        out = self.relu(out)\n        return out\n\nclass CustomResNet(nn.Module):\n    def __init__(self, num_classes=10):\n        super(CustomResNet, self).__init__()\n        self.init_conv = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.init_bn = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.layer1 = self._make_layer(64, 64, 2, stride=1)\n        self.layer2 = self._make_layer(64, 128, 2, stride=2)\n        self.layer3 = self._make_layer(128, 256, 2, stride=2)\n        #self.layer4 = self._make_layer(256, 512, 2, stride=2)\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Linear(256, num_classes)\n\n    def _make_layer(self, in_channels, out_channels, blocks, stride):\n        layers = [ResidualBlock(in_channels, out_channels, stride)]\n        for _ in range(1, blocks):\n            layers.append(ResidualBlock(out_channels, out_channels))\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = self.init_conv(x)\n        out = self.init_bn(out)\n        out = self.relu(out)\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        #out = self.layer4(out)\n        out = self.avg_pool(out)\n        out = torch.flatten(out, 1)\n        out = self.fc(out)\n        return out\n\n# put models to devices (CPU/GPU)\nmodel = CustomResNet().to(device)\n\n# Print the number of parameters\nfrom torchsummary import summary\nsummary(model, (3, 32, 32))\n\n# Train the model\ntrain_model(model, train_loader, val_loader, epochs=100) #change epoch\n\n# Generate submission file\nmodel.eval()\npredictions = []\nwith torch.no_grad():\n    for batch in test_loader:\n        images = batch[0].to(device)  # Get images tensor from tuple and move to device\n        outputs = model(images) \n        _, predicted = torch.max(outputs, 1)\n        predictions.extend(predicted.cpu().numpy())\n\n# Generate submission file\nsubmission = pd.DataFrame({'ID': np.arange(len(predictions)), 'Labels': predictions})\nsubmission.to_csv('/kaggle/working/submission10.csv', index=False)\nprint(\"Submission10 file saved.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T16:44:05.905418Z","iopub.execute_input":"2025-03-09T16:44:05.905720Z","iopub.status.idle":"2025-03-09T17:34:14.720302Z","shell.execute_reply.started":"2025-03-09T16:44:05.905696Z","shell.execute_reply":"2025-03-09T17:34:14.719399Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1           [-1, 64, 32, 32]           1,728\n       BatchNorm2d-2           [-1, 64, 32, 32]             128\n              ReLU-3           [-1, 64, 32, 32]               0\n            Conv2d-4           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-5           [-1, 64, 32, 32]             128\n              ReLU-6           [-1, 64, 32, 32]               0\n            Conv2d-7           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-8           [-1, 64, 32, 32]             128\n              ReLU-9           [-1, 64, 32, 32]               0\n    ResidualBlock-10           [-1, 64, 32, 32]               0\n           Conv2d-11           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-12           [-1, 64, 32, 32]             128\n             ReLU-13           [-1, 64, 32, 32]               0\n           Conv2d-14           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-15           [-1, 64, 32, 32]             128\n             ReLU-16           [-1, 64, 32, 32]               0\n    ResidualBlock-17           [-1, 64, 32, 32]               0\n           Conv2d-18          [-1, 128, 16, 16]           8,192\n      BatchNorm2d-19          [-1, 128, 16, 16]             256\n           Conv2d-20          [-1, 128, 16, 16]          73,728\n      BatchNorm2d-21          [-1, 128, 16, 16]             256\n             ReLU-22          [-1, 128, 16, 16]               0\n           Conv2d-23          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-24          [-1, 128, 16, 16]             256\n             ReLU-25          [-1, 128, 16, 16]               0\n    ResidualBlock-26          [-1, 128, 16, 16]               0\n           Conv2d-27          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-28          [-1, 128, 16, 16]             256\n             ReLU-29          [-1, 128, 16, 16]               0\n           Conv2d-30          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-31          [-1, 128, 16, 16]             256\n             ReLU-32          [-1, 128, 16, 16]               0\n    ResidualBlock-33          [-1, 128, 16, 16]               0\n           Conv2d-34            [-1, 256, 8, 8]          32,768\n      BatchNorm2d-35            [-1, 256, 8, 8]             512\n           Conv2d-36            [-1, 256, 8, 8]         294,912\n      BatchNorm2d-37            [-1, 256, 8, 8]             512\n             ReLU-38            [-1, 256, 8, 8]               0\n           Conv2d-39            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-40            [-1, 256, 8, 8]             512\n             ReLU-41            [-1, 256, 8, 8]               0\n    ResidualBlock-42            [-1, 256, 8, 8]               0\n           Conv2d-43            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-44            [-1, 256, 8, 8]             512\n             ReLU-45            [-1, 256, 8, 8]               0\n           Conv2d-46            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-47            [-1, 256, 8, 8]             512\n             ReLU-48            [-1, 256, 8, 8]               0\n    ResidualBlock-49            [-1, 256, 8, 8]               0\nAdaptiveAvgPool2d-50            [-1, 256, 1, 1]               0\n           Linear-51                   [-1, 10]           2,570\n================================================================\nTotal params: 2,777,674\nTrainable params: 2,777,674\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.01\nForward/backward pass size (MB): 14.50\nParams size (MB): 10.60\nEstimated Total Size (MB): 25.11\n----------------------------------------------------------------\nEpoch 1, Loss: 1.5185987935824827, Validation Accuracy: 49.52%\nEpoch 2, Loss: 1.1012639007107778, Validation Accuracy: 57.52%\nEpoch 3, Loss: 0.922681014476852, Validation Accuracy: 62.9%\nEpoch 4, Loss: 0.8056586520238356, Validation Accuracy: 70.0%\nEpoch 5, Loss: 0.7239066991447047, Validation Accuracy: 72.68%\nEpoch 6, Loss: 0.6523420261219144, Validation Accuracy: 69.82%\nEpoch 7, Loss: 0.605683075602759, Validation Accuracy: 77.26%\nEpoch 8, Loss: 0.5624909798022021, Validation Accuracy: 77.46%\nEpoch 9, Loss: 0.5284343631091443, Validation Accuracy: 79.98%\nEpoch 10, Loss: 0.4984216740016233, Validation Accuracy: 77.42%\nEpoch 11, Loss: 0.4645929218439216, Validation Accuracy: 81.14%\nEpoch 12, Loss: 0.44107385428453033, Validation Accuracy: 83.6%\nEpoch 13, Loss: 0.42684201582927594, Validation Accuracy: 82.9%\nEpoch 14, Loss: 0.4084696973758665, Validation Accuracy: 80.34%\nEpoch 15, Loss: 0.3887058140032671, Validation Accuracy: 83.98%\nEpoch 16, Loss: 0.3800073050978509, Validation Accuracy: 81.38%\nEpoch 17, Loss: 0.35976023066111584, Validation Accuracy: 82.62%\nEpoch 18, Loss: 0.3499926457350904, Validation Accuracy: 83.96%\nEpoch 19, Loss: 0.3288491025821052, Validation Accuracy: 84.6%\nEpoch 20, Loss: 0.32238820593126793, Validation Accuracy: 81.92%\nEpoch 21, Loss: 0.3030807986347513, Validation Accuracy: 85.66%\nEpoch 22, Loss: 0.2955971199765124, Validation Accuracy: 85.58%\nEpoch 23, Loss: 0.28731329150667245, Validation Accuracy: 85.42%\nEpoch 24, Loss: 0.2786900750361383, Validation Accuracy: 86.48%\nEpoch 25, Loss: 0.2687420834871856, Validation Accuracy: 85.98%\nEpoch 26, Loss: 0.26055201826701785, Validation Accuracy: 86.66%\nEpoch 27, Loss: 0.24977090158923107, Validation Accuracy: 85.94%\nEpoch 28, Loss: 0.2469051658937877, Validation Accuracy: 85.44%\nEpoch 29, Loss: 0.24057874189351092, Validation Accuracy: 88.16%\nEpoch 30, Loss: 0.23306210483001036, Validation Accuracy: 85.84%\nEpoch 31, Loss: 0.21570220217108727, Validation Accuracy: 88.22%\nEpoch 32, Loss: 0.21447324922138994, Validation Accuracy: 86.74%\nEpoch 33, Loss: 0.20424622151238675, Validation Accuracy: 86.96%\nEpoch 34, Loss: 0.19779357879253273, Validation Accuracy: 86.8%\nEpoch 35, Loss: 0.19547687657177448, Validation Accuracy: 86.1%\nEpoch 36, Loss: 0.18895150325261056, Validation Accuracy: 86.68%\nEpoch 37, Loss: 0.18557004766030746, Validation Accuracy: 86.78%\nEpoch 38, Loss: 0.18397324594711376, Validation Accuracy: 86.56%\nEpoch 39, Loss: 0.17431342374237085, Validation Accuracy: 88.28%\nEpoch 40, Loss: 0.17595563670196993, Validation Accuracy: 88.52%\nEpoch 41, Loss: 0.16002973921554672, Validation Accuracy: 88.16%\nEpoch 42, Loss: 0.15372656123839656, Validation Accuracy: 87.48%\nEpoch 43, Loss: 0.15232146278404715, Validation Accuracy: 88.52%\nEpoch 44, Loss: 0.15215801178816368, Validation Accuracy: 87.92%\nEpoch 45, Loss: 0.1497795177644796, Validation Accuracy: 87.8%\nEpoch 46, Loss: 0.13855044288687746, Validation Accuracy: 88.92%\nEpoch 47, Loss: 0.1341605024750937, Validation Accuracy: 88.08%\nEpoch 48, Loss: 0.13755761504977604, Validation Accuracy: 88.88%\nEpoch 49, Loss: 0.13622871006373316, Validation Accuracy: 89.22%\nEpoch 50, Loss: 0.134139408336275, Validation Accuracy: 88.08%\nEpoch 51, Loss: 0.12674799974245782, Validation Accuracy: 89.36%\nEpoch 52, Loss: 0.1165456519652666, Validation Accuracy: 88.42%\nEpoch 53, Loss: 0.11711380848745731, Validation Accuracy: 89.16%\nEpoch 54, Loss: 0.11527294596784156, Validation Accuracy: 89.06%\nEpoch 55, Loss: 0.11345171765424311, Validation Accuracy: 88.24%\nEpoch 56, Loss: 0.1080152172574096, Validation Accuracy: 88.38%\nEpoch 57, Loss: 0.10482612121003596, Validation Accuracy: 89.36%\nEpoch 58, Loss: 0.10801812129052864, Validation Accuracy: 89.28%\nEpoch 59, Loss: 0.10240830430252985, Validation Accuracy: 89.64%\nEpoch 60, Loss: 0.1015193515817042, Validation Accuracy: 89.96%\nEpoch 61, Loss: 0.09907636767126281, Validation Accuracy: 88.88%\nEpoch 62, Loss: 0.08981221000960266, Validation Accuracy: 89.28%\nEpoch 63, Loss: 0.0903774519472129, Validation Accuracy: 88.88%\nEpoch 64, Loss: 0.08728546458719806, Validation Accuracy: 88.54%\nEpoch 65, Loss: 0.0862739366077056, Validation Accuracy: 89.78%\nEpoch 66, Loss: 0.09069389170988208, Validation Accuracy: 89.76%\nEpoch 67, Loss: 0.0843713801163672, Validation Accuracy: 88.24%\nEpoch 68, Loss: 0.08587441450535235, Validation Accuracy: 88.24%\nEpoch 69, Loss: 0.08015285881066864, Validation Accuracy: 90.3%\nEpoch 70, Loss: 0.08043690122113648, Validation Accuracy: 89.3%\nEpoch 71, Loss: 0.07769928023811769, Validation Accuracy: 89.94%\nEpoch 72, Loss: 0.07260867114051837, Validation Accuracy: 90.42%\nEpoch 73, Loss: 0.07137532427970489, Validation Accuracy: 90.84%\nEpoch 74, Loss: 0.068255787887293, Validation Accuracy: 90.34%\nEpoch 75, Loss: 0.06873849475893869, Validation Accuracy: 90.18%\nEpoch 76, Loss: 0.06351357512176037, Validation Accuracy: 89.62%\nEpoch 77, Loss: 0.06564220687141642, Validation Accuracy: 90.18%\nEpoch 78, Loss: 0.06422427455651235, Validation Accuracy: 89.84%\nEpoch 79, Loss: 0.06523179073172453, Validation Accuracy: 89.52%\nEpoch 80, Loss: 0.06448951408277605, Validation Accuracy: 89.56%\nEpoch 81, Loss: 0.05885869413825937, Validation Accuracy: 90.4%\nEpoch 82, Loss: 0.05987717934344387, Validation Accuracy: 89.42%\nEpoch 83, Loss: 0.05635718132940714, Validation Accuracy: 90.9%\nEpoch 84, Loss: 0.05573517933159813, Validation Accuracy: 89.96%\nEpoch 85, Loss: 0.05577550849887881, Validation Accuracy: 90.68%\nEpoch 86, Loss: 0.05416958012210671, Validation Accuracy: 90.52%\nEpoch 87, Loss: 0.0562863296575167, Validation Accuracy: 89.18%\nEpoch 88, Loss: 0.057826840863774785, Validation Accuracy: 90.74%\nEpoch 89, Loss: 0.056304625412766734, Validation Accuracy: 90.92%\nEpoch 90, Loss: 0.05422755389273251, Validation Accuracy: 90.54%\nEpoch 91, Loss: 0.04819415474247018, Validation Accuracy: 90.84%\nEpoch 92, Loss: 0.04910812036674046, Validation Accuracy: 90.46%\nEpoch 93, Loss: 0.0455290161044104, Validation Accuracy: 90.48%\nEpoch 94, Loss: 0.04531301915994845, Validation Accuracy: 90.64%\nEpoch 95, Loss: 0.047066233374855736, Validation Accuracy: 90.04%\nEpoch 96, Loss: 0.04583983073164497, Validation Accuracy: 90.78%\nEpoch 97, Loss: 0.04531889804506632, Validation Accuracy: 90.42%\nEpoch 98, Loss: 0.04365889233304188, Validation Accuracy: 90.42%\nEpoch 99, Loss: 0.047086206502916124, Validation Accuracy: 90.22%\nEpoch 100, Loss: 0.04486508446412203, Validation Accuracy: 90.56%\nSubmission10 file saved.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# adjust optimizer lr to 0.007 + scheduler\nimport numpy as np\nimport pandas as pd\nimport os\nimport pickle\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nfrom torch.utils.data import DataLoader, random_split, TensorDataset\nfrom torch.optim.lr_scheduler import StepLR\nfrom PIL import Image\nimport torch.optim.lr_scheduler as lr_scheduler\n\n# auto. choose CPU or GPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n# Function to load CIFAR-10 dataset\ndef load_cifar_batch(file):\n    with open(file, 'rb') as fo:\n        dict = pickle.load(fo, encoding='bytes')\n    return dict\n\n# Specify the directory containing CIFAR-10 batches\ncifar10_dir = '/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py'\n\n# Load metadata (labels)\nmeta_data_dict = load_cifar_batch(os.path.join(cifar10_dir, 'batches.meta'))\nlabel_names = [label.decode('utf-8') for label in meta_data_dict[b'label_names']]\n\n# Load training data\ntrain_data = []\ntrain_labels = []\nfor i in range(1, 6):\n    batch = load_cifar_batch(os.path.join(cifar10_dir, f'data_batch_{i}'))\n    train_data.append(batch[b'data'])\n    train_labels += batch[b'labels']\n\ntrain_data = np.vstack(train_data).reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)  # Convert to HWC format\ntrain_labels = np.array(train_labels)\n\n# Data augmentation and normalization\ntransform = transforms.Compose([\n    transforms.ToPILImage(),  # Convert numpy array to PIL Image\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(brightness = 0.1,contrast = 0.1,saturation = 0.1),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomAdjustSharpness(sharpness_factor = 2,p = 0.2),\n    transforms.RandomCrop(32, padding=4),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n    transforms.RandomErasing(p=0.2,scale=(0.02, 0.1),value=1.0, inplace=False)\n])\n\n# Convert to TensorDataset and apply transformations\nclass CustomCIFAR10Dataset(torch.utils.data.Dataset):\n    def __init__(self, images, labels, transform=None):\n        self.images = images\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        img = self.images[idx]\n        label = self.labels[idx]\n\n        if self.transform:\n            img = self.transform(img)\n\n        return img, label\n\ntrain_dataset = CustomCIFAR10Dataset(train_data, train_labels, transform=transform)\n\n# Split into training and validation sets\ntrain_size = int(0.9 * len(train_dataset))\nval_size = len(train_dataset) - train_size\ntrain_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n\n# DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=4)\n\n# Load test dataset\ncifar_test_path = '/kaggle/input/deep-learning-spring-2025-project-1/cifar_test_nolabel.pkl'\ntest_batch = load_cifar_batch(cifar_test_path)\ntest_images = test_batch[b'data'].astype(np.float32) / 255.0\n\ntest_transform = transforms.Compose([\n    transforms.ToPILImage(),  # Convert numpy array to PIL Image\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n])\n\n# Convert test dataset to Tensor\ntest_dataset = [(test_transform(img),) for img in test_images]\ntest_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4)\n\n# Train function\ndef train_model(model, train_loader, val_loader, epochs=50):\n    criterion = nn.CrossEntropyLoss()\n    #optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n    optimizer = optim.SGD(model.parameters(), lr=0.007, momentum=0.9, weight_decay=1e-4) #change lr\n    #scheduler = StepLR(optimizer, step_size=20, gamma=0.1)\n    scheduler = StepLR(optimizer, step_size=10, gamma=0.9)\n\n    \n    for epoch in range(epochs):\n        model.train()\n        running_loss = 0.0\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        \n        model.eval()\n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                _, predicted = torch.max(outputs, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n        \n        scheduler.step()\n        print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}, Validation Accuracy: {100 * correct / total}%')\n\n# Define a custom ResNet model from scratch\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.skip = nn.Sequential()\n        if stride != 1 or in_channels != out_channels:\n            self.skip = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels)\n            )\n    def forward(self, x):\n        identity = x \n        if self.skip:\n            identity = self.skip(x)\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out += identity\n        out = self.relu(out)\n        return out\n\nclass CustomResNet(nn.Module):\n    def __init__(self, num_classes=10):\n        super(CustomResNet, self).__init__()\n        self.init_conv = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.init_bn = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.layer1 = self._make_layer(64, 64, 2, stride=1)\n        self.layer2 = self._make_layer(64, 128, 2, stride=2)\n        self.layer3 = self._make_layer(128, 256, 2, stride=2)\n        #self.layer4 = self._make_layer(256, 512, 2, stride=2)\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Linear(256, num_classes)\n\n    def _make_layer(self, in_channels, out_channels, blocks, stride):\n        layers = [ResidualBlock(in_channels, out_channels, stride)]\n        for _ in range(1, blocks):\n            layers.append(ResidualBlock(out_channels, out_channels))\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = self.init_conv(x)\n        out = self.init_bn(out)\n        out = self.relu(out)\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        #out = self.layer4(out)\n        out = self.avg_pool(out)\n        out = torch.flatten(out, 1)\n        out = self.fc(out)\n        return out\n\n# put models to devices (CPU/GPU)\nmodel = CustomResNet().to(device)\n\n# Print the number of parameters\nfrom torchsummary import summary\nsummary(model, (3, 32, 32))\n\n# Train the model\ntrain_model(model, train_loader, val_loader, epochs=100) #change epoch\n\n# Generate submission file\nmodel.eval()\npredictions = []\nwith torch.no_grad():\n    for batch in test_loader:\n        images = batch[0].to(device)  # Get images tensor from tuple and move to device\n        outputs = model(images) \n        _, predicted = torch.max(outputs, 1)\n        predictions.extend(predicted.cpu().numpy())\n\n# Generate submission file\nsubmission = pd.DataFrame({'ID': np.arange(len(predictions)), 'Labels': predictions})\nsubmission.to_csv('/kaggle/working/submission11.csv', index=False)\nprint(\"Submission11 file saved.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T17:34:14.721764Z","iopub.execute_input":"2025-03-09T17:34:14.722002Z","iopub.status.idle":"2025-03-09T18:24:28.276209Z","shell.execute_reply.started":"2025-03-09T17:34:14.721980Z","shell.execute_reply":"2025-03-09T18:24:28.275267Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1           [-1, 64, 32, 32]           1,728\n       BatchNorm2d-2           [-1, 64, 32, 32]             128\n              ReLU-3           [-1, 64, 32, 32]               0\n            Conv2d-4           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-5           [-1, 64, 32, 32]             128\n              ReLU-6           [-1, 64, 32, 32]               0\n            Conv2d-7           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-8           [-1, 64, 32, 32]             128\n              ReLU-9           [-1, 64, 32, 32]               0\n    ResidualBlock-10           [-1, 64, 32, 32]               0\n           Conv2d-11           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-12           [-1, 64, 32, 32]             128\n             ReLU-13           [-1, 64, 32, 32]               0\n           Conv2d-14           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-15           [-1, 64, 32, 32]             128\n             ReLU-16           [-1, 64, 32, 32]               0\n    ResidualBlock-17           [-1, 64, 32, 32]               0\n           Conv2d-18          [-1, 128, 16, 16]           8,192\n      BatchNorm2d-19          [-1, 128, 16, 16]             256\n           Conv2d-20          [-1, 128, 16, 16]          73,728\n      BatchNorm2d-21          [-1, 128, 16, 16]             256\n             ReLU-22          [-1, 128, 16, 16]               0\n           Conv2d-23          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-24          [-1, 128, 16, 16]             256\n             ReLU-25          [-1, 128, 16, 16]               0\n    ResidualBlock-26          [-1, 128, 16, 16]               0\n           Conv2d-27          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-28          [-1, 128, 16, 16]             256\n             ReLU-29          [-1, 128, 16, 16]               0\n           Conv2d-30          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-31          [-1, 128, 16, 16]             256\n             ReLU-32          [-1, 128, 16, 16]               0\n    ResidualBlock-33          [-1, 128, 16, 16]               0\n           Conv2d-34            [-1, 256, 8, 8]          32,768\n      BatchNorm2d-35            [-1, 256, 8, 8]             512\n           Conv2d-36            [-1, 256, 8, 8]         294,912\n      BatchNorm2d-37            [-1, 256, 8, 8]             512\n             ReLU-38            [-1, 256, 8, 8]               0\n           Conv2d-39            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-40            [-1, 256, 8, 8]             512\n             ReLU-41            [-1, 256, 8, 8]               0\n    ResidualBlock-42            [-1, 256, 8, 8]               0\n           Conv2d-43            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-44            [-1, 256, 8, 8]             512\n             ReLU-45            [-1, 256, 8, 8]               0\n           Conv2d-46            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-47            [-1, 256, 8, 8]             512\n             ReLU-48            [-1, 256, 8, 8]               0\n    ResidualBlock-49            [-1, 256, 8, 8]               0\nAdaptiveAvgPool2d-50            [-1, 256, 1, 1]               0\n           Linear-51                   [-1, 10]           2,570\n================================================================\nTotal params: 2,777,674\nTrainable params: 2,777,674\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.01\nForward/backward pass size (MB): 14.50\nParams size (MB): 10.60\nEstimated Total Size (MB): 25.11\n----------------------------------------------------------------\nEpoch 1, Loss: 1.507496772503311, Validation Accuracy: 52.42%\nEpoch 2, Loss: 1.0971157493239099, Validation Accuracy: 59.94%\nEpoch 3, Loss: 0.9024164329536937, Validation Accuracy: 64.66%\nEpoch 4, Loss: 0.7728878327391364, Validation Accuracy: 72.2%\nEpoch 5, Loss: 0.6902479710565372, Validation Accuracy: 68.68%\nEpoch 6, Loss: 0.6325324422425844, Validation Accuracy: 73.78%\nEpoch 7, Loss: 0.5820782740007747, Validation Accuracy: 75.48%\nEpoch 8, Loss: 0.5470729321241379, Validation Accuracy: 76.6%\nEpoch 9, Loss: 0.5020496978170492, Validation Accuracy: 70.56%\nEpoch 10, Loss: 0.47811295913363044, Validation Accuracy: 77.96%\nEpoch 11, Loss: 0.43841626948084345, Validation Accuracy: 79.98%\nEpoch 12, Loss: 0.42294197935949673, Validation Accuracy: 81.6%\nEpoch 13, Loss: 0.40456362877210433, Validation Accuracy: 82.12%\nEpoch 14, Loss: 0.38181403190405533, Validation Accuracy: 81.2%\nEpoch 15, Loss: 0.37037627229636366, Validation Accuracy: 81.38%\nEpoch 16, Loss: 0.36227893621914764, Validation Accuracy: 78.36%\nEpoch 17, Loss: 0.3423542648299851, Validation Accuracy: 82.72%\nEpoch 18, Loss: 0.3329598994671621, Validation Accuracy: 83.32%\nEpoch 19, Loss: 0.3152993801473217, Validation Accuracy: 82.78%\nEpoch 20, Loss: 0.30352068857543846, Validation Accuracy: 86.04%\nEpoch 21, Loss: 0.28444414187900047, Validation Accuracy: 85.78%\nEpoch 22, Loss: 0.27295068109577353, Validation Accuracy: 86.08%\nEpoch 23, Loss: 0.2659443565644324, Validation Accuracy: 87.02%\nEpoch 24, Loss: 0.2613929374651475, Validation Accuracy: 85.52%\nEpoch 25, Loss: 0.24682695575227792, Validation Accuracy: 85.64%\nEpoch 26, Loss: 0.24111810136078435, Validation Accuracy: 85.16%\nEpoch 27, Loss: 0.2328981610480696, Validation Accuracy: 86.68%\nEpoch 28, Loss: 0.2276341717224568, Validation Accuracy: 86.36%\nEpoch 29, Loss: 0.22085273687050425, Validation Accuracy: 86.46%\nEpoch 30, Loss: 0.2133446705146608, Validation Accuracy: 85.62%\nEpoch 31, Loss: 0.2016598184339025, Validation Accuracy: 87.04%\nEpoch 32, Loss: 0.19553626796484672, Validation Accuracy: 87.12%\nEpoch 33, Loss: 0.18778478913009167, Validation Accuracy: 87.44%\nEpoch 34, Loss: 0.18787223530340602, Validation Accuracy: 88.06%\nEpoch 35, Loss: 0.1741400024514984, Validation Accuracy: 88.26%\nEpoch 36, Loss: 0.17145931369371034, Validation Accuracy: 87.6%\nEpoch 37, Loss: 0.17009302259380507, Validation Accuracy: 88.34%\nEpoch 38, Loss: 0.16672921278090638, Validation Accuracy: 86.78%\nEpoch 39, Loss: 0.1646523273295977, Validation Accuracy: 88.94%\nEpoch 40, Loss: 0.1564876220231368, Validation Accuracy: 87.64%\nEpoch 41, Loss: 0.14991436357906257, Validation Accuracy: 88.58%\nEpoch 42, Loss: 0.14259077796437356, Validation Accuracy: 88.5%\nEpoch 43, Loss: 0.13690818405964159, Validation Accuracy: 88.66%\nEpoch 44, Loss: 0.13049152976071293, Validation Accuracy: 88.56%\nEpoch 45, Loss: 0.13478385348042304, Validation Accuracy: 89.48%\nEpoch 46, Loss: 0.13236209100366317, Validation Accuracy: 89.02%\nEpoch 47, Loss: 0.12152276755395261, Validation Accuracy: 89.58%\nEpoch 48, Loss: 0.12031598075885665, Validation Accuracy: 88.22%\nEpoch 49, Loss: 0.12066861012400212, Validation Accuracy: 88.54%\nEpoch 50, Loss: 0.11790239526255225, Validation Accuracy: 87.72%\nEpoch 51, Loss: 0.1120020070282573, Validation Accuracy: 89.86%\nEpoch 52, Loss: 0.10546835434665396, Validation Accuracy: 88.94%\nEpoch 53, Loss: 0.10139344281262973, Validation Accuracy: 89.22%\nEpoch 54, Loss: 0.10481396887387912, Validation Accuracy: 89.0%\nEpoch 55, Loss: 0.09702105565123599, Validation Accuracy: 88.76%\nEpoch 56, Loss: 0.09863507613243366, Validation Accuracy: 89.16%\nEpoch 57, Loss: 0.09787912099008364, Validation Accuracy: 88.94%\nEpoch 58, Loss: 0.09325565413085067, Validation Accuracy: 89.16%\nEpoch 59, Loss: 0.08868969308572229, Validation Accuracy: 89.88%\nEpoch 60, Loss: 0.09066181272712791, Validation Accuracy: 89.66%\nEpoch 61, Loss: 0.08268115656789053, Validation Accuracy: 89.66%\nEpoch 62, Loss: 0.0833698003552854, Validation Accuracy: 89.74%\nEpoch 63, Loss: 0.07653887026191858, Validation Accuracy: 89.64%\nEpoch 64, Loss: 0.0787982093831736, Validation Accuracy: 89.4%\nEpoch 65, Loss: 0.07420370832286691, Validation Accuracy: 90.02%\nEpoch 66, Loss: 0.07654521956150843, Validation Accuracy: 89.26%\nEpoch 67, Loss: 0.07424326668313536, Validation Accuracy: 90.46%\nEpoch 68, Loss: 0.0737400867457671, Validation Accuracy: 89.84%\nEpoch 69, Loss: 0.0703540346452924, Validation Accuracy: 90.22%\nEpoch 70, Loss: 0.07364557435291565, Validation Accuracy: 90.34%\nEpoch 71, Loss: 0.06378810923408972, Validation Accuracy: 90.36%\nEpoch 72, Loss: 0.0645178893067747, Validation Accuracy: 90.08%\nEpoch 73, Loss: 0.0626705510658212, Validation Accuracy: 90.88%\nEpoch 74, Loss: 0.06081639448794621, Validation Accuracy: 90.38%\nEpoch 75, Loss: 0.05860870217756284, Validation Accuracy: 90.58%\nEpoch 76, Loss: 0.05944603314856067, Validation Accuracy: 90.76%\nEpoch 77, Loss: 0.05791197701314972, Validation Accuracy: 90.22%\nEpoch 78, Loss: 0.05743680106719363, Validation Accuracy: 90.18%\nEpoch 79, Loss: 0.05718838023974306, Validation Accuracy: 90.7%\nEpoch 80, Loss: 0.05817559677102095, Validation Accuracy: 91.32%\nEpoch 81, Loss: 0.05396428233838047, Validation Accuracy: 90.6%\nEpoch 82, Loss: 0.04799057278962044, Validation Accuracy: 90.4%\nEpoch 83, Loss: 0.04919387230554342, Validation Accuracy: 90.46%\nEpoch 84, Loss: 0.04935422109238888, Validation Accuracy: 90.0%\nEpoch 85, Loss: 0.051562033770923416, Validation Accuracy: 90.52%\nEpoch 86, Loss: 0.04940717220465145, Validation Accuracy: 91.14%\nEpoch 87, Loss: 0.044833985452317975, Validation Accuracy: 90.74%\nEpoch 88, Loss: 0.04838740222939206, Validation Accuracy: 90.64%\nEpoch 89, Loss: 0.04775840186894956, Validation Accuracy: 90.16%\nEpoch 90, Loss: 0.04382149338595231, Validation Accuracy: 90.68%\nEpoch 91, Loss: 0.04351556147660383, Validation Accuracy: 91.04%\nEpoch 92, Loss: 0.043464157858662394, Validation Accuracy: 90.6%\nEpoch 93, Loss: 0.042368766449561175, Validation Accuracy: 90.72%\nEpoch 94, Loss: 0.038441011872650546, Validation Accuracy: 90.34%\nEpoch 95, Loss: 0.03797511379922402, Validation Accuracy: 90.48%\nEpoch 96, Loss: 0.038925541326699946, Validation Accuracy: 90.64%\nEpoch 97, Loss: 0.03910429816063366, Validation Accuracy: 90.9%\nEpoch 98, Loss: 0.03987978561913637, Validation Accuracy: 91.12%\nEpoch 99, Loss: 0.03424074733894403, Validation Accuracy: 90.76%\nEpoch 100, Loss: 0.03861764490879564, Validation Accuracy: 91.38%\nSubmission11 file saved.\n","output_type":"stream"}],"execution_count":10}]}